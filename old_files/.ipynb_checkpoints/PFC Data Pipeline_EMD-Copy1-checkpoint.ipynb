{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import sima\n",
    "import sima.motion\n",
    "from sima.ROI import ROIList\n",
    "from sima.motion import HiddenMarkov2D\n",
    "from sima.motion import PlaneTranslation2D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import subprocess\n",
    "import bisect\n",
    "import errno\n",
    "import time\n",
    "import pandas\n",
    "import pickle\n",
    "#import num2words\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import roc_auc_score as auROC\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import (ModelDesc, EvalEnvironment, Term, EvalFactor, LookupFactor, dmatrices, INTERCEPT)\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from shapely.geometry import MultiPolygon, Polygon, Point\n",
    "import PIL\n",
    "from itertools import product\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as colorbar\n",
    "from sima.ROI import poly2mask, _reformat_polygons\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\Beth\\Self-Administration\\2P-HER_PrL-GCaMP6s\\LCDD_PGa-Tomato\\LCDD_PGa-T1\\210219_LCDD-PGa-T1_FOV1_LOW_D9\\T1-LCDD-PGa-T1_FOV1_LOW-D9_behavior_pt3\n"
     ]
    }
   ],
   "source": [
    "### NOTE: CHANGE THIS EVERY TIME YOU RUN THE CODE, SPECIFIC TO EACH MOUSE, FOV, and DAY\n",
    "## THIS IS FOR RUNNING FROM LAB, ANALYSIS COMPUTER\n",
    "\n",
    "filename = 'T1-LCDD-PGa-T1_FOV1_LOW-D9_behavior_pt3'\n",
    "basedir = r'Z:\\Beth\\Self-Administration\\2P-HER_PrL-GCaMP6s\\LCDD_PGa-Tomato\\LCDD_PGa-T1\\210219_LCDD-PGa-T1_FOV1_LOW_D9'\n",
    "print os.path.join(basedir, filename)\n",
    "\n",
    "sequences = [sima.Sequence.create('HDF5', os.path.join(basedir, filename+'.h5'), 'tyx')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS IS FOR RUNNING FROM JIM'S MACBOOK PRO\n",
    "# filename= 'BL8_D3_FOV3_PC3'\n",
    "# basedir = r'C:\\Users\\Stuber Lab\\Desktop\\JimDatProcessing\\BL8_D3_FOV3_PC3'\n",
    "# print os.path.join(basedir, filename)\n",
    "\n",
    "# sequences = [sima.Sequence.create('HDF5', os.path.join(basedir, filename+'.h5'), 'tyx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "WindowsError",
     "evalue": "[Error 183] Cannot create a file when that file already exists: 'Z:\\\\Beth\\\\Self-Administration\\\\2P-HER_PrL-GCaMP6s\\\\LCDD_PGa-Tomato\\\\LCDD_PGa-T4\\\\210331_LCDD-PGa-T4_FOV1_RST-CUE_PERS\\\\LCDD-PGa-T4_RST-CUE_PERSIST_part2_new-npy-with-RoiSet-aligned-to-part-1\\\\T2_LCDD-PGa-T4_FOV1_RST-CUE_PERSIST_behavior_pt2.sima'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mWindowsError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c6555cbfa49f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#generate the sima data file from your loaded data & run the motion correction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msima\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImagingDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.sima'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmc_approach\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msima\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHiddenMarkov2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgranularity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_displacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmc_approach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_mc.sima'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\imaging.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sequences, savedir, channel_names, read_only)\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msima\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavedir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msavedir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchannel_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\imaging.pyc\u001b[0m in \u001b[0;36msavedir\u001b[1;34m(self, savedir)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msavedir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.sima'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0msavedir\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.sima'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_savedir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msavedir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0morig_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\os.pyc\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[1;33m:\u001b[0m           \u001b[1;31m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremovedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWindowsError\u001b[0m: [Error 183] Cannot create a file when that file already exists: 'Z:\\\\Beth\\\\Self-Administration\\\\2P-HER_PrL-GCaMP6s\\\\LCDD_PGa-Tomato\\\\LCDD_PGa-T4\\\\210331_LCDD-PGa-T4_FOV1_RST-CUE_PERS\\\\LCDD-PGa-T4_RST-CUE_PERSIST_part2_new-npy-with-RoiSet-aligned-to-part-1\\\\T2_LCDD-PGa-T4_FOV1_RST-CUE_PERSIST_behavior_pt2.sima'"
     ]
    }
   ],
   "source": [
    "#generate the sima data file from your loaded data & run the motion correction\n",
    "dataset = sima.ImagingDataset(sequences, os.path.join(basedir, filename+'.sima'))\n",
    "mc_approach = sima.motion.HiddenMarkov2D(granularity='row', max_displacement=[50, 50], verbose=False)\n",
    "dataset = mc_approach.correct(sequences, os.path.join(basedir, filename+'_mc.sima'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "integer out of range for 'I' format code",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3db91294a915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_averages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_AVG.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TIFF16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'average'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_averages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_STD.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TIFF16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'std'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_mc.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TIFF16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_gaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\imaging.pyc\u001b[0m in \u001b[0;36mexport_frames\u001b[1;34m(self, filenames, fmt, fill_gaps, scale_values, compression)\u001b[0m\n\u001b[0;32m    739\u001b[0m                 \u001b[0mfns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_gaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_gaps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 \u001b[0mchannel_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m                 scale_values=scale_values)\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexport_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignals_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\sequence.pyc\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, filenames, fmt, fill_gaps, channel_names, compression, scale_values)\u001b[0m\n\u001b[0;32m    487\u001b[0m                         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mplane_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'TIFF16'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m                         \u001b[1;32melif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'TIFF8'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\misc\\tifffile.pyc\u001b[0m in \u001b[0;36mwrite_page\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_seek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ifd_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_seek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\misc\\tifffile.pyc\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, arg, *args)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_byteorder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\sima\\misc\\tifffile.pyc\u001b[0m in \u001b[0;36mpack\u001b[1;34m(fmt, *val)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_byteorder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: integer out of range for 'I' format code"
     ]
    }
   ],
   "source": [
    "#this line exports motion corrected frames.  \n",
    "dataset.export_averages([os.path.join(basedir, filename+'_AVG.tif')], fmt='TIFF16', projection_type=u'average')\n",
    "dataset.export_averages([os.path.join(basedir, filename+'_STD.tif')], fmt='TIFF16', projection_type=u'std')\n",
    "dataset.export_frames([[[os.path.join(basedir, filename+'_mc.tif')]]], fmt='TIFF16', fill_gaps='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load motioncorrection folder\n",
    "dataset = sima.ImagingDataset.load(os.path.join(basedir, filename+'_mc.sima'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\Beth\\Self-Administration\\2P-HER_PrL-GCaMP6s\\LCDD_PGa-Tomato\\LCDD_PGa-T1\\210219_LCDD-PGa-T1_FOV1_LOW_D9\n",
      "T1-LCDD-PGa-T1_FOV1_LOW-D9_behavior_pt3\n"
     ]
    }
   ],
   "source": [
    "print basedir\n",
    "print filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load in ROIs from ImageJ\n",
    "rois = ROIList.load(os.path.join(basedir, filename+'_RoiSet.zip'), fmt='ImageJ')\n",
    "dataset\n",
    "#add the ROIs to the SIMA dataset\n",
    "dataset.add_ROIs(rois, 'from_ImageJ')\n",
    "#check the properties of the loaded ROIs\n",
    "dataset.ROIs.keys()\n",
    "#extract ROI data as a new datafile called signals\n",
    "signals = dataset.extract(rois, remove_overlap=False)\n",
    "#this will pull the extracted data from the SIMA extracted file and place it in new numpy array called extracted signals.\n",
    "extractedsignals = np.asarray(signals['raw'])\n",
    "#export signals as a .csv and .npy file\n",
    "np.save(os.path.join(basedir, filename+'_extractedsignals_raw.npy'), extractedsignals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###DONT RUN FOR PVT CORRECTION\n",
    "# ###THIS IS FOR NEUROPIL CORRECTION.  RUN ONLY IF YOU ARE RECORDING FROM CELL BODIES (E.G., ALL BL MICE)\n",
    "# try:\n",
    "#     from IPython.core.display import clear_output\n",
    "#     have_ipython = True\n",
    "# except ImportError:\n",
    "#     have_ipython = False\n",
    "\n",
    "# class ProgressBar:\n",
    "#     def __init__(self, iterations):\n",
    "#         self.iterations = iterations\n",
    "#         self.prog_bar = '[]'\n",
    "#         self.fill_char = '*'\n",
    "#         self.width = 40\n",
    "#         self.__update_amount(0)\n",
    "#         if have_ipython:\n",
    "#             self.animate = self.animate_ipython\n",
    "#         else:\n",
    "#             self.animate = self.animate_noipython\n",
    "\n",
    "#     def animate_ipython(self, iter):\n",
    "#         try:\n",
    "#             clear_output()\n",
    "#         except Exception:\n",
    "#             # terminal IPython has no clear_output\n",
    "#             pass\n",
    "#         print '\\r', self,\n",
    "#         sys.stdout.flush()\n",
    "#         self.update_iteration(iter + 1)\n",
    "\n",
    "#     def update_iteration(self, elapsed_iter):\n",
    "#         self.__update_amount((elapsed_iter / float(self.iterations)) * 100.0)\n",
    "#         self.prog_bar += '  %d of %s complete' % (elapsed_iter, self.iterations)\n",
    "\n",
    "#     def __update_amount(self, new_amount):\n",
    "#         percent_done = int(round((new_amount / 100.0) * 100.0))\n",
    "#         all_full = self.width - 2\n",
    "#         num_hashes = int(round((percent_done / 100.0) * all_full))\n",
    "#         self.prog_bar = '[' + self.fill_char * num_hashes + ' ' * (all_full - num_hashes) + ']'\n",
    "#         pct_place = (len(self.prog_bar) / 2) - len(str(percent_done))\n",
    "#         pct_string = '%d%%' % percent_done\n",
    "#         self.prog_bar = self.prog_bar[0:pct_place] + \\\n",
    "#             (pct_string + self.prog_bar[pct_place + len(pct_string):])\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return str(self.prog_bar)\n",
    "\n",
    "# def correct_sima_paths(h5filepath, savedir, simadir, dual_channel):\n",
    "#     # This is a function that corrects the paths to datafiles in all files\n",
    "#     # within the .sima directory. It assumes that the original data file is\n",
    "#     # a .h5 file in the same directory as the .sima directory, and that\n",
    "#     # the name of this file is such that if its name is \"data.h5\", the \n",
    "#     # .sima directory has the name \"data_mc.sima\". So there should be an\n",
    "#     # \"_mc.sima\" at the end of the .sima directory\n",
    "#     if not os.path.isdir(os.path.join(savedir, simadir)):\n",
    "#         raise Exception('%s does not exist in %s'%(simadir, savedir))\n",
    "#     sequencesdict = pickle.load(open(os.path.join(savedir, simadir, 'sequences.pkl'), 'rb'))\n",
    "#     datasetdict = pickle.load(open(os.path.join(savedir, simadir, 'dataset.pkl'), 'rb'))\n",
    "#     #print sequencesdict[0]['base']['base']['sequences'][0].keys()\n",
    "#     #print datasetdict\n",
    "#     if dual_channel:\n",
    "#         abspath=sequencesdict[0]['base']['base']['sequences'][0]['_abspath']\n",
    "#     else:\n",
    "#         abspath=sequencesdict[0]['base']['base']['_abspath']\n",
    "#     correctabspath = h5filepath\n",
    "#     #print correctabspath, abspath\n",
    "#     if abspath != correctabspath:\n",
    "#         print('Paths not appropriate in the .sima directory. Correcting them..')\n",
    "#         sequencesdict[0]['base']['base']['_abspath'] = correctabspath\n",
    "#         datasetdict['savedir'] = os.path.join(savedir, simadir)\n",
    "#         with open(os.path.join(savedir, simadir, 'sequences.pkl'), 'wb') as out1:\n",
    "#             pickle.dump(sequencesdict, out1)\n",
    "#         with open(os.path.join(savedir, simadir, 'dataset.pkl'), 'wb') as out2:\n",
    "#             pickle.dump(datasetdict, out2)\n",
    "            \n",
    "# def load_rois_for_session(session_folder):\n",
    "#     temp = os.walk(session_folder).next()[1]\n",
    "#     sima_folder = [a for a in temp if 'mc.sima' in a][0] #adjusted by JO 8/30/2017\n",
    "#     with open(os.path.join(session_folder, sima_folder, 'signals_0.pkl'), 'rb') as temp:\n",
    "#         a = pickle.load(temp)\n",
    "#     numrois = len(a[sorted(a.keys())[-1]]['rois']) #Load the latest extraction\n",
    "#     im_shape = a[sorted(a.keys())[-1]]['rois'][0]['im_shape'][1:]\n",
    "#     #roi_polygons = [a[sorted(a.keys())[-1]]['rois'][roi_id]['polygons'][0][:,:-1] for roi_id in range(numrois)] # no z coordinate\n",
    "#     roi_polygons = [a[sorted(a.keys())[-1]]['rois'][roi_id]['polygons'][0] for roi_id in range(numrois)]  # with z coordinate\n",
    "    \n",
    "#     return roi_polygons, im_shape\n",
    "\n",
    "# def calculate_roi_centroids(session_folder):\n",
    "#     roi_polygons, im_shape = load_rois_for_session(session_folder)\n",
    "#     roi_centroids = [Polygon(roi).centroid.coords[0] for roi in roi_polygons]\n",
    "#     return roi_centroids, im_shape, roi_polygons\n",
    "\n",
    "# def calculate_roi_masks(roi_polygons, im_size):\n",
    "#     masks = []\n",
    "#     if len(im_size) == 2:\n",
    "#         im_size = (1,) + im_size\n",
    "#     roi_polygons = _reformat_polygons(roi_polygons)\n",
    "#     for poly in roi_polygons:\n",
    "#         mask = np.zeros(im_size, dtype=bool)\n",
    "#         # assuming all points in the polygon share a z-coordinate\n",
    "#         z = int(np.array(poly.exterior.coords)[0][2])\n",
    "#         if z > im_size[0]:\n",
    "#             warn('Polygon with zero-coordinate {} '.format(z) +\n",
    "#                  'cropped using im_size = {}'.format(im_size))\n",
    "#             continue\n",
    "#         x_min, y_min, x_max, y_max = poly.bounds\n",
    "\n",
    "#         # Shift all points by 0.5 to move coordinates to corner of pixel\n",
    "#         shifted_poly = Polygon(np.array(poly.exterior.coords)[:, :2] - 0.5)\n",
    "\n",
    "#         points = [Point(x, y) for x, y in\n",
    "#                   product(np.arange(int(x_min), np.ceil(x_max)),\n",
    "#                           np.arange(int(y_min), np.ceil(y_max)))]\n",
    "#         points_in_poly = list(filter(shifted_poly.contains, points))\n",
    "#         for point in points_in_poly:\n",
    "#             xx, yy = point.xy\n",
    "#             x = int(xx[0])\n",
    "#             y = int(yy[0])\n",
    "#             if 0 <= y < im_size[1] and 0 <= x < im_size[2]:\n",
    "#                 mask[z, y, x] = True\n",
    "#         masks.append(mask[0,:,:])\n",
    "#     return masks\n",
    "\n",
    "# def calculate_spatialweights_around_roi(indir, roi_masks, roi_centroids,\n",
    "#                                         neuropil_radius, min_neuropil_radius, h5file):\n",
    "#     # roi_centroids has order (x,y). The index for any roi_masks is in row, col shape or y,x shape.\n",
    "#     # So be careful to flip the order when you subtract from centroid\n",
    "#     numrois = len(roi_masks)\n",
    "#     allrois_mask = np.logical_not(np.sum(roi_masks, axis=0))\n",
    "#     (im_ysize, im_xsize) = allrois_mask.shape\n",
    "#     y_base = np.tile(np.array([range(1,im_ysize+1)]).transpose(), (1,im_xsize))\n",
    "#     x_base = np.tile(np.array(range(1,im_xsize+1)), (im_ysize,1))\n",
    "    \n",
    "#     # Set weights for a minimum radius around all ROIs to zero as not the whole ROI is drawn\n",
    "#     deadzones_aroundrois = np.ones((im_ysize, im_xsize))\n",
    "#     for roi in range(numrois):\n",
    "#         x_diff = x_base-roi_centroids[roi][0]\n",
    "#         y_diff = y_base-roi_centroids[roi][1]\n",
    "#         dist_from_centroid = np.sqrt(x_diff**2 + y_diff**2)\n",
    "#         temp = np.ones((im_ysize, im_xsize))\n",
    "#         temp[dist_from_centroid<min_neuropil_radius] = 0\n",
    "#         deadzones_aroundrois *= temp\n",
    "    \n",
    "#     allrois_mask *= deadzones_aroundrois.astype(bool)\n",
    "      \n",
    "#     h5 = h5py.File(os.path.join(indir, '%s_spatialweights_%d_%d.h5'%(os.path.splitext(h5file)[0],\n",
    "#                                                                      min_neuropil_radius,\n",
    "#                                                                      neuropil_radius)),\n",
    "#                    'w', libver='latest')\n",
    "    \n",
    "#     output_shape = (numrois, im_ysize, im_xsize)\n",
    "#     h5['/'].create_dataset(\n",
    "#         'spatialweights', output_shape, maxshape=output_shape,\n",
    "#         chunks=(1, output_shape[1], output_shape[2]))\n",
    "    \n",
    "#     for roi in range(numrois):\n",
    "#         x_diff = x_base-roi_centroids[roi][0]\n",
    "#         y_diff = y_base-roi_centroids[roi][1]\n",
    "#         dist_from_centroid = np.sqrt(x_diff**2 + y_diff**2)\n",
    "#         spatialweights = np.exp(-(x_diff**2 + y_diff**2)/neuropil_radius**2)\n",
    "#         spatialweights *= im_ysize*im_xsize/np.sum(spatialweights)\n",
    "        \n",
    "#         # Set weights for a minimum radius around the ROI to zero\n",
    "#         #spatialweights[dist_from_centroid<min_neuropil_radius] = 0\n",
    "#         # Set weights for pixels containing other ROIs to 0\n",
    "#         spatialweights *= allrois_mask\n",
    "#         \"\"\"fig, ax = plt.subplots()\n",
    "#         ax.imshow(spatialweights, cmap='gray')\n",
    "#         raise Exception()\"\"\"\n",
    "#         h5['/spatialweights'][roi, :, :] = spatialweights\n",
    "\n",
    "# def calculate_neuropil_signals(h5filepath, neuropil_radius, min_neuropil_radius):\n",
    "    \n",
    "#     savedir = os.path.dirname(h5filepath)\n",
    "#     h5file = h5py.File(h5filepath,'r') #Read-only \n",
    "#     h5filename = os.path.basename(h5filepath)\n",
    "    \n",
    "#     if os.path.splitext(h5filename)[0][-4:] == '_CH1':\n",
    "#         dual_channel = True\n",
    "#     else:\n",
    "#         dual_channel = False\n",
    "        \n",
    "#     simadir = os.path.splitext(h5filename)[0]+'_mc.sima'\n",
    "    \n",
    "#     correct_sima_paths(h5filepath, savedir, simadir, dual_channel)\n",
    "#     dataset = sima.ImagingDataset.load(os.path.join(savedir, simadir))\n",
    "#     sequence = dataset.sequences[0]\n",
    "#     frame_iter1 = iter(sequence)\n",
    "#     def fill_gaps(framenumber):  #adapted from SIMA source code  \n",
    "#         first_obs = next(frame_iter1)\n",
    "#         for frame in frame_iter1:\n",
    "#             for frame_chan, fobs_chan in zip(frame, first_obs):\n",
    "#                 fobs_chan[np.isnan(fobs_chan)] = frame_chan[np.isnan(fobs_chan)]\n",
    "#             if all(np.all(np.isfinite(chan)) for chan in first_obs):\n",
    "#                 break\n",
    "#         most_recent = [x * np.nan for x in first_obs]\n",
    "#         while True:\n",
    "#             frame = np.array(sequence[framenumber])[0,:,:,:,:]\n",
    "#             for fr_chan, mr_chan in zip(frame, most_recent):\n",
    "#                 mr_chan[np.isfinite(fr_chan)] = fr_chan[np.isfinite(fr_chan)]\n",
    "#             temp=[np.nan_to_num(mr_ch) + np.isnan(mr_ch) * fo_ch\n",
    "#                 for mr_ch, fo_ch in zip(most_recent, first_obs)]\n",
    "#             framenumber = yield np.array(temp)[0,:,:,0]\n",
    "\n",
    "\n",
    "#     fill_gapscaller = fill_gaps(0)\n",
    "#     fill_gapscaller.send(None)\n",
    "    \n",
    "#     roi_centroids, im_shape, roi_polygons = calculate_roi_centroids(savedir)\n",
    "#     roi_masks = calculate_roi_masks(roi_polygons, im_shape)\n",
    "        \n",
    "#     if not os.path.isfile(os.path.join(savedir, '%s_spatialweights_%d_%d.h5'%(os.path.splitext(h5filename)[0],\n",
    "#                                                                            min_neuropil_radius, neuropil_radius))):\n",
    "#         calculate_spatialweights_around_roi(savedir, roi_masks, roi_centroids,\n",
    "#                                             neuropil_radius, min_neuropil_radius, h5filename)\n",
    "#     h5weights = h5py.File(os.path.join(savedir, '%s_spatialweights_%d_%d.h5'%(os.path.splitext(h5filename)[0],\n",
    "#                                                                            min_neuropil_radius, neuropil_radius)), 'r')\n",
    "#     spatialweights = h5weights['/spatialweights']\n",
    "#     \"\"\"for roi in range(1, spatialweights.shape[0]):\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.imshow(spatialweights[roi,:,:], cmap='gray')\n",
    "#         ax.spy(roi_masks[roi], marker='.', markersize=2, color='r')\n",
    "#         ax.grid('off')\n",
    "#         ax.set_xticklabels('')\n",
    "#         ax.set_yticklabels('')\n",
    "#         #fig.savefig(os.path.join(savedir, 'spatialweights_%d_%d.png'%(min_neuropil_radius, neuropil_radius)),\n",
    "#         #            format='png', dpi=300)\n",
    "#         raise Exception()\"\"\"\n",
    "    \n",
    "#     numframes = h5file['/imaging'].shape[0]\n",
    "#     neuropil_signals = np.nan*np.ones((len(roi_masks), numframes))\n",
    "    \n",
    "#     #pb = ProgressBar(numframes)\n",
    "#     start_time = time.time()\n",
    "#     for frame in range(numframes):\n",
    "#         #temp = np.array(dataset.sequences[0][frame])[:,0,:,:,0]\n",
    "#         temp = fill_gapscaller.send(frame)[None,:,:] #this will fill gaps in rows by interpolation\n",
    "#         temp = np.nan_to_num(temp) # Remove nans from the following sum\n",
    "#         neuropil_signals[:, frame] = np.einsum('ijk,ijk->i', spatialweights,\n",
    "#                                                temp)#/np.sum(spatialweights, axis=(1,2))\n",
    "#         # The einsum method above is way faster than multiplying array elements individually\n",
    "#         # The above RHS basically implements a nanmean and averages over x and y pixels\n",
    "        \n",
    "#         #pb.animate(frame+1)\n",
    "#     neuropil_signals /= np.sum(spatialweights, axis=(1,2))[:,None]    \n",
    "#     print 'Took %.1f seconds to analyze %s\\n' % (time.time()-start_time, savedir)\n",
    "#     np.save(os.path.join(savedir, '%s_neuropilsignals_%d_%d.npy'%(os.path.splitext(h5filename)[0],\n",
    "#                                                                min_neuropil_radius,\n",
    "#                                                                neuropil_radius)),\n",
    "#             neuropil_signals)\n",
    "    \n",
    "# def calculate_neuropil_signals_for_session(indir, neuropil_radius=50, min_neuropil_radius=15, beta_neuropil=0.7):\n",
    "    \n",
    "#     print indir\n",
    "#     sys.stdout.flush()\n",
    "#     tempfiles = os.walk(indir).next()[2]\n",
    "\n",
    "#     npyfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'neuropil' not in f and 'temp' not in f]\n",
    "#     if len(npyfiles)>1:\n",
    "#         dendrite_or_soma = 'soma'\n",
    "#         try:\n",
    "#             npyfiles = [f for f in npyfiles if dendrite_or_soma in f]\n",
    "#         except:\n",
    "#             raise Exception('Too many .npy files found. Only keep the extracted signals file')\n",
    "#     npyfile = npyfiles[0]\n",
    "\n",
    "#     h5files = [f for f in tempfiles if os.path.splitext(f)[1]=='.h5' and 'spatialweights' not in f]\n",
    "#     if len(h5files) > 1:\n",
    "#         raise Exception('Too many .h5 files found. Only keep the data file for this session')\n",
    "#     h5file = h5files[0]\n",
    "\n",
    "#     if not os.path.isfile(os.path.join(indir, '%s_neuropilsignals_%d_%d.npy'%(os.path.splitext(h5file)[0],\n",
    "#                                                                               min_neuropil_radius,\n",
    "#                                                                               neuropil_radius))):\n",
    "#         calculate_neuropil_signals(os.path.join(indir, h5file), neuropil_radius, min_neuropil_radius)\n",
    "    \n",
    "#     #raise Exception()\n",
    "    \n",
    "#     h5filepath = os.path.join(indir, h5file)\n",
    "#     signals = np.squeeze(np.load(os.path.join(indir, npyfile)))\n",
    "#     savedir = os.path.dirname(h5filepath)\n",
    "#     h5file = h5py.File(h5filepath,'r') #Read-only \n",
    "#     h5filename = os.path.basename(h5filepath)\n",
    "#     simadir = os.path.splitext(h5filename)[0]+'_mc.sima'\n",
    "#     dataset = sima.ImagingDataset.load(os.path.join(savedir, simadir))\n",
    "#     roi_centroids, im_shape, roi_polygons = calculate_roi_centroids(savedir)\n",
    "#     roi_masks = calculate_roi_masks(roi_polygons, im_shape)\n",
    "#     mean_roi_response = np.nansum(roi_masks*dataset.time_averages[:,:,:,0], axis=(1,2))/np.sum(roi_masks, axis=(1,2))\n",
    "#     #print mean_roi_response\n",
    "        \n",
    "#     signals *= mean_roi_response[:,None]\n",
    "    \n",
    "#     #raise Exception()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     neuropil_signals = np.squeeze(np.load(os.path.join(indir,\n",
    "#                                                        '%s_neuropilsignals_%d_%d.npy'%(os.path.splitext(h5filename)[0],\n",
    "#                                                                                        min_neuropil_radius,\n",
    "#                                                                                        neuropil_radius))))\n",
    "#     #print neuropil_signals\n",
    "#     #raise Exception()\n",
    "#     #neuropil_signals *= (512*494/np.sum(spatialweights, axis=(1,2)))[:,None]\n",
    "    \n",
    "#     beta_rois, skewness_rois = calculate_neuropil_coefficients_for_session(indir, signals, neuropil_signals,\n",
    "#                                                                            neuropil_radius, min_neuropil_radius,\n",
    "#                                                                            beta_neuropil=beta_neuropil)\n",
    "    \n",
    "#     save_neuropil_corrected_signals(indir, signals, neuropil_signals, beta_rois,\n",
    "#                                     neuropil_radius, min_neuropil_radius, h5filename)\n",
    "        \n",
    "# def fit_regression(x, y):\n",
    "#     lm = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "#     x_range = sm.add_constant(np.array([x.min(), x.max()]))\n",
    "#     x_range_pred = lm.predict(x_range)\n",
    "#     return lm.pvalues[1], lm.params[1], x_range[:,1], x_range_pred, lm.rsquared\n",
    "\n",
    "# def calculate_neuropil_coefficients_for_session(indir, signals, neuropil_signals,\n",
    "#                                                 neuropil_radius, min_neuropil_radius, beta_neuropil=None):\n",
    "#     skewness_rois = np.nan*np.ones((signals.shape[0],2)) #before, after correction\n",
    "#     if beta_neuropil is None:\n",
    "#         beta_rois = np.nan*np.ones((signals.shape[0],))\n",
    "#         for roi in range(signals.shape[0]):        \n",
    "#             def f(beta):\n",
    "#                 temp1 = signals[roi]-beta*neuropil_signals[roi]\n",
    "#                 temp2 = neuropil_signals[roi]\n",
    "#                 _,_,_,_,temp3 = fit_regression(temp1, temp2)\n",
    "#                 return temp3\n",
    "#             #beta_rois[roi] = optimize.brent(f)\n",
    "#             beta_rois[roi] = optimize.minimize(f, [1], bounds=((0,None),)).x\n",
    "#             skewness_rois[roi,0] = stats.skew(signals[roi])\n",
    "#             temp1 = signals[roi]-beta_rois[roi]*neuropil_signals[roi]\n",
    "#             temp2 = neuropil_signals[roi]\n",
    "#             _,temp4,_,_,temp3 = fit_regression(temp1, temp2)\n",
    "#             skewness_rois[roi,1] = np.sqrt(temp3)* np.sign(temp4)\n",
    "#             \"\"\"print beta_rois[roi]\n",
    "#             fig, ax = plt.subplots()\n",
    "#             ax.plot(signals[roi], 'b')\n",
    "#             ax.plot(neuropil_signals[roi], 'r')\n",
    "#             ax.plot(beta_rois[roi]*neuropil_signals[roi], 'g')\n",
    "#             raise Exception()\"\"\"\n",
    "#         #print beta_rois\n",
    "#         fig, axs = plt.subplots(1,2,figsize=(8,4))\n",
    "#         CDFplot(beta_rois, axs[0])\n",
    "#         CDFplot(skewness_rois[:,1], axs[1])\n",
    "#         #raise Exception()\n",
    "#         return beta_rois, skewness_rois\n",
    "#     else:\n",
    "#         skewness_rois[:,0] = stats.skew(signals, axis=1)\n",
    "#         skewness_rois[:,1] = stats.skew(signals-beta_neuropil*neuropil_signals, axis=1)\n",
    "#         \"\"\"tempslope = np.nan*np.ones((signals.shape[0],))\n",
    "#         corrected_signals = signals-beta_neuropil*neuropil_signals\n",
    "#         for roi in range(signals.shape[0]):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             ax.plot(signals[roi,:1000], 'b', alpha=0.5, label='uncorrected signal')\n",
    "#             ax.plot(corrected_signals[roi,:1000], 'b', label='corrected signal')\n",
    "#             ax.plot(neuropil_signals[roi,:1000], '--r', label='raw neuropil signal')\n",
    "#             ax.plot(beta_neuropil*neuropil_signals[roi,:1000], 'r', label='scaled neuropil signal') \n",
    "#             ax.set_xlabel('Frame number (5Hz)')\n",
    "#             ax.set_ylabel('Signal amplitude')\n",
    "#             ax.legend(loc='upper right')\n",
    "#             fig.savefig(os.path.join(indir, 'neuropil', 'roi%d.png'%roi))\n",
    "#             fig.clf()\"\"\"\n",
    "#             #tempslope[roi] = sm.OLS(corrected_signals[roi,:], sm.add_constant(neuropil_signals[roi,:])).fit().params[1]\n",
    "#         #raise Exception()\n",
    "#         \"\"\"fig, ax = plt.subplots(figsize=(4,4))\n",
    "#         CDFplot(tempslope, ax=ax)\n",
    "#         ax.set_xlabel('Correlation coefficient between\\ncorrected signal and neuropil signal')\n",
    "#         ax.set_ylabel('Cumulative probability')\n",
    "#         ax.axvline(0,color='k',linestyle='--')\n",
    "#         fig.subplots_adjust(left=0.15)\n",
    "#         fig.subplots_adjust(bottom=0.15)\n",
    "#         fig.subplots_adjust(top=0.98)\n",
    "#         fig.savefig(os.path.join(indir, 'correlationdistribution_%d_%d_beta_%.1f.png'%(min_neuropil_radius,\n",
    "#                                                                                       neuropil_radius,\n",
    "#                                                                                       beta_neuropil)),\n",
    "#                    format='png', dpi=300)\"\"\"\n",
    "#         #raise Exception()\n",
    "#         return beta_neuropil, skewness_rois\n",
    "\n",
    "# def save_neuropil_corrected_signals(indir, signals, neuropil_signals, beta_rois,\n",
    "#                                     neuropil_radius, min_neuropil_radius, h5file):\n",
    "#     if isinstance(beta_rois, np.ndarray):\n",
    "#         corrected_signals = signals-beta_rois[:,None]*neuropil_signals\n",
    "#         np.save(os.path.join(indir, '%s_neuropil_corrected_signals_%d_%d_betacalculated.npy'%(os.path.splitext(h5file)[0],\n",
    "#                                                                                            min_neuropil_radius,\n",
    "#                                                                                            neuropil_radius)),\n",
    "#                 corrected_signals)\n",
    "#     else:\n",
    "#         corrected_signals = signals-beta_rois*neuropil_signals\n",
    "#         np.save(os.path.join(indir, '%s_neuropil_corrected_signals_%d_%d_beta_%.1f.npy'%(os.path.splitext(h5file)[0],\n",
    "#                                                                                          min_neuropil_radius,\n",
    "#                                                                                          neuropil_radius,\n",
    "#                                                                                          beta_rois)),\n",
    "#                 corrected_signals)\n",
    "    \n",
    "# def CDFplot(x, ax, color=None, label='', linetype='-'):\n",
    "#     x = np.squeeze(np.array(x))\n",
    "#     ix=np.argsort(x)\n",
    "#     ax.plot(x[ix], ECDF(x)(x)[ix], linetype, color=color, label=label)\n",
    "#     return ax\n",
    "\n",
    "# calculate_neuropil_signals_for_session(os.path.join(basedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otisl\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "###THIS IS FOR SIGNAL AVERAGING, ONLY RUN IF THE FRAME RATE WAS NOT 5HZ (6 FRAME AVERAGING FOR ROUNDTRIP RESONANT SCANNING)\n",
    "\n",
    "###UNCOMMENT IF USING RAW SIGNALS\n",
    "corrected_signals = np.load(os.path.join(basedir, filename+'_extractedsignals_raw.npy'))\n",
    "extension = '_raw_averaged_signals.npy'\n",
    "\n",
    "###UNCOMMENT IF USING NEUROPIL CORRECTED SIGNALS\n",
    "#corrected_signals = np.load(os.path.join(basedir, filename+'_neuropil_corrected_signals_15_50_beta_0.7.npy'))\n",
    "#extension = '_corrected_averaged_signals.npy'\n",
    "\n",
    "corrected_signals = np.squeeze(corrected_signals)\n",
    "numrois = corrected_signals.shape[0]\n",
    "numframes = corrected_signals.shape[1]\n",
    "\n",
    "averaging = 4  #number of frames that you want to average, if frame rate was 30hz, averaging=4 will give you 7.5hz frame rate\n",
    "numframesforslicing = (numframes/averaging)\n",
    "                        \n",
    "#this reshapes the original, unaveraged dataset into a larger array that can be averaged by a factor of 6\n",
    "extractedsignals = np.nan*np.ones((numrois,660000))   #this initializes a larger array that original array will fit into, allowing for averaging\n",
    "extractedsignals[:numrois, :numframes] = corrected_signals #fit original array into extractedsignals nan array\n",
    "extractedsignals=extractedsignals.reshape(numrois,-1,averaging) #reshape axis 2 (signals) into 2 dimensions (of 6)\n",
    "extractedsignals=np.nanmean(extractedsignals,axis=2) #average axis 2 (signals)\n",
    "\n",
    "corrected_averaged_signals = np.nan*np.ones((numrois, numframesforslicing))\n",
    "corrected_averaged_signals = extractedsignals[:, :numframesforslicing]\n",
    "\n",
    "np.save(os.path.join(basedir, filename+extension), corrected_averaged_signals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
