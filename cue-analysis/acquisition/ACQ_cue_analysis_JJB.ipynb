{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Josh Boquiren\n",
    "OTIS Lab MUSC\n",
    "5.23.2023\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Notes:\n",
    "- this code relies on the existence of previously made .npy files; if no .npy files exist,\n",
    "  please refer to one of the other programs where the preprocessing portion exists\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "#data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#directory and file manager\n",
    "import os\n",
    "\n",
    "#statistics\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import roc_auc_score as auROC\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize directories\n",
    "\n",
    "population = 'ACQUISITION'\n",
    "\n",
    "user = 'jboqu'\n",
    "#user = 'OtisLab'\n",
    "\n",
    "basedir = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data'%(user)\n",
    "\n",
    "earlybasedir = os.path.join(basedir, 'EarlyAcq')\n",
    "middlebasedir = os.path.join(basedir, 'MidAcq')\n",
    "latebasedir = os.path.join(basedir, 'LateAcq')\n",
    "\n",
    "models = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\universal_models'%(user)\n",
    "results = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\acquisition\\results'%(user)\n",
    "\n",
    "#cluster list files\n",
    "early_newlabels = np.load(os.path.join(earlybasedir, 'cluster_list_per_session_Acquisition.npy')) #put clustering files in a folder to loop through\n",
    "middle_newlabels = np.load(os.path.join(middlebasedir, 'cluster_list_per_session_Acquisition.npy'))\n",
    "late_newlabels = np.load(os.path.join(latebasedir, 'cluster_list_per_session_Acquisition.npy'))\n",
    "\n",
    "#for later plot titles\n",
    "plot_titles = ['EARLY', 'MIDDLE', 'LATE']\n",
    "population_title = \"ACQ\"\n",
    "\n",
    "#animals of interest\n",
    "early_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L2', 'ER-L1',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa5','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]  \n",
    "middle_animals_of_interest = [\n",
    "    'CTL1',\n",
    "\n",
    "    'ER-L1', #FIXME - only 1 inactive press frame recorded\n",
    "    'ER-L2',\n",
    "\n",
    "    'IG-19',\n",
    "\n",
    "    'LCDD-PGa1', #FIXME - only 1 inactive press frame recorded\n",
    "    'LCDD-PGa3',\n",
    "    'LCDD-PGa4',\n",
    "    'LCDD-PGa5',\n",
    "    'LCDD-PGa6',\n",
    "\n",
    "    'LCDD-PGa-T1',\n",
    "    'LCDD-PGa-T2', #FIXME - only 1 inactive press frame recorded\n",
    "    'LCDD-PGa-T3',\n",
    "    'LCDD-PGa-T4',\n",
    "    'LCDD-PGa-T5',\n",
    "\n",
    "    'PGa-T1',\n",
    "    'PGa-T2',\n",
    "    'PGa-T3'\n",
    "    ]  \n",
    "late_animals_of_interest = [\n",
    "    'CTL1',\n",
    "\n",
    "    'ER-L1',\n",
    "    'ER-L2',\n",
    "\n",
    "    'IG-19',\n",
    "\n",
    "    'LCDD-PGa1',\n",
    "    'LCDD-PGa3', \n",
    "    'LCDD-PGa4',\n",
    "    'LCDD-PGa5',\n",
    "    'LCDD-PGa6',\n",
    "\n",
    "    'LCDD-PGa-T1',\n",
    "    'LCDD-PGa-T2',\n",
    "    'LCDD-PGa-T3',\n",
    "    'LCDD-PGa-T4',\n",
    "    'LCDD-PGa-T5',\n",
    "\n",
    "    'PGa-T1',\n",
    "    'PGa-T2',\n",
    "    'PGa-T3' #FIXME\n",
    "    ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame rate: 8.333325\n",
      "Averaged frame rate: 8.333325\n",
      "Prewindow size: 83\n",
      "Window size: 190\n",
      "Postwindow size: 107\n",
      "No Cell Tracking\n"
     ]
    }
   ],
   "source": [
    "#frame rate variables\n",
    "frameaveraging = 4\n",
    "timebetweenframes = 33.3333\n",
    "framerate = 30\n",
    "framerate = timebetweenframes/frameaveraging #raw frame rate\n",
    "averagedframerate = timebetweenframes/frameaveraging #averaged frame rate\n",
    "print('Frame rate:', framerate)\n",
    "print('Averaged frame rate:', averagedframerate)\n",
    "\n",
    "#window size variables\n",
    "pre_window_size = int(10*framerate) #How many frames per trial before origin to be plotted?\n",
    "window_size =  int((pre_window_size*2)+(3*framerate)) #How many frames do you want to plot around the origin?\n",
    "post_window_size = window_size - pre_window_size\n",
    "baselinefirstframe = 0\n",
    "baselinelastframe = int(1*framerate)\n",
    "infusionframe = int(pre_window_size+(3*framerate))\n",
    "print('Prewindow size:', pre_window_size)\n",
    "print('Window size:', window_size)\n",
    "print('Postwindow size:', post_window_size)\n",
    "\n",
    "#set cell tracking\n",
    "tracking = 'No' ### 'Yes' or 'No'\n",
    "sorting = 'Yes' ### 'Yes' or 'No'\n",
    "sorttoearly = 'No' ###'Yes' or 'No'; This is for sorting, but align to early data. 'Sorting' must also be Yes\n",
    "csv_id_for_tracking = 'CUE-DRUG-TMT'\n",
    "\n",
    "#tracking\n",
    "if tracking == 'Yes':\n",
    "    population_active_tracked_early = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_middle = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_late = np.nan*np.ones((1,window_size))\n",
    "    print ('Cell Tracking')\n",
    "else:\n",
    "    print ('No Cell Tracking')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded behavior data.\n"
     ]
    }
   ],
   "source": [
    "#method for fixing dropped frames\n",
    "def fix_any_dropped_frames(frame_timestamps):\n",
    "    first_frame = np.array([0])\n",
    "    last_frame = np.array([int(np.max(frame_timestamps)+(500*timebetweenframes))])\n",
    "    frame_index_temp = np.concatenate((first_frame,frame_timestamps, last_frame)) ###adds frame to timepoint '0' and an extra 500 frames at end\n",
    "    frames_missed = [] ###creates empty list for us to add timestamps for missed frames\n",
    "    for i in range(len(frame_index_temp)-1): ###iterates through each collected frame\n",
    "            numframes_missed = int(np.round((frame_index_temp[i+1]-frame_index_temp[i])\\\n",
    "                /timebetweenframes)-1) ### number of missed frames per frame interval\n",
    "            if numframes_missed > 0: \n",
    "                for j in range(numframes_missed):\n",
    "                    frame_missed = np.array([frame_index_temp[i] + (int(timebetweenframes * (j+1)))])\n",
    "                    frames_missed = np.concatenate((frames_missed, frame_missed))\n",
    "    corrected_frame_index = np.array(sorted(np.concatenate((frame_index_temp, frames_missed))))\n",
    "    return corrected_frame_index\n",
    "\n",
    "#method for fixing assumed frames\n",
    "def fix_assumed_frames(frames):\n",
    "    dropped_frames = []\n",
    "    diff_frames = np.diff(frames)\n",
    "    inter_frame_interval = 33\n",
    "    frame_drop_idx = np.where(diff_frames>1.5*inter_frame_interval)[0]\n",
    "    for idx in frame_drop_idx:\n",
    "        numframesdropped = int(np.round((frames[idx+1]-frames[idx])/(inter_frame_interval+0.0))-1)\n",
    "        temp = [frames[idx]+a*inter_frame_interval for a in range(1,numframesdropped+1)]\n",
    "        dropped_frames.extend(temp)\n",
    "    corrected_frames = np.sort(np.concatenate((frames, np.array(dropped_frames))))\n",
    "    return corrected_frames\n",
    "\n",
    "#generate behavior data\n",
    "try:\n",
    "    assumed_frames = np.load(os.path.join(models, 'assumed_frames.npy'))\n",
    "    assumed_frame_timestamps = np.load(os.path.join(models, 'assumed_frame_timestamps.npy'))\n",
    "    print(\"Loaded behavior data.\")\n",
    "except:\n",
    "    #load in data\n",
    "    behaviordata_noframes = sio.loadmat(r\"\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data\\Spreadsheets\\matfile_noframes_3.mat\"%(user))\n",
    "    eventlog_noframes = np.squeeze(behaviordata_noframes['eventlog'])\n",
    "\n",
    "    #parse desired data\n",
    "    max_of_eventlog_noframes = max(eventlog_noframes[:,1]) #all rows, second column\n",
    "    length_of_eventlog_noframes = len(eventlog_noframes[:,1])\n",
    "    x = np.vstack((eventlog_noframes, eventlog_noframes, eventlog_noframes))\n",
    "    x[length_of_eventlog_noframes:,1]= x[length_of_eventlog_noframes:,1]+max_of_eventlog_noframes\n",
    "    x[length_of_eventlog_noframes*2:,1]= x[length_of_eventlog_noframes*2:,1]+(2*max_of_eventlog_noframes)\n",
    "    eventlog_noframes = x\n",
    "\n",
    "    assumed_frames = fix_any_dropped_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    assumed_frame_timestamps = fix_assumed_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "\n",
    "    np.save(os.path.join(models, 'assumed_frames'), assumed_frames)\n",
    "    np.save(os.path.join(models, 'assumed_frame_timestamps'), assumed_frame_timestamps)\n",
    "    print(\"Behavior data processed and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def fit_regression(x, y):\n",
    "    lm = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    x_range = sm.add_constant(np.array([x.min(), x.max()]))\n",
    "    x_range_pred = lm.predict(x_range)\n",
    "    return lm.pvalues[1], lm.params[1], x_range[:,1], x_range_pred, lm.rsquared\n",
    "\n",
    "def CDFplot(x, ax, color=None, label='', linetype='-'):\n",
    "    x = np.array(x)\n",
    "    ix=np.argsort(x)\n",
    "    ax.plot(x[ix], ECDF(x)(x)[ix], linetype, color=color, label=label)\n",
    "    return ax\n",
    "\n",
    "def fit_regression_and_plot(x, y, ax, plot_label='', color='k', markersize=3):\n",
    "    #linetype is a string like 'bo'\n",
    "    pvalue, slope, temp, temppred, R2 = fit_regression(x, y)    \n",
    "    ax.scatter(x, y, color=color, label='%s p=%.3f\\nR$^2$=%.3f'% (plot_label, pvalue, R2), s=markersize)\n",
    "    ax.plot(temp, temppred, color=color)\n",
    "    return ax, slope, pvalue, R2\n",
    "\n",
    "def ismembertol(x, y, tol=1E-6):\n",
    "    # Are elements of x in y within tolerance of tol?\n",
    "    # x and y must be 1d numpy arrays\n",
    "    sortx = np.sort(x)\n",
    "    orderofx = np.argsort(x)\n",
    "    sorty = np.sort(y)\n",
    "    current_y_idx = 0\n",
    "    result = np.nan*np.zeros(x.shape)\n",
    "    for i, elt in enumerate(sortx):\n",
    "        temp = sorty[current_y_idx:]\n",
    "        if np.any(np.abs(temp-elt)<=tol):\n",
    "            result[orderofx[i]]=1\n",
    "        else:\n",
    "            result[orderofx[i]]=0\n",
    "        temp = np.argwhere(sorty>elt)\n",
    "        if temp.size>0:\n",
    "            current_y_idx = temp[0][0]\n",
    "    return result\n",
    "\n",
    "def mkdir_p(path):\n",
    "    #makes a new directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise \n",
    "            \n",
    "def framenumberforevent(event, frame_timestamps):\n",
    "    framenumber = np.nan*np.zeros(event.shape)\n",
    "    for ie, e in enumerate(event):\n",
    "        #print('     e:', e)\n",
    "        if np.isnan(e):\n",
    "            framenumber[ie] = np.nan\n",
    "        else:\n",
    "            temp = np.nonzero(frame_timestamps<=e)[0]\n",
    "            if temp.shape[0]>0:\n",
    "                framenumber[ie] = np.nonzero(frame_timestamps<=e)[0][-1]\n",
    "            else:\n",
    "                framenumber[ie] = 0\n",
    "    return framenumber\n",
    "\n",
    "def calculate_num_licks_for_each_frame(framenumberforlicks, numframes):\n",
    "    numlicksperframe = np.nan*np.ones((numframes,))\n",
    "    for i in range(numframes):\n",
    "        numlicksperframe[i] = np.sum(framenumberforlicks==i)\n",
    "    return numlicksperframe\n",
    "\n",
    "def calculate_auROC(x,y,offset_to_zero=True):\n",
    "    U, p = stats.mannwhitneyu(x,y)\n",
    "    labels = np.concatenate((np.ones(x.shape), np.zeros(y.shape)))\n",
    "    data = np.concatenate((x,y))\n",
    "    A = auROC(labels, data)\n",
    "    if offset_to_zero:\n",
    "        return (2*(A-0.5), p)\n",
    "    else:\n",
    "        return (A, p)\n",
    "    \n",
    "def Benjamini_Hochberg_correction(vector_of_pvals,\n",
    "                                  alpha = 0.05):\n",
    "    # This function ipltements the BH FDR correction\n",
    "    \n",
    "    # Parameters:\n",
    "    # Vector of p values from the different tests\n",
    "    # alpha:significance level\n",
    "    \n",
    "    # Returns: Corrected p values. All the p values that are above the FDR threshold are set to 1. \n",
    "    #          Remaining p values are unchanged.\n",
    "    \n",
    "    sortedpvals = np.sort(vector_of_pvals)\n",
    "    orderofpvals = np.argsort(vector_of_pvals)\n",
    "    m = sortedpvals[np.isfinite(sortedpvals)].shape[0] #Total number of hypotheses\n",
    "    for i in range(m):\n",
    "        if sortedpvals[i] > (i+1)*alpha/m:\n",
    "            k = i\n",
    "            break\n",
    "        elif i == m-1:\n",
    "            k = m-1\n",
    "        \n",
    "    correctedpvals = np.copy(vector_of_pvals)\n",
    "    correctedpvals[orderofpvals[k:]] = 1\n",
    "    correctedpvals[np.isnan(vector_of_pvals)] = np.nan\n",
    "    return correctedpvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for animal analysis\n",
    "def analyze_single_session(indir, window_size, pre_window_size):    \n",
    "    tempfiles = next(os.walk(indir))[2]\n",
    "    npyfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "        and 'extractedsignals_raw' in f]\n",
    "    matfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat']\n",
    "\n",
    "    if len(npyfiles) > 1:\n",
    "        npyfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "            and 'extractedsignals_raw' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        if npyfile[0][0]!='nan':\n",
    "            npyfile = npyfile [0]\n",
    "        matfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' \n",
    "            and not 'results' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        matfile = matfile [0]\n",
    "    else:\n",
    "        npyfile = npyfiles[0]\n",
    "        matfile = matfiles[0]\n",
    "    \n",
    "    signals = np.squeeze(np.load(os.path.join(indir, npyfile)))\n",
    "    numneurons = signals.shape[0] \n",
    "   \n",
    "    behaviordata = sio.loadmat(os.path.join(indir, matfile))\n",
    "    eventlog = np.squeeze(behaviordata['eventlog'])\n",
    "    licks = np.squeeze(behaviordata['licks'])\n",
    "    lastframe_timestamp_part1 = np.max(eventlog)\n",
    "    \n",
    "    if len(npyfiles) > 1:\n",
    "        npyfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part2' in f]\n",
    "        matfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part2' in f and not 'results' in f]\n",
    "        npyfile2 = npyfiles2[0]\n",
    "        matfile2 = matfiles2[0]\n",
    "        signals2 = np.squeeze(np.load(os.path.join(indir, npyfile2))) \n",
    "        if signals2[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals2))\n",
    "        behaviordata2 = sio.loadmat(os.path.join(indir, matfile2))\n",
    "        eventlog2 = np.squeeze(behaviordata2['eventlog'])\n",
    "        eventlog2[:,1] = eventlog2[:,1]+lastframe_timestamp_part1  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog2))\n",
    "        lastframe_timestamp_part2 = np.max(eventlog)        \n",
    "        licks2 = np.squeeze(behaviordata2['licks'])\n",
    "        licks2 = licks2+lastframe_timestamp_part1\n",
    "        licks = np.concatenate ([licks, licks2])\n",
    "    if len(npyfiles) > 2:\n",
    "        npyfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part3' in f]\n",
    "        matfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part3' in f and not 'results' in f]\n",
    "        npyfile3 = npyfiles3[0]\n",
    "        matfile3 = matfiles3[0]\n",
    "        signals3 = np.squeeze(np.load(os.path.join(indir, npyfile3))) \n",
    "        if signals3[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals3))\n",
    "        behaviordata3 = sio.loadmat(os.path.join(indir, matfile3))\n",
    "        eventlog3 = np.squeeze(behaviordata3['eventlog'])\n",
    "        eventlog3[:,1] = eventlog3[:,1]+lastframe_timestamp_part2  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog3))\n",
    "        lastframe_timestamp_part3 = np.max(eventlog)\n",
    "        licks3 = np.squeeze(behaviordata3['licks'])\n",
    "        licks3 = licks3+lastframe_timestamp_part2\n",
    "        licks = np.concatenate ([licks, licks3])\n",
    "    if len(npyfiles) > 3:\n",
    "        npyfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw' and 'part4' in f]\n",
    "        matfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part4' in f and not 'results' in f]\n",
    "        npyfile4 = npyfiles4[0]\n",
    "        matfile4 = matfiles4[0]\n",
    "        signals4 = np.squeeze(np.load(os.path.join(indir, npyfile4))) \n",
    "        if signals4[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals4))\n",
    "        behaviordata4 = sio.loadmat(os.path.join(indir, matfile4))\n",
    "        eventlog4 = np.squeeze(behaviordata4['eventlog'])\n",
    "        eventlog4[:,1] = eventlog4[:,1]+lastframe_timestamp_part3  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog4))\n",
    "        lastframe_timestamp_part4 = np.max(eventlog)\n",
    "        licks4 = np.squeeze(behaviordata4['licks'])\n",
    "        licks4 = licks4+lastframe_timestamp_part3\n",
    "        licks = np.concatenate ([licks, licks4])\n",
    "    #pulling data from eventlog\n",
    "    activelever = eventlog[eventlog[:,0]==22,1]\n",
    "    activelevertimeout = eventlog[eventlog[:,0]==222,1]\n",
    "    inactivelever = eventlog[eventlog[:,0]==21,1]\n",
    "    inactivelevertimeout = eventlog[eventlog[:,0]==212,1]\n",
    "    cues = eventlog[eventlog[:,0]==7,1]\n",
    "    infusions = eventlog[eventlog[:,0]==4,1]    \n",
    "\n",
    "    signals /= np.mean(signals, axis=1)[:, None]\n",
    "    signalsT = signals.T\n",
    "    \n",
    "    ###IF YOUR CODE LACKS FRAME INPUTS, WE CAN ATTEMPT TO PREDICT FRAME TIMING BY USING PREVIOUS FRAME TIMESTAMPS\n",
    "    if animal == 'CTL1' or animal == 'ER-L1' or animal == 'ER-L2' or animal == 'IG-19' or animal == 'IG-28' or animal == 'PGa-T1' or animal == 'XYZ':\n",
    "        frame_timestamps = assumed_frame_timestamps ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    else:\n",
    "        frame_timestamps = fix_any_dropped_frames(eventlog[eventlog[:,0]==9,1]) \n",
    "    frame_timestamps = frame_timestamps[::frameaveraging] ###incorporates averaging into timestamp array\n",
    "    \n",
    "    ###DISCARDS BEHAVIORAL EVENTS THAT WERE NOT FULLY MONITORED WITH IMAGING\n",
    "    if signals.shape[1] > frame_timestamps.shape[0]:\n",
    "        signals = signals[:,:frame_timestamps.shape[0]-1] ###cuts signals so it's not longer than the frame timestamps\n",
    "        \n",
    "    final_frame_timestamp = frame_timestamps[signals.shape[1]] #This is the timestamp of the final frame in milliseconds\n",
    "    #FIXME initialize flags here\n",
    "    activelever = activelever[activelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    activelevertimeout = activelevertimeout[activelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelever = inactivelever[inactivelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelevertimeout = inactivelevertimeout[inactivelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    \n",
    "    active_flags_dict = []\n",
    "    for press in activelever:\n",
    "        active_flags_dict.append({'Timestamp': press, 'Flag': 'cue'})\n",
    "    for press in activelevertimeout:\n",
    "        active_flags_dict.append({'Timestamp': press, 'Flag': 'no cue'})\n",
    "    active_flags_df = pd.DataFrame(active_flags_dict)\n",
    "\n",
    "    seconds_monitored = int(signals.shape[1]/averagedframerate) ###seconds monitored by 2p imaging\n",
    "    seconds_behavior = int(max(activelever/1000)) ###final seconds to be monitored for behavior\n",
    "\n",
    "    if seconds_monitored < seconds_behavior: #calculates last fully-monitored active lever press with 2p recording\n",
    "        included_trials = []\n",
    "        discarded_trials=[]\n",
    "        for i in range(len(activelever)):\n",
    "            if activelever[i]/1000<seconds_monitored:\n",
    "                included_trials=np.append(included_trials, activelever[i])\n",
    "            else:\n",
    "                discarded_trials=np.append(discarded_trials,activelever[i]) #FIXME why is this even here?\n",
    "        activelever=included_trials \n",
    "    #combines all presses\n",
    "    activeleverall = np.hstack((activelever, activelevertimeout))\n",
    "    inactiveleverall = np.hstack((inactivelever, inactivelevertimeout))\n",
    "\n",
    "    #FIXME\n",
    "    if activeleverall.shape[0] < 6:\n",
    "        activeleverall =np.array([])\n",
    "    if inactiveleverall.shape[0] < 6:\n",
    "        inactiveleverall = np.array([])\n",
    "\n",
    "    #method for calculating aligned data\n",
    "    def calculate_aligneddata_forevent(data, frame_after_event): #FIXME\n",
    "        framenumberfor_eventofinterest = np.squeeze(framenumberforevent(frame_after_event, frame_timestamps))\n",
    "        numtrials = framenumberfor_eventofinterest.shape[0]\n",
    "        if data.size==signals.size:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size,numneurons])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size,numneurons])###CHANGED ON AUGUST 20 2021\n",
    "        else:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size])\n",
    "        temp = data\n",
    "        prevendindex = 0\n",
    "        for i in range(numtrials):  ###CHANGED THIS SECTION ON AUGUST 20 2021\n",
    "            tempindex = framenumberfor_eventofinterest[i]\n",
    "            if np.isfinite(tempindex):\n",
    "                tempindex = int(tempindex)\n",
    "                tempstartindex = np.amin([pre_window_size, tempindex]).astype(int)\n",
    "                startindex = np.amin([tempstartindex, tempindex-prevendindex]).astype(int)\n",
    "                tempendindex = np.amin([len(frame_timestamps)-tempindex, post_window_size])\n",
    "                if i<(numtrials-1) and np.isfinite(framenumberfor_eventofinterest[i+1]):\n",
    "                    endindex = tempendindex\n",
    "                else:\n",
    "                    endindex = tempendindex\n",
    "                    prevendindex = tempindex+endindex\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex,:] = temp[tempindex-startindex:tempindex+endindex,:]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex,:] = temp[tempindex-tempstartindex:tempindex+endindex,:]\n",
    "                else: \n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex] = temp[tempindex-startindex:tempindex+endindex]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex] = temp[tempindex-tempstartindex:tempindex+endindex]\n",
    "            else:\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    align_to_plot[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                    align[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                else:\n",
    "                    align_to_plot[i,:] = np.nan*np.ones((window_size))\n",
    "                    align[i,:] = np.nan*np.ones((window_size))\n",
    "        if temp.shape[0]!=temp.size:         \n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]     \n",
    "        else:\n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]\n",
    "        return align, align_to_plot, framenumberfor_eventofinterest\n",
    "    \n",
    "    align_activelever, align_to_plot_activelever, framenumberfor_frameafter_activelever = \\\n",
    "        calculate_aligneddata_forevent(signalsT, activeleverall)  \n",
    "    populationdata_activelever = np.nanmean(align_activelever, axis=0).T-1\n",
    "\n",
    "    align_inactivelever, align_to_plot_inactivelever, framenumberfor_frameafter_inactivelever = \\\n",
    "        calculate_aligneddata_forevent(signalsT, inactiveleverall) #FIXME\n",
    "    populationdata_inactivelever = np.nanmean(align_inactivelever, axis=0).T-1\n",
    "    \n",
    "    for i in range(signals.shape[0]):\n",
    "        if np.isnan(np.mean(signals[i,:])):\n",
    "            print(animal, fov, 'IMAGE J ROI.ZIP CELL NUMBER %s HAS NaNs AND SHOULD BE CHANGED'%(i+1))\n",
    "        \n",
    "    return populationdata_activelever, populationdata_inactivelever, align_activelever, align_inactivelever, framerate, active_flags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> CTL1\n",
      "Early excluded animals: []\n"
     ]
    }
   ],
   "source": [
    "#FIXME TEST DATA\n",
    "\n",
    "test_animals = early_animals_of_interest[:1]\n",
    "\n",
    "\n",
    "#Early population\n",
    "excluded = []\n",
    "for animal in test_animals:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        for fov in sorted(FOVs):\n",
    "            try:\n",
    "                activeLever, inactiveLever, alignedActiveLever, alignedInactiveLever, framerate, cueFlags = analyze_single_session(\n",
    "                    #analysis parameters\n",
    "                    os.path.join(earlybasedir, animal, fov), \n",
    "                    window_size, \n",
    "                    pre_window_size\n",
    "                    )\n",
    "                cueFlags.to_csv(os.path.join(earlybasedir, animal, fov, 'active_flags.csv'), index=False)\n",
    "            except Exception as e:\n",
    "                print('***ERROR:', e, '***')\n",
    "                excluded.append(animal)\n",
    "print('Early excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362926</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>854689</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882559</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3221116</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3279653</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6105130</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7385406</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7930088</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8209172</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9065859</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3284566</td>\n",
       "      <td>no cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9066167</td>\n",
       "      <td>no cue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp    Flag\n",
       "0      362926     cue\n",
       "1      854689     cue\n",
       "2     1882559     cue\n",
       "3     3221116     cue\n",
       "4     3279653     cue\n",
       "5     6105130     cue\n",
       "6     7385406     cue\n",
       "7     7930088     cue\n",
       "8     8209172     cue\n",
       "9     9065859     cue\n",
       "10    3284566  no cue\n",
       "11    9066167  no cue"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FIXME TEST DATA\n",
    "\n",
    "df = pd.read_csv(os.path.join(earlybasedir, 'CTL1', 'FOV1', 'active_flags.csv'))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making cue flag files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> CTL1\n",
      ">>> ER-L2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OtisLab\\.conda\\envs\\josh\\lib\\site-packages\\ipykernel_launcher.py:189: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ER-L1\n",
      ">>> IG-19\n",
      ">>> LCDD-PGa1\n",
      ">>> LCDD-PGa3\n",
      ">>> LCDD-PGa4\n",
      ">>> LCDD-PGa5\n",
      ">>> LCDD-PGa6\n",
      ">>> LCDD-PGa-T1\n",
      ">>> LCDD-PGa-T2\n",
      ">>> LCDD-PGa-T3\n",
      ">>> LCDD-PGa-T4\n",
      ">>> LCDD-PGa-T5\n",
      ">>> PGa-T1\n",
      ">>> PGa-T2\n",
      ">>> PGa-T3\n",
      "Early excluded animals: []\n"
     ]
    }
   ],
   "source": [
    "#Early population\n",
    "excluded = []\n",
    "for animal in early_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            activeLever, inactiveLever, alignedActiveLever, alignedInactiveLever, framerate, cueFlags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(earlybasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            cueFlags.to_csv(os.path.join(earlybasedir, animal, fov, 'active_flags.csv'), index=False)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Early excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> CTL1\n",
      ">>> ER-L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OtisLab\\.conda\\envs\\josh\\lib\\site-packages\\ipykernel_launcher.py:189: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ER-L2\n",
      ">>> IG-19\n",
      ">>> LCDD-PGa1\n",
      ">>> LCDD-PGa3\n",
      ">>> LCDD-PGa4\n",
      ">>> LCDD-PGa5\n",
      ">>> LCDD-PGa6\n",
      ">>> LCDD-PGa-T1\n",
      ">>> LCDD-PGa-T2\n",
      ">>> LCDD-PGa-T3\n",
      ">>> LCDD-PGa-T4\n",
      ">>> LCDD-PGa-T5\n",
      ">>> PGa-T1\n",
      ">>> PGa-T2\n",
      ">>> PGa-T3\n",
      "Middle excluded animals: []\n"
     ]
    }
   ],
   "source": [
    "#Middle population\n",
    "excluded = []\n",
    "for animal in middle_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(middlebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            activeLever, inactiveLever, alignedActiveLever, alignedInactiveLever, framerate, cueFlags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(middlebasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            cueFlags.to_csv(os.path.join(middlebasedir, animal, fov, 'active_flags.csv'), index=False)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Middle excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> CTL1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OtisLab\\.conda\\envs\\josh\\lib\\site-packages\\ipykernel_launcher.py:189: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ER-L1\n",
      ">>> ER-L2\n",
      ">>> IG-19\n",
      ">>> LCDD-PGa1\n",
      ">>> LCDD-PGa3\n",
      ">>> LCDD-PGa4\n",
      ">>> LCDD-PGa5\n",
      ">>> LCDD-PGa6\n",
      ">>> LCDD-PGa-T1\n",
      ">>> LCDD-PGa-T2\n",
      ">>> LCDD-PGa-T3\n",
      ">>> LCDD-PGa-T4\n",
      ">>> LCDD-PGa-T5\n",
      ">>> PGa-T1\n",
      ">>> PGa-T2\n",
      ">>> PGa-T3\n",
      "Late excluded animals: []\n"
     ]
    }
   ],
   "source": [
    "#Late population\n",
    "excluded = []\n",
    "for animal in late_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(latebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            activeLever, inactiveLever, alignedActiveLever, alignedInactiveLever, framerate, cueFlags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(latebasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            cueFlags.to_csv(os.path.join(latebasedir, animal, fov, 'active_flags.csv'), index=False)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Late excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jboqu\\AppData\\Local\\Temp\\ipykernel_18916\\409106232.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  flags_df[flags_df['Flag']=='cue'][flags_df['Group']=='Early'].head(20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>362926</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>854689</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>1882559</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>3221116</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>3279653</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>6105130</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>7385406</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>7930088</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>8209172</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Early</td>\n",
       "      <td>CTL1</td>\n",
       "      <td>9065859</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>30706</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>451698</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>1187542</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>1630241</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>2406093</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>5551947</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>6204381</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>8249654</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L2</td>\n",
       "      <td>8765998</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Early</td>\n",
       "      <td>ER-L1</td>\n",
       "      <td>85444</td>\n",
       "      <td>cue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group Animal  Timestamp Flag\n",
       "0   Early   CTL1     362926  cue\n",
       "1   Early   CTL1     854689  cue\n",
       "2   Early   CTL1    1882559  cue\n",
       "3   Early   CTL1    3221116  cue\n",
       "4   Early   CTL1    3279653  cue\n",
       "5   Early   CTL1    6105130  cue\n",
       "6   Early   CTL1    7385406  cue\n",
       "7   Early   CTL1    7930088  cue\n",
       "8   Early   CTL1    8209172  cue\n",
       "9   Early   CTL1    9065859  cue\n",
       "12  Early  ER-L2      30706  cue\n",
       "13  Early  ER-L2     451698  cue\n",
       "14  Early  ER-L2    1187542  cue\n",
       "15  Early  ER-L2    1630241  cue\n",
       "16  Early  ER-L2    2406093  cue\n",
       "17  Early  ER-L2    5551947  cue\n",
       "18  Early  ER-L2    6204381  cue\n",
       "19  Early  ER-L2    8249654  cue\n",
       "20  Early  ER-L2    8765998  cue\n",
       "28  Early  ER-L1      85444  cue"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making population dataframes\n",
    "\n",
    "groups = ['Early', 'Middle', 'Late']\n",
    "animals = [early_animals_of_interest, middle_animals_of_interest, late_animals_of_interest]\n",
    "directories = [earlybasedir, middlebasedir, latebasedir]\n",
    "\n",
    "temp_dict = [] #list for population array\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    animals_of_interest = animals[index]\n",
    "    indir = directories[index]\n",
    "    for animal in animals_of_interest:\n",
    "        FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(FOVs):\n",
    "            flags = pd.read_csv(os.path.join(indir, animal, fov, 'active_flags.csv'))\n",
    "            for i in range(len(flags)):\n",
    "                # print(flags['Timestamp'][i], '-', flags['Flag'][i])\n",
    "                temp_dict.append(\n",
    "                    {'Group': group,\n",
    "                     'Animal': animal,\n",
    "                     'Timestamp': flags['Timestamp'][i],\n",
    "                     'Flag': flags['Flag'][i]}\n",
    "                )\n",
    "flags_df = pd.DataFrame(temp_dict)\n",
    "flags_df[flags_df['Flag']=='cue'][flags_df['Group']=='Early'].head(20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for stacking data\n",
    "def stack_data(indir, animals_of_interest, window, signals_file, aligned_levers_file):\n",
    "    temp_data = np.nan*np.ones((1, window))\n",
    "    for animal in animals_of_interest:\n",
    "            FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "            for fov in sorted(FOVs):\n",
    "                    try:\n",
    "                        #load in data\n",
    "                        signal_data = np.load(os.path.join(indir, animal, fov, signals_file))\n",
    "                        lever_data = np.load(os.path.join(indir, animal, fov, aligned_levers_file))\n",
    "                        #stack data\n",
    "                        temp_data = np.vstack((temp_data, signal_data))\n",
    "                    except Exception as e:\n",
    "                        print('***ERROR:', e, ' ***')\n",
    "    data = temp_data[1:,:]\n",
    "    return(data, lever_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for matching neurons to clusters based on criteria\n",
    "def find_indexes(indir, sub_animals_of_interest_array, original_full_stack, signal_file, cluster_labels_file):\n",
    "    indexes = []\n",
    "    for animal in sub_animals_of_interest_array:\n",
    "        FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(FOVs):\n",
    "            signal_data = np.load(os.path.join(indir, animal, fov, signal_file))\n",
    "            for neuron in range(len(signal_data)):\n",
    "                for row in range(len(original_full_stack)):\n",
    "                    if np.equal(signal_data[neuron], original_full_stack[row])[0]==True:\n",
    "                        indexes.append({'Animal': animal, 'Stack index': row, 'Cluster': cluster_labels_file[row]})\n",
    "    indexes = pd.DataFrame(indexes)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#stacking early data\n",
    "\n",
    "#early active data\n",
    "temp_early_active, early_active_levers = stack_data(earlybasedir, early_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_active = temp_early_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_active = temp_early_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_early_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "early_active_mean = np.nanmean(early_active, axis=0)\n",
    "\n",
    "\n",
    "#early inactive data\n",
    "temp_early_inactive, early_inactive_levers = stack_data(earlybasedir, early_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_inactive = temp_early_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_inactive = temp_early_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_early_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "early_inactive_mean = np.nanmean(early_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', early_active.shape)\n",
    "print('Active lever shape:', early_active_levers.shape)\n",
    "print('Inative shape:', early_inactive.shape)\n",
    "print('Inctive lever shape:', early_inactive_levers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking middle data\n",
    "\n",
    "#middle active data\n",
    "temp_middle_active, middle_active_levers = stack_data(middlebasedir, middle_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_middle_active = temp_middle_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_active = temp_middle_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_middle_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "middle_active_mean = np.nanmean(middle_active, axis=0)\n",
    "\n",
    "\n",
    "#middle inactive data\n",
    "temp_middle_inactive, middle_inactive_levers = stack_data(middlebasedir, middle_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_middle_inactive = temp_middle_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_inactive = temp_middle_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_middle_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "middle_inactive_mean = np.nanmean(middle_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', middle_active.shape)\n",
    "print('Active lever shape:', middle_active_levers.shape)\n",
    "print('Inative shape:', middle_inactive.shape)\n",
    "print('Inctive lever shape:', middle_inactive_levers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking late data\n",
    "\n",
    "#late active data\n",
    "temp_late_active, late_active_levers = stack_data(latebasedir, late_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_late_active = temp_late_active.shape[0]-1 \n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_active = temp_late_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_late_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "late_active_mean = np.nanmean(late_active, axis=0)\n",
    "\n",
    "\n",
    "#late inactive data\n",
    "temp_late_inactive, late_inactive_levers = stack_data(latebasedir, late_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_late_inactive = temp_late_inactive.shape[0]-1 \n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_inactive = temp_late_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_late_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "late_inactive_mean = np.nanmean(late_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', late_active.shape)\n",
    "print('Active lever shape:', late_active_levers.shape)\n",
    "print('Inative shape:', late_inactive.shape)\n",
    "print('Inctive lever shape:', late_inactive_levers.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array of animals that meet lever press requirement\n",
    "\n",
    "req_presses = 6\n",
    "\n",
    "#early animals\n",
    "sub_early = []\n",
    "for animal in early_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(earlybasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_early.append(animal)\n",
    "\n",
    "#middle animals\n",
    "sub_middle = []\n",
    "for animal in middle_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(middlebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(middlebasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_middle.append(animal)\n",
    "\n",
    "#late animals\n",
    "sub_late = []\n",
    "for animal in late_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(latebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(latebasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_late.append(animal)\n",
    "\n",
    "print('Early animals with sufficient presses:', sub_early)\n",
    "print('Middle animals with sufficient presses:', sub_middle)\n",
    "print('Late animals with sufficient presses:', sub_late)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_early_active_df = find_indexes(earlybasedir, sub_early, temp_early_active, 'active.npy', early_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_early_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, early_active[index]))\n",
    "sub_early_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_early_active = sub_early_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_early_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_early_active_minus_baseline = sub_early_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_early_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_early_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_early_active_mean = np.nanmean(sub_early_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_early_inactive_df = find_indexes(earlybasedir, sub_early, temp_early_inactive, 'inactive.npy', early_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_early_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, early_inactive[index]))\n",
    "sub_early_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_early_inactive = sub_early_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_early_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_early_inactive_minus_baseline = sub_early_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_early_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_early_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_early_inactive_mean = np.nanmean(sub_early_inactive, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#middle data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_middle_active_df = find_indexes(middlebasedir, sub_middle, temp_middle_active, 'active.npy', middle_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_middle_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, middle_active[index]))\n",
    "sub_middle_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_middle_active = sub_middle_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_middle_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_middle_active_minus_baseline = sub_middle_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_middle_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_middle_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_middle_active_mean = np.nanmean(sub_middle_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_middle_inactive_df = find_indexes(middlebasedir, sub_middle, temp_middle_inactive, 'inactive.npy', middle_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_middle_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, middle_inactive[index]))\n",
    "sub_middle_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_middle_inactive = sub_middle_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_middle_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_middle_inactive_minus_baseline = sub_middle_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_middle_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_middle_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_middle_inactive_mean = np.nanmean(sub_middle_inactive, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#late data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_late_active_df = find_indexes(latebasedir, sub_late, temp_late_active, 'active.npy', late_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_late_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, late_active[index]))\n",
    "sub_late_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_late_active = sub_late_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_late_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_late_active_minus_baseline = sub_late_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_late_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_late_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_late_active_mean = np.nanmean(sub_late_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_late_inactive_df = find_indexes(latebasedir, sub_late, temp_late_inactive, 'inactive.npy', late_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_late_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, late_inactive[index]))\n",
    "sub_late_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_late_inactive = sub_late_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_late_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_late_inactive_minus_baseline = sub_late_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_late_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_late_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_late_inactive_mean = np.nanmean(sub_late_inactive, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the NaN values\n",
    "def filter_NAN(processed_data, windowsize, prewindowsize, framerate):\n",
    "        filtered_stack = np.nan*np.ones((1, windowsize))\n",
    "        for row in processed_data:\n",
    "                if np.isfinite(row[0]):\n",
    "                        filtered_stack = np.vstack((filtered_stack, row))\n",
    "        filtered_stack = filtered_stack[1:,:]\n",
    "        response = np.nanmean(filtered_stack[:,prewindowsize-(1*int(framerate)):prewindowsize+1*int(framerate)], axis=1)\n",
    "        sortresponse = np.argsort(response)[::-1]\n",
    "        return(filtered_stack, sortresponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "# 2 rows and 3 columns of graphs; may end up with blank column\n",
    "fig, axs = plt.subplots(4, 3, figsize=(11, 14))\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "# early active plots\n",
    "ax = axs[0, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_active[sortresponse_early_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_early_active, fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_active], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[1, 0]\n",
    "ax.plot(early_active_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "\n",
    "# early inactive plots (sorted to active plot)\n",
    "ax = axs[2, 0]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_early_inactive, inactive_sort = filter_NAN(early_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_early_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_early_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[3, 0]\n",
    "ax.plot(early_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "\n",
    "# middle active plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_active[sortresponse_middle_active, :], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_middle_active, fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[1, 1]\n",
    "ax.plot(middle_active_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "\n",
    "# middle inactive plots\n",
    "ax = axs[2, 1]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_middle_inactive, inactive_sort = filter_NAN(middle_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_middle_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_middle_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[3, 1]\n",
    "ax.plot(middle_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "\n",
    "# late active plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_active[sortresponse_late_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_late_active, fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[1, 2]\n",
    "ax.plot(late_active_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "\n",
    "# late inactive plots\n",
    "ax = axs[2, 2]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_late_inactive, inactive_sort = filter_NAN(late_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_late_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_late_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[3, 2]\n",
    "ax.plot(late_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-inactive-all_population_heatmaps.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-inactive-all_population_heatmaps.PNG'), format='PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "# 2 rows and 3 columns of graphs; may end up with blank column\n",
    "fig, axs = plt.subplots(3, 3, figsize=(11, 11))\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "# early active plots\n",
    "ax = axs[0, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_early_active[sortresponse_sub_early_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_early_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_early_active], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 0]\n",
    "ax.plot(sub_early_active_mean)\n",
    "ax.plot(sub_early_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# early inactive plots (sorted to active plot)\n",
    "ax = axs[1, 0]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_early_inactive, inactive_sort = filter_NAN(sub_early_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_early_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_early_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_early_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# middle active plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_middle_active[sortresponse_sub_middle_active, :], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_middle_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_middle_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 1]\n",
    "ax.plot(sub_middle_active_mean)\n",
    "ax.plot(sub_middle_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# middle inactive plots\n",
    "ax = axs[1, 1]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_middle_inactive, inactive_sort = filter_NAN(sub_middle_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_middle_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_middle_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_middle_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# late active plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_late_active[sortresponse_sub_late_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_late_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_late_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 2]\n",
    "ax.plot(sub_late_active_mean)\n",
    "ax.plot(sub_late_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# late inactive plots\n",
    "ax = axs[1, 2]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_late_inactive, inactive_sort = filter_NAN(sub_late_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_late_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_late_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_late_inactive], '--', linewidth=1.5, color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-inactive_sub-population_heatmaps.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-inactive_sub-population_heatmaps.PNG'), format='PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering, KMeans\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import interpolate\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import (ModelDesc, EvalEnvironment, Term, EvalFactor, LookupFactor, dmatrices, INTERCEPT)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inactive data\n",
    "early_populationdata = early_inactive\n",
    "middle_populationdata = middle_inactive\n",
    "late_populationdata = late_inactive\n",
    "all_populationdata = np.vstack((early_inactive, middle_inactive, late_inactive))\n",
    "\n",
    "##active data\n",
    "#early_populationdata = early_active\n",
    "#middle_populationdata = middle_active\n",
    "#late_populationdata = late_active\n",
    "#all_populationdata = np.vstack((early_active, middle_active, late_active))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late', 'all'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            temp = early_populationdata[np.where(early_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            temp = middle_populationdata[np.where(middle_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            temp = late_populationdata[np.where(late_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "#fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-all_clusters_heatmaps.PDF'), format='PDF')\n",
    "#fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-all_clusters_heatmaps.PNG'), format='PNG')\n",
    "\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_inactive-all_clusters_heatmaps.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_inactive-all_clsters_heatmaps.PNG'), format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            temp = early_populationdata[np.where(early_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'middle':\n",
    "            temp = middle_populationdata[np.where(middle_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'late':\n",
    "            temp = late_populationdata[np.where(late_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "#fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-all_clusters_polylines.PDF'), format='PDF')\n",
    "#fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_active-all_clusters_polylines.PNG'), format='PNG')\n",
    "\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_inactive-all_clusters_polylines.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'PFC_HEROIN_SA_Acquisition_inactive-all_clusters_polylines.PNG'), format='PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Active clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active data\n",
    "early_populationdata = early_active\n",
    "middle_populationdata = middle_active\n",
    "late_populationdata = late_active\n",
    "all_populationdata = np.vstack((early_active, middle_active, late_active))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_active_df['Stack index'][np.where(sub_early_active_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_active_df['Stack index'][np.where(sub_middle_active_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_active_df['Stack index'][np.where(sub_late_active_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_active-subset_clusters_heatmaps.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_active-subset_clusters_heatmaps.PNG'), format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_active_df['Stack index'][np.where(sub_early_active_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_active_df['Stack index'][np.where(sub_middle_active_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_active_df['Stack index'][np.where(sub_late_active_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_active-subset_clusters_polylines.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_active-subset_clusters_polylines.PNG'), format='PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inactive clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inactive data\n",
    "early_populationdata = early_inactive\n",
    "middle_populationdata = middle_inactive\n",
    "late_populationdata = late_inactive\n",
    "all_populationdata = np.vstack((early_inactive, middle_inactive, late_inactive))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_inactive_df['Stack index'][np.where(sub_early_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_inactive_df['Stack index'][np.where(sub_middle_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_inactive_df['Stack index'][np.where(sub_late_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_inactive-subset_clusters_heatmaps.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_inactive-subset_clusters_heatmaps.PNG'), format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_inactive_df['Stack index'][np.where(sub_early_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_inactive_df['Stack index'][np.where(sub_middle_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_inactive_df['Stack index'][np.where(sub_late_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fig\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_inactive-subset_clusters_polylines.PDF'), format='PDF')\n",
    "fig.savefig(os.path.join(results, 'clusters', 'subset_6_presses', 'PFC_HEROIN_SA_Acquisition_inactive-subset_clusters_polylines.PNG'), format='PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivoxel Pattern Analysis *(decoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import subprocess\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, SVR\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def binaryclassifier(y, X, cv_val):\n",
    "    hyperparameters = {'kernel': ['rbf'], 'gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                     'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "    try:\n",
    "        clf = GridSearchCV(SVC(), hyperparameters, cv=cv_val)\n",
    "        clf.fit(X, y)\n",
    "        accuracy = clf.best_score_\n",
    "        return accuracy\n",
    "    except Exception as e:\n",
    "        print('*** ERROR:', e, '***')\n",
    "\n",
    "def svmregression(y, X):\n",
    "    hyperparameters = {'kernel': ['rbf'], 'cluster': np.logspace(-3, 3, 5),\n",
    "                      'epsilon': np.logspace(-3, 3, 5),\n",
    "                      'gamma': np.logspace(-5, 5, 10)}\n",
    "    clf = GridSearchCV(SVR(), hyperparameters, cv=10)\n",
    "    if np.all(np.isnan(X)):\n",
    "        R2=np.nan\n",
    "    else:\n",
    "        clf.fit(X, y)\n",
    "        R2 = clf.best_score_\n",
    "    #reference for 10-fold cross-validation http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf\n",
    "    return R2\n",
    "\n",
    "def calculate_t(x, y):\n",
    "    Sp= np.sqrt((np.nanstd(x)**2 + np.nanstd(y)**2)/2)\n",
    "    denominator = Sp*(np.sqrt(2/len(x)))\n",
    "    numerator = np.nanmean(x) - np.nanmean(y)\n",
    "    t = numerator/denominator\n",
    "    return t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding: Neuron, ActivePress-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['Early','Middle', 'Late'] ###INSERT YOUR GROUPS (E.G., EARLY AND LATE LEARNING)\n",
    "#animals_of_interest_list = [sub_early, sub_middle, sub_late]\n",
    "animals_of_interest_list = [early_animals_of_interest, middle_animals_of_interest, late_animals_of_interest]\n",
    "indir_list = [earlybasedir, middlebasedir, latebasedir]\n",
    "session_analysis_split_by_ensemble = ['Yes'] ###SET TO ['Yes'] OR TO ['No']\n",
    "decoding = ['Neuron', 'Trial'] ###SET TO Neuron or Session and Trial or Lick\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS #FIXME -> 4 clusters?\n",
    "\n",
    "baseline = [1, 8]  ###These variables are for assigning neuronal data epochs\n",
    "leverresponse = [pre_window_size-9, pre_window_size-1]\n",
    "\n",
    "numshuffles = 1 \n",
    "classification_accuracy = {}\n",
    "uniquelabels = np.arange(numclusters)\n",
    "numneuronsincluster = np.nan*np.ones((numclusters,))\n",
    "\n",
    "print('========== STARTING ==========')\n",
    "datadir=0\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    classification_accuracy[group] = {}\n",
    "    classification_accuracy[group]['individualneurons'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['shuffled'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['unshuffled'] = {}\n",
    "\n",
    "    animals_of_interest = animals_of_interest_list[index]\n",
    "    indir = indir_list[index]\n",
    "\n",
    "    numneuronstillnow = 0 \n",
    "    for animal in animals_of_interest:\n",
    "        fovs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(fovs):\n",
    "            trials = np.load(os.path.join(indir, animal, fov, 'aligned_active_lever_data.npy'))\n",
    "\n",
    "            ###THIS SECTION DELETES ANY TRIALS WITH NANs\n",
    "            for i in reversed(range(trials.shape[0])): ###reversed to prevent deletion from messing up indexing\n",
    "                if np.isnan(np.mean(trials[i,:,:])):\n",
    "                    trials = np.delete(trials, i, axis = 0)\n",
    "            \n",
    "            ###THIS SECTION ALIGNS DATA FOR DECODING        \n",
    "            numtrials = trials.shape[0]\n",
    "            numsapltes = trials.shape[1]\n",
    "            numneuronsinfov = trials.shape[2]\n",
    "\n",
    "            baseline_inactive = np.nan*np.ones((numtrials,numneuronsinfov))\n",
    "            response_inactive = np.nan*np.ones((numtrials,numneuronsinfov))\n",
    "\n",
    "            activeflag = np.hstack((np.zeros((numtrials)), np.ones((numtrials))))\n",
    "\n",
    "            for neuron in range(numneuronsinfov):\n",
    "                print('Group:', group, '\\nAnimal:', animal, '\\nNeuron:', neuron, 'of', numneuronsinfov)\n",
    "                baseline_inactive[:,neuron] = np.nanmean(trials[:,baseline[0]:baseline[1],neuron], axis=1)\n",
    "                response_inactive[:,neuron] = np.nanmean(trials[:,leverresponse[0]:leverresponse[1],neuron], axis=1)\n",
    "                \n",
    "                cv = 10\n",
    "                ###CHANGE THESE VARIABLES TO ADJUST WHAT YOU ARE DECODING AND ENSURE IT ALIGNS WITH YOUR FLAGS\n",
    "                neuralactivity_trialtype = np.vstack((baseline_inactive, response_inactive)) ###FOR COMPARING TRIAL TYPES\n",
    "                ###TRIAL DECODING IN SINGLE NEURONS\n",
    "                #print('-----\\nbinaryclassifier unshuffled')\n",
    "                #print('y:', activeflag.shape)\n",
    "                #print('X:', np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1).shape)\n",
    "                classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron] = binaryclassifier(activeflag, np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1), cv)\n",
    "                #print('Unshuffled accuracy:', classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron])\n",
    "\n",
    "                shuffledresults = np.nan*np.ones((numshuffles,))\n",
    "                for shuffleid in range(numshuffles):\n",
    "                    shuffled_flag = np.random.permutation(activeflag)\n",
    "                    #print('-----\\nbinaryclassifier shuffled')\n",
    "                    #print('y:', shuffled_flag.shape)\n",
    "                    #print('X:', np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1).shape)\n",
    "                    shuffledresults[shuffleid] = binaryclassifier(shuffled_flag, np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1), cv)\n",
    "                classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron] = shuffledresults\n",
    "                #print('Shuffled accuracy:', classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron][0],'\\n-----')\n",
    "                print()\n",
    "            numneuronstillnow += numneuronsinfov\n",
    "print('========== FINISHED ==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS SECTION IS TO SAVE DECODING DATA AS NUMPY ARRAYS\n",
    "variable_to_save = 'ActivePress-All'\n",
    "decoding_dict_results_dir = os.path.join(results,'decoding','dictionaries')\n",
    "groups = ['Early','Middle', 'Late'] ###INSERT YOUR GROUPS (E.G., EARLY AND LATE LEARNING)\n",
    "\n",
    "for g, group in enumerate (groups):\n",
    "    unshuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['unshuffled'])))\n",
    "    shuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['shuffled'])))\n",
    "    if unshuffled.shape[0] > 0:\n",
    "        print(unshuffled.shape)\n",
    "        print(shuffled.shape)\n",
    "        stacked = np.vstack((unshuffled[:,1], shuffled[:,1]))\n",
    "    np.save(os.path.join(decoding_dict_results_dir,'PFC-HeroinSA_%s_%s_Decoding-dict.npy'%(group,variable_to_save,decoding[0])),stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show what's in each file\n",
    "decoding_dict_results_dir = os.path.join(results,'decoding','dictionaries')\n",
    "\n",
    "for i in os.listdir(decoding_dict_results_dir):\n",
    "    print(i)\n",
    "    infile = np.load(os.path.join(decoding_dict_results_dir, i), allow_pickle=True)\n",
    "    print(infile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DECODING CDF PLOTS FOR EARLY, MIDDLE, AND LATE DATA\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "variables_to_analyze = ['ActivePress-All']\n",
    "groups = ['Early', 'Middle', 'Late'] \n",
    "color = (['k'],['tab:red'], ['tab:green'],['tab:blue'])\n",
    "ls = ['--','solid']\n",
    "decode_results_dir = r'C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\acquisition\\results\\decoding'\n",
    "\n",
    "d = {}\n",
    "###THIS SECTION IS FOR LOADING AND PLOTTING SAVED POPULATION DECODING ARRAYS (BY NEURON OR SESSION)\n",
    "for v, variable in enumerate (variables_to_analyze):\n",
    "    d[variable] = {}\n",
    "    all_shuffle_for_variable=[]\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "    for g, group in enumerate(groups):\n",
    "        d[variable][group] = {}\n",
    "        d[variable][group] = np.array(np.load(os.path.join(decoding_dict_results_dir,\n",
    "                                                           'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group,variable,analyze_by)), \n",
    "                                                           allow_pickle = True).astype(float))\n",
    "        temp_unshuffle_nonans, temp_shuffle_nonans = ([],[])\n",
    "        temp_unshuffle,temp_shuffle = (d[variable][group][0],d[variable][group][1])\n",
    "\n",
    "        for i in range(len(temp_unshuffle)):\n",
    "            if np.isfinite(temp_unshuffle[i]):\n",
    "                temp_unshuffle_nonans = np.append(temp_unshuffle_nonans, temp_unshuffle[i])\n",
    "        for i in range(len(temp_shuffle)):\n",
    "            if np.isfinite(temp_shuffle[i]):\n",
    "                temp_shuffle_nonans = np.append(temp_shuffle_nonans, temp_shuffle[i])\n",
    "                \n",
    "       ##NORMALIZING\n",
    "        mean_shuffle = np.mean(temp_shuffle_nonans)\n",
    "        temp_unshuffle_nonans = temp_unshuffle_nonans - mean_shuffle\n",
    "        temp_shuffle_nonans = temp_shuffle_nonans - mean_shuffle\n",
    "\n",
    "        plt.hist((temp_unshuffle_nonans),  density=True, cumulative=True,\\\n",
    "            label = ['%s-Unshuffle'%(group)], histtype='step',\\\n",
    "            linestyle = ('-'), bins = 'auto', color = color[g], linewidth=2)\n",
    "\n",
    "        all_shuffle_for_variable = np.append(all_shuffle_for_variable, d[variable][group][1])\n",
    "        if g == len(groups)-1:\n",
    "            plt.hist((temp_shuffle_nonans),  density=True, cumulative=True,\\\n",
    "                label = ['Shuffle','%sUnhuffle'%(group)], histtype='step',\\\n",
    "                linestyle = ('--'), bins ='auto', color = 'k', alpha=.7, linewidth=2)\n",
    "                \n",
    "        ax[0].text(.2,1-g*.5,'%s-Shuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_shuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_shuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_shuffle_nonans)))\n",
    "        ax[0].text(.2, .9-g*.5,'%s-Unhuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_unshuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_unshuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_unshuffle_nonans)))\n",
    "        t, p = stats.ttest_ind(temp_shuffle_nonans,\\\n",
    "            temp_unshuffle_nonans, equal_var=False)\n",
    "        ax[0].text(.2, .8-g*.5, '%s T-test: t = '%(group) + '{0:.3g}'.format(t) + ', p = ' + '{0:.3g}'.format(p))\n",
    "\n",
    "    ax[0].get_xaxis().set_visible(False)\n",
    "    ax[0].get_yaxis().set_visible(False)\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].spines['left'].set_visible(False)\n",
    "    ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "    plt.legend(loc=2)\n",
    "    plt.title('%s-level analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "    \n",
    "    #plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding.PDF'%(population, variable, analyze_by)), format = 'PDF')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "decode_results_dir = r'C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\acquisition\\results\\decoding'\n",
    "\n",
    "\n",
    "### DECODING CDF PLOTS FOR EARLY, MIDDLE, AND LATE DATA\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "variables_to_analyze = ['ActivePress-All']\n",
    "groups = ['Early', 'Middle', 'Late'] \n",
    "dir_list = [earlybasedir, middlebasedir, latebasedir]\n",
    "color = (['k'],['tab:red'], ['tab:green'],['tab:blue'], ['tab:yellow'])\n",
    "ls = ['--','solid']\n",
    "bins = np.arange(0.4,0.8,0.01)  \n",
    "\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    newlabels = np.load((os.path.join(dir_list[index], 'cluster_list_per_session_Acquisition.npy')))\n",
    "    dict_file = np.load(os.path.join(decoding_dict_results_dir, 'PFC-HeroinSA_%s_ActivePress-All_Neuron_Decoding-dict.npy'%(group)),allow_pickle = True).astype(float)\n",
    "    for variable in variables_to_analyze:\n",
    "        print('Group:', group)\n",
    "        d = {}\n",
    "        d[variable]={}\n",
    "        all_shuffle_for_variable = []\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "        for cluster in range(numclusters):\n",
    "            d[variable][cluster] = {}\n",
    "            file_max = len(dict_file[1])\n",
    "            fit = np.array(newlabels[:file_max])\n",
    "            temp_array = np.squeeze(dict_file[:,np.where(fit==cluster)[0]])\n",
    "            d[variable][cluster] = temp_array\n",
    "\n",
    "            shuffled_mean = np.nanmean(d[variable][cluster][1])\n",
    "            normalized_unshuffled = d[variable][cluster][0] - shuffled_mean\n",
    "            normalized_shuffled = d[variable][cluster][1] - shuffled_mean\n",
    "            all_shuffle_for_variable = np.append(all_shuffle_for_variable, normalized_shuffled)\n",
    "\n",
    "            plt.hist((normalized_unshuffled), density=True, cumulative=True,\\\n",
    "                                label = ['Cluster %s'%(cluster+1)], histtype='step', linestyle = '-',\\\n",
    "                                bins = 'auto', linewidth=2)\n",
    "            ax[0].text(-0.15, (1.1-cluster*.16), \n",
    "                    ('Ensemble '+str(cluster+1)+' (shuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_shuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_shuffled[np.where(np.isfinite(normalized_shuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_shuffled)))\n",
    "            ax[0].text(-0.15, 1.03-cluster*.16, \n",
    "                    ('Ensemble '+str(cluster+1)+' (unshuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_unshuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_unshuffled[np.where(np.isfinite(normalized_unshuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_unshuffled)))\n",
    "            if cluster == len(uniquelabels)-1:\n",
    "                plt.hist((all_shuffle_for_variable), density=True, cumulative=True,\\\n",
    "                    label = ['Shuffled'], histtype='step', linestyle = '--',\\\n",
    "                    bins = 'auto', linewidth=2, color = 'k', alpha = .8)\n",
    "                ax[0].text(-0.15, .8-cluster*.16, \n",
    "                    ('All shuffled stats -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean(all_shuffle_for_variable)) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(all_shuffle_for_variable[np.where(np.isfinite(all_shuffle_for_variable))]))) +\n",
    "                    ', N: ' + str(len(all_shuffle_for_variable)))\n",
    "\n",
    "            ax[0].get_xaxis().set_visible(False)\n",
    "            ax[0].get_yaxis().set_visible(False)\n",
    "            ax[0].spines['top'].set_visible(False)\n",
    "            ax[0].spines['right'].set_visible(False)\n",
    "            ax[0].spines['left'].set_visible(False)\n",
    "            ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "            plt.legend(loc=2)\n",
    "            plt.title('%s-level Cluster analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "        #change plot title as needed\n",
    "        #plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_%s_Normalized-Cluster_Decoding.PDF'%(population, group, variable, analyze_by)), format = 'PDF')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "josh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
