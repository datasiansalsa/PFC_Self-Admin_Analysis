{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Josh Boquiren\n",
    "OTIS Lab MUSC\n",
    "5.23.2023\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Notes:\n",
    "- populations of interest: Acquisition, CueRein\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "#data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#directory and file manager\n",
    "import os\n",
    "\n",
    "#statistics\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import roc_auc_score as auROC\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: jboqu\n",
      "Base directory: C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data\n",
      "Results directory: C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\cue\\results\n"
     ]
    }
   ],
   "source": [
    "#initialize directories\n",
    "\n",
    "population = 'ACQUISITION and REINSTATEMENT'\n",
    "\n",
    "try:\n",
    "    user = 'jboqu'\n",
    "except:\n",
    "    user = 'OtisLab'\n",
    "print('User:', user)\n",
    "\n",
    "basedir = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data'%(user)\n",
    "print('Base directory:', basedir)\n",
    "\n",
    "acq_earlybasedir = os.path.join(basedir, 'EarlyAcq')\n",
    "acq_middlebasedir = os.path.join(basedir, 'MidAcq')\n",
    "acq_latebasedir = os.path.join(basedir, 'LateAcq')\n",
    "rst_cuedir = os.path.join(basedir, 'CueRein')\n",
    "\n",
    "results = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\cue\\results'%(user)\n",
    "print('Results directory:', results)\n",
    "\n",
    "#cluster list files\n",
    "acq_early_newlabels = np.load(os.path.join(acq_earlybasedir, 'cluster_list_per_session_Acquisition.npy')) #put clustering files in a folder to loop through\n",
    "acq_middle_newlabels = np.load(os.path.join(acq_middlebasedir, 'cluster_list_per_session_Acquisition.npy'))\n",
    "acq_late_newlabels = np.load(os.path.join(acq_latebasedir, 'cluster_list_per_session_Acquisition.npy'))\n",
    "\n",
    "rst_newlabels = np.load(os.path.join(rst_cuedir, 'cluster_list_per_session_CueDrugTMT.npy'))\n",
    "\n",
    "#for later plot titles\n",
    "plot_titles = ['EARLY', 'MIDDLE', 'LATE']\n",
    "population_title = \"ACQ\"\n",
    "\n",
    "#animals of interest\n",
    "early_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L2', 'ER-L1',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa5','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]  \n",
    "middle_animals_of_interest = [\n",
    "    'CTL1',\n",
    "\n",
    "    'ER-L1', #FIXME - only 1 inactive press frame recorded\n",
    "    'ER-L2',\n",
    "\n",
    "    'IG-19',\n",
    "\n",
    "    'LCDD-PGa1', #FIXME - only 1 inactive press frame recorded\n",
    "    'LCDD-PGa3',\n",
    "    'LCDD-PGa4',\n",
    "    'LCDD-PGa5',\n",
    "    'LCDD-PGa6',\n",
    "\n",
    "    'LCDD-PGa-T1',\n",
    "    'LCDD-PGa-T2', #FIXME - only 1 inactive press frame recorded\n",
    "    'LCDD-PGa-T3',\n",
    "    'LCDD-PGa-T4',\n",
    "    'LCDD-PGa-T5',\n",
    "\n",
    "    'PGa-T1',\n",
    "    'PGa-T2',\n",
    "    'PGa-T3'\n",
    "    ]  \n",
    "late_animals_of_interest = [\n",
    "    'CTL1',\n",
    "\n",
    "    'ER-L1',\n",
    "    'ER-L2',\n",
    "\n",
    "    'IG-19',\n",
    "\n",
    "    'LCDD-PGa1',\n",
    "    'LCDD-PGa3', \n",
    "    'LCDD-PGa4',\n",
    "    'LCDD-PGa5',\n",
    "    'LCDD-PGa6',\n",
    "\n",
    "    'LCDD-PGa-T1',\n",
    "    'LCDD-PGa-T2',\n",
    "    'LCDD-PGa-T3',\n",
    "    'LCDD-PGa-T4',\n",
    "    'LCDD-PGa-T5',\n",
    "\n",
    "    'PGa-T1',\n",
    "    'PGa-T2',\n",
    "    'PGa-T3' #FIXME\n",
    "    ]  \n",
    "\n",
    "cue_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L2', 'ER-L1',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa5','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame rate: 8.333325\n",
      "Averaged frame rate: 8.333325\n",
      "Prewindow size: 83\n",
      "Window size: 190\n",
      "Postwindow size: 107\n",
      "No Cell Tracking\n"
     ]
    }
   ],
   "source": [
    "#frame rate variables\n",
    "frameaveraging = 4\n",
    "timebetweenframes = 33.3333\n",
    "framerate = 30\n",
    "framerate = timebetweenframes/frameaveraging #raw frame rate\n",
    "averagedframerate = timebetweenframes/frameaveraging #averaged frame rate\n",
    "print('Frame rate:', framerate)\n",
    "print('Averaged frame rate:', averagedframerate)\n",
    "\n",
    "#window size variables\n",
    "pre_window_size = int(10*framerate)\n",
    "window_size =  int((pre_window_size*2)+(3*framerate))\n",
    "post_window_size = window_size - pre_window_size\n",
    "baselinefirstframe = 0\n",
    "baselinelastframe = int(1*framerate)\n",
    "infusionframe = int(pre_window_size+(3*framerate))\n",
    "print('Prewindow size:', pre_window_size)\n",
    "print('Window size:', window_size)\n",
    "print('Postwindow size:', post_window_size)\n",
    "\n",
    "#set cell tracking\n",
    "tracking = 'No' ### 'Yes' or 'No'\n",
    "sorting = 'Yes' ### 'Yes' or 'No'\n",
    "sorttoearly = 'No' ###'Yes' or 'No'; This is for sorting, but align to early data. 'Sorting' must also be Yes\n",
    "csv_id_for_tracking = 'CUE-DRUG-TMT'\n",
    "\n",
    "#tracking\n",
    "if tracking == 'Yes':\n",
    "    population_active_tracked_early = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_middle = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_late = np.nan*np.ones((1,window_size))\n",
    "    print ('Cell Tracking')\n",
    "else:\n",
    "    print ('No Cell Tracking')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for fixing dropped frames\n",
    "def fix_any_dropped_frames(frame_timestamps):\n",
    "    first_frame = np.array([0])\n",
    "    last_frame = np.array([int(np.max(frame_timestamps)+(500*timebetweenframes))])\n",
    "    frame_index_temp = np.concatenate((first_frame,frame_timestamps, last_frame)) ###adds frame to timepoint '0' and an extra 500 frames at end\n",
    "    frames_missed = [] ###creates empty list for us to add timestamps for missed frames\n",
    "    for i in range(len(frame_index_temp)-1): ###iterates through each collected frame\n",
    "            numframes_missed = int(np.round((frame_index_temp[i+1]-frame_index_temp[i])\\\n",
    "                /timebetweenframes)-1) ### number of missed frames per frame interval\n",
    "            if numframes_missed > 0: \n",
    "                for j in range(numframes_missed):\n",
    "                    frame_missed = np.array([frame_index_temp[i] + (int(timebetweenframes * (j+1)))])\n",
    "                    frames_missed = np.concatenate((frames_missed, frame_missed))\n",
    "    corrected_frame_index = np.array(sorted(np.concatenate((frame_index_temp, frames_missed))))\n",
    "    return corrected_frame_index\n",
    "\n",
    "#method for fixing assumed frames\n",
    "def fix_assumed_frames(frames):\n",
    "    dropped_frames = []\n",
    "    diff_frames = np.diff(frames)\n",
    "    inter_frame_interval = 33\n",
    "    frame_drop_idx = np.where(diff_frames>1.5*inter_frame_interval)[0]\n",
    "    for idx in frame_drop_idx:\n",
    "        numframesdropped = int(np.round((frames[idx+1]-frames[idx])/(inter_frame_interval+0.0))-1)\n",
    "        temp = [frames[idx]+a*inter_frame_interval for a in range(1,numframesdropped+1)]\n",
    "        dropped_frames.extend(temp)\n",
    "    corrected_frames = np.sort(np.concatenate((frames, np.array(dropped_frames))))\n",
    "    return corrected_frames\n",
    "\n",
    "#generate behavior data\n",
    "try:\n",
    "    assumed_frames = np.load(os.path.join(models, 'assumed_frames.npy'))\n",
    "    assumed_frame_timestamps = np.load(os.path.join(models, 'assumed_frame_timestamps.npy'))\n",
    "    print(\"Loaded behavior data.\")\n",
    "except:\n",
    "    #load in data\n",
    "    print('Processing data...')\n",
    "    behaviordata_noframes = sio.loadmat(r\"\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data\\Spreadsheets\\matfile_noframes_3.mat\"%(user))\n",
    "    eventlog_noframes = np.squeeze(behaviordata_noframes['eventlog'])\n",
    "\n",
    "    #parse desired data\n",
    "    max_of_eventlog_noframes = max(eventlog_noframes[:,1]) #all rows, second column\n",
    "    length_of_eventlog_noframes = len(eventlog_noframes[:,1])\n",
    "    x = np.vstack((eventlog_noframes, eventlog_noframes, eventlog_noframes))\n",
    "    x[length_of_eventlog_noframes:,1]= x[length_of_eventlog_noframes:,1]+max_of_eventlog_noframes\n",
    "    x[length_of_eventlog_noframes*2:,1]= x[length_of_eventlog_noframes*2:,1]+(2*max_of_eventlog_noframes)\n",
    "    eventlog_noframes = x\n",
    "\n",
    "    assumed_frames = fix_any_dropped_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    assumed_frame_timestamps = fix_assumed_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "\n",
    "    np.save(os.path.join(models, 'assumed_frames'), assumed_frames)\n",
    "    np.save(os.path.join(models, 'assumed_frame_timestamps'), assumed_frame_timestamps)\n",
    "    print(\"Behavior data processed and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def fit_regression(x, y):\n",
    "    lm = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    x_range = sm.add_constant(np.array([x.min(), x.max()]))\n",
    "    x_range_pred = lm.predict(x_range)\n",
    "    return lm.pvalues[1], lm.params[1], x_range[:,1], x_range_pred, lm.rsquared\n",
    "\n",
    "def CDFplot(x, ax, color=None, label='', linetype='-'):\n",
    "    x = np.array(x)\n",
    "    ix=np.argsort(x)\n",
    "    ax.plot(x[ix], ECDF(x)(x)[ix], linetype, color=color, label=label)\n",
    "    return ax\n",
    "\n",
    "def fit_regression_and_plot(x, y, ax, plot_label='', color='k', markersize=3):\n",
    "    #linetype is a string like 'bo'\n",
    "    pvalue, slope, temp, temppred, R2 = fit_regression(x, y)    \n",
    "    ax.scatter(x, y, color=color, label='%s p=%.3f\\nR$^2$=%.3f'% (plot_label, pvalue, R2), s=markersize)\n",
    "    ax.plot(temp, temppred, color=color)\n",
    "    return ax, slope, pvalue, R2\n",
    "\n",
    "def ismembertol(x, y, tol=1E-6):\n",
    "    # Are elements of x in y within tolerance of tol?\n",
    "    # x and y must be 1d numpy arrays\n",
    "    sortx = np.sort(x)\n",
    "    orderofx = np.argsort(x)\n",
    "    sorty = np.sort(y)\n",
    "    current_y_idx = 0\n",
    "    result = np.nan*np.zeros(x.shape)\n",
    "    for i, elt in enumerate(sortx):\n",
    "        temp = sorty[current_y_idx:]\n",
    "        if np.any(np.abs(temp-elt)<=tol):\n",
    "            result[orderofx[i]]=1\n",
    "        else:\n",
    "            result[orderofx[i]]=0\n",
    "        temp = np.argwhere(sorty>elt)\n",
    "        if temp.size>0:\n",
    "            current_y_idx = temp[0][0]\n",
    "    return result\n",
    "\n",
    "def mkdir_p(path):\n",
    "    #makes a new directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise \n",
    "            \n",
    "def framenumberforevent(event, frame_timestamps):\n",
    "    framenumber = np.nan*np.zeros(event.shape)\n",
    "    for ie, e in enumerate(event):\n",
    "        #print('     e:', e)\n",
    "        if np.isnan(e):\n",
    "            framenumber[ie] = np.nan\n",
    "        else:\n",
    "            temp = np.nonzero(frame_timestamps<=e)[0]\n",
    "            if temp.shape[0]>0:\n",
    "                framenumber[ie] = np.nonzero(frame_timestamps<=e)[0][-1]\n",
    "            else:\n",
    "                framenumber[ie] = 0\n",
    "    return framenumber\n",
    "\n",
    "def calculate_num_licks_for_each_frame(framenumberforlicks, numframes):\n",
    "    numlicksperframe = np.nan*np.ones((numframes,))\n",
    "    for i in range(numframes):\n",
    "        numlicksperframe[i] = np.sum(framenumberforlicks==i)\n",
    "    return numlicksperframe\n",
    "\n",
    "def calculate_auROC(x,y,offset_to_zero=True):\n",
    "    U, p = stats.mannwhitneyu(x,y)\n",
    "    labels = np.concatenate((np.ones(x.shape), np.zeros(y.shape)))\n",
    "    data = np.concatenate((x,y))\n",
    "    A = auROC(labels, data)\n",
    "    if offset_to_zero:\n",
    "        return (2*(A-0.5), p)\n",
    "    else:\n",
    "        return (A, p)\n",
    "    \n",
    "def Benjamini_Hochberg_correction(vector_of_pvals,\n",
    "                                  alpha = 0.05):\n",
    "    # This function ipltements the BH FDR correction\n",
    "    \n",
    "    # Parameters:\n",
    "    # Vector of p values from the different tests\n",
    "    # alpha:significance level\n",
    "    \n",
    "    # Returns: Corrected p values. All the p values that are above the FDR threshold are set to 1. \n",
    "    #          Remaining p values are unchanged.\n",
    "    \n",
    "    sortedpvals = np.sort(vector_of_pvals)\n",
    "    orderofpvals = np.argsort(vector_of_pvals)\n",
    "    m = sortedpvals[np.isfinite(sortedpvals)].shape[0] #Total number of hypotheses\n",
    "    for i in range(m):\n",
    "        if sortedpvals[i] > (i+1)*alpha/m:\n",
    "            k = i\n",
    "            break\n",
    "        elif i == m-1:\n",
    "            k = m-1\n",
    "        \n",
    "    correctedpvals = np.copy(vector_of_pvals)\n",
    "    correctedpvals[orderofpvals[k:]] = 1\n",
    "    correctedpvals[np.isnan(vector_of_pvals)] = np.nan\n",
    "    return correctedpvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for animal analysis\n",
    "def analyze_single_session(indir, window_size, pre_window_size):    \n",
    "    tempfiles = next(os.walk(indir))[2]\n",
    "    npyfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "        and 'extractedsignals_raw' in f]\n",
    "    matfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat']\n",
    "\n",
    "    if len(npyfiles) > 1:\n",
    "        npyfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "            and 'extractedsignals_raw' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        if npyfile[0][0]!='nan':\n",
    "            npyfile = npyfile [0]\n",
    "        matfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' \n",
    "            and not 'results' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        matfile = matfile [0]\n",
    "    else:\n",
    "        npyfile = npyfiles[0]\n",
    "        matfile = matfiles[0]\n",
    "    \n",
    "    signals = np.squeeze(np.load(os.path.join(indir, npyfile)))\n",
    "    numneurons = signals.shape[0] \n",
    "   \n",
    "    behaviordata = sio.loadmat(os.path.join(indir, matfile))\n",
    "    eventlog = np.squeeze(behaviordata['eventlog'])\n",
    "    licks = np.squeeze(behaviordata['licks'])\n",
    "    lastframe_timestamp_part1 = np.max(eventlog)\n",
    "    \n",
    "    if len(npyfiles) > 1:\n",
    "        npyfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part2' in f]\n",
    "        matfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part2' in f and not 'results' in f]\n",
    "        npyfile2 = npyfiles2[0]\n",
    "        matfile2 = matfiles2[0]\n",
    "        signals2 = np.squeeze(np.load(os.path.join(indir, npyfile2))) \n",
    "        if signals2[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals2))\n",
    "        behaviordata2 = sio.loadmat(os.path.join(indir, matfile2))\n",
    "        eventlog2 = np.squeeze(behaviordata2['eventlog'])\n",
    "        eventlog2[:,1] = eventlog2[:,1]+lastframe_timestamp_part1  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog2))\n",
    "        lastframe_timestamp_part2 = np.max(eventlog)        \n",
    "        licks2 = np.squeeze(behaviordata2['licks'])\n",
    "        licks2 = licks2+lastframe_timestamp_part1\n",
    "        licks = np.concatenate ([licks, licks2])\n",
    "    if len(npyfiles) > 2:\n",
    "        npyfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part3' in f]\n",
    "        matfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part3' in f and not 'results' in f]\n",
    "        npyfile3 = npyfiles3[0]\n",
    "        matfile3 = matfiles3[0]\n",
    "        signals3 = np.squeeze(np.load(os.path.join(indir, npyfile3))) \n",
    "        if signals3[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals3))\n",
    "        behaviordata3 = sio.loadmat(os.path.join(indir, matfile3))\n",
    "        eventlog3 = np.squeeze(behaviordata3['eventlog'])\n",
    "        eventlog3[:,1] = eventlog3[:,1]+lastframe_timestamp_part2  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog3))\n",
    "        lastframe_timestamp_part3 = np.max(eventlog)\n",
    "        licks3 = np.squeeze(behaviordata3['licks'])\n",
    "        licks3 = licks3+lastframe_timestamp_part2\n",
    "        licks = np.concatenate ([licks, licks3])\n",
    "    if len(npyfiles) > 3:\n",
    "        npyfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw' and 'part4' in f]\n",
    "        matfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part4' in f and not 'results' in f]\n",
    "        npyfile4 = npyfiles4[0]\n",
    "        matfile4 = matfiles4[0]\n",
    "        signals4 = np.squeeze(np.load(os.path.join(indir, npyfile4))) \n",
    "        if signals4[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals4))\n",
    "        behaviordata4 = sio.loadmat(os.path.join(indir, matfile4))\n",
    "        eventlog4 = np.squeeze(behaviordata4['eventlog'])\n",
    "        eventlog4[:,1] = eventlog4[:,1]+lastframe_timestamp_part3  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog4))\n",
    "        lastframe_timestamp_part4 = np.max(eventlog)\n",
    "        licks4 = np.squeeze(behaviordata4['licks'])\n",
    "        licks4 = licks4+lastframe_timestamp_part3\n",
    "        licks = np.concatenate ([licks, licks4])\n",
    "    \n",
    "    #pulling data from eventlog\n",
    "    activelever = eventlog[eventlog[:,0]==22,1]\n",
    "    activelevertimeout = eventlog[eventlog[:,0]==222,1]\n",
    "    inactivelever = eventlog[eventlog[:,0]==21,1]\n",
    "    inactivelevertimeout = eventlog[eventlog[:,0]==212,1]\n",
    "    cues = eventlog[eventlog[:,0]==7,1]\n",
    "    infusions = eventlog[eventlog[:,0]==4,1]  \n",
    "\n",
    "    signals /= np.mean(signals, axis=1)[:, None]\n",
    "    signalsT = signals.T\n",
    "    \n",
    "    ###IF YOUR CODE LACKS FRAME INPUTS, WE CAN ATTEMPT TO PREDICT FRAME TIMING BY USING PREVIOUS FRAME TIMESTAMPS\n",
    "    if animal == 'CTL1' or animal == 'ER-L1' or animal == 'ER-L2' or animal == 'IG-19' or animal == 'IG-28' or animal == 'PGa-T1' or animal == 'XYZ':\n",
    "        frame_timestamps = assumed_frame_timestamps ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    else:\n",
    "        frame_timestamps = fix_any_dropped_frames(eventlog[eventlog[:,0]==9,1]) \n",
    "    frame_timestamps = frame_timestamps[::frameaveraging] ###incorporates averaging into timestamp array\n",
    "    \n",
    "    ###DISCARDS BEHAVIORAL EVENTS THAT WERE NOT FULLY MONITORED WITH IMAGING\n",
    "    if signals.shape[1] > frame_timestamps.shape[0]:\n",
    "        signals = signals[:,:frame_timestamps.shape[0]-1] ###cuts signals so it's not longer than the frame timestamps\n",
    "    final_frame_timestamp = frame_timestamps[signals.shape[1]] #This is the timestamp of the final frame in milliseconds\n",
    "    \n",
    "    activelever = activelever[activelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    activelevertimeout = activelevertimeout[activelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelever = inactivelever[inactivelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelevertimeout = inactivelevertimeout[inactivelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "\n",
    "    seconds_monitored = int(signals.shape[1]/averagedframerate) #seconds monitored by 2p imaging\n",
    "    seconds_behavior = int(max(activelever/1000)) #final seconds to be monitored for behavior\n",
    "\n",
    "    #calculate last fully-monitored active lever press with 2p recording\n",
    "    if seconds_monitored < seconds_behavior: \n",
    "        included_trials = []\n",
    "        discarded_trials=[]\n",
    "        for i in range(len(activelever)):\n",
    "            if activelever[i]/1000<seconds_monitored:\n",
    "                included_trials=np.append(included_trials, activelever[i])\n",
    "            else:\n",
    "                discarded_trials=np.append(discarded_trials,activelever[i]) #FIXME why is this even here?\n",
    "        activelever=included_trials \n",
    "    #combines all presses\n",
    "    activeleverall = np.hstack((activelever, activelevertimeout))\n",
    "    inactiveleverall = np.hstack((inactivelever, inactivelevertimeout))\n",
    "\n",
    "    #creating flags\n",
    "    positive = np.ones(len(activelever))\n",
    "    negative = np.zeros(len(activelevertimeout))\n",
    "    flags = np.hstack((positive, negative))\n",
    "\n",
    "    #array shape error handler\n",
    "    if activeleverall.shape[0] < 6:\n",
    "        activeleverall =np.array([])\n",
    "    if inactiveleverall.shape[0] < 6:\n",
    "        inactiveleverall = np.array([])\n",
    "\n",
    "    #method for calculating aligned data\n",
    "    def calculate_aligneddata_forevent(data, frame_after_event):\n",
    "        framenumberfor_eventofinterest = framenumberforevent(frame_after_event, frame_timestamps)\n",
    "        numtrials = framenumberfor_eventofinterest.shape[0] \n",
    "        if data.size==signals.size:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size,numneurons])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size,numneurons])###CHANGED ON AUGUST 20 2021\n",
    "        else:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size])\n",
    "        temp = data\n",
    "        prevendindex = 0\n",
    "        for i in range(numtrials):  ###CHANGED THIS SECTION ON AUGUST 20 2021\n",
    "            tempindex = framenumberfor_eventofinterest[i]\n",
    "            if np.isfinite(tempindex):\n",
    "                tempindex = int(tempindex)\n",
    "                tempstartindex = np.amin([pre_window_size, tempindex]).astype(int)\n",
    "                startindex = np.amin([tempstartindex, tempindex-prevendindex]).astype(int)\n",
    "                tempendindex = np.amin([len(frame_timestamps)-tempindex, post_window_size])\n",
    "                if i<(numtrials-1) and np.isfinite(framenumberfor_eventofinterest[i+1]):\n",
    "                    endindex = tempendindex\n",
    "                else:\n",
    "                    endindex = tempendindex\n",
    "                    prevendindex = tempindex+endindex\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex,:] = temp[tempindex-startindex:tempindex+endindex,:]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex,:] = temp[tempindex-tempstartindex:tempindex+endindex,:]\n",
    "                else: \n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex] = temp[tempindex-startindex:tempindex+endindex]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex] = temp[tempindex-tempstartindex:tempindex+endindex]\n",
    "            else:\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    align_to_plot[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                    align[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                else:\n",
    "                    align_to_plot[i,:] = np.nan*np.ones((window_size))\n",
    "                    align[i,:] = np.nan*np.ones((window_size))\n",
    "        if temp.shape[0]!=temp.size:         \n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]     \n",
    "        else:\n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]\n",
    "        return align, align_to_plot, framenumberfor_eventofinterest\n",
    "    \n",
    "    # align_activelever_cue, align_to_plot_activelever, framenumberfor_frameafter_activelever = \\\n",
    "    #     calculate_aligneddata_forevent(signalsT, activeleverall)  \n",
    "    # population_cue = np.nanmean(align_activelever_cue, axis=0).T-1\n",
    "\n",
    "    # align_activelever_no_cue, align_to_plot_activelever, framenumberfor_frameafter_activelever = \\\n",
    "    #     calculate_aligneddata_forevent(signalsT, activelevertimeout)  \n",
    "    # population_no_cue = np.nanmean(align_activelever_no_cue, axis=0).T-1\n",
    "\n",
    "    align_activelever_all, align_to_plot_activelever, framenumberfor_frameafter_activelever = calculate_aligneddata_forevent(signalsT, activeleverall)\n",
    "    population_data = np.nanmean(align_activelever_all, axis=0).T-1\n",
    "        \n",
    "    # return population_cue, population_no_cue, align_activelever_cue, align_activelever_no_cue, framerate, active_flags_df\n",
    "    return population_data, align_activelever_all, framerate, flags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME Testing\n",
    "\n",
    "trouble_animals = ['LCDD-PGa-T1']\n",
    "for animal in trouble_animals:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(acq_earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        populationData, alignedActiveLeverCueAll, framerate, flags = analyze_single_session(\n",
    "            #analysis parameters\n",
    "            os.path.join(acq_earlybasedir, animal, fov), \n",
    "            window_size, \n",
    "            pre_window_size\n",
    "            )\n",
    "        print(flags)\n",
    "        print(alignedActiveLeverCueAll.shape)\n",
    "        print(populationData.shape)\n",
    "        # np.save(os.path.join(earlybasedir, animal, fov, 'cuePopulation.npy'), cuePopulation)\n",
    "        # np.save(os.path.join(earlybasedir, animal, fov, 'noCuePopulation.npy'), noCuePopulation)\n",
    "        # np.save(os.path.join(earlybasedir, animal, fov, 'alignedActiveLeverCue.npy'), alignedActiveLeverCue)\n",
    "        # np.save(os.path.join(earlybasedir, animal, fov, 'alignedActiveLeverNoCue.npy'), alignedActiveLeverNoCue)\n",
    "        # cueFlags.to_csv(os.path.join(earlybasedir, animal, fov, 'active_flags.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early population\n",
    "excluded = []\n",
    "for animal in early_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(acq_earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            signalsData, alignedActiveLeverCueAll, framerate, flags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(acq_earlybasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            np.save(os.path.join(acq_earlybasedir, animal, fov, 'signalsData.npy'), signalsData)\n",
    "            np.save(os.path.join(acq_earlybasedir, animal, fov, 'alignedActiveLeverCueData.npy'), alignedActiveLeverCueAll)\n",
    "            np.save(os.path.join(acq_earlybasedir, animal, fov, 'classificationFlags.npy'), flags)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Early excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Middle population\n",
    "excluded = []\n",
    "for animal in middle_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(acq_middlebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            signalsData, alignedActiveLeverCueAll, framerate, flags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(acq_middlebasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            np.save(os.path.join(acq_middlebasedir, animal, fov, 'signalsData.npy'), signalsData)\n",
    "            np.save(os.path.join(acq_middlebasedir, animal, fov, 'alignedActiveLeverCueData.npy'), alignedActiveLeverCueAll)\n",
    "            np.save(os.path.join(acq_middlebasedir, animal, fov, 'classificationFlags.npy'), flags)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Middle excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Late population\n",
    "excluded = []\n",
    "for animal in late_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(acq_latebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            signalsData, alignedActiveLeverCueAll, framerate, flags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(acq_latebasedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            np.save(os.path.join(acq_latebasedir, animal, fov, 'signalsData.npy'), signalsData)\n",
    "            np.save(os.path.join(acq_latebasedir, animal, fov, 'alignedActiveLeverCueData.npy'), alignedActiveLeverCueAll)\n",
    "            np.save(os.path.join(acq_latebasedir, animal, fov, 'classificationFlags.npy'), flags)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Late excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cue Rein\n",
    "excluded = []\n",
    "for animal in cue_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(rst_cuedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        try:\n",
    "            signalsData, alignedActiveLeverCueAll, framerate, flags = analyze_single_session(\n",
    "                #analysis parameters\n",
    "                os.path.join(rst_cuedir, animal, fov), \n",
    "                window_size, \n",
    "                pre_window_size\n",
    "                )\n",
    "            np.save(os.path.join(rst_cuedir, animal, fov, 'signalsData.npy'), signalsData)\n",
    "            np.save(os.path.join(rst_cuedir, animal, fov, 'alignedActiveLeverCueData.npy'), alignedActiveLeverCueAll)\n",
    "            np.save(os.path.join(rst_cuedir, animal, fov, 'classificationFlags.npy'), flags)\n",
    "        except Exception as e:\n",
    "            print('***ERROR:', e, '***')\n",
    "            excluded.append(animal)\n",
    "print('Early excluded animals:', excluded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for stacking data\n",
    "def stack_data(indir, animals_of_interest, window, signals_file, aligned_levers_file):\n",
    "    temp_data = np.nan*np.ones((1, window))\n",
    "    for animal in animals_of_interest:\n",
    "            FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "            for fov in sorted(FOVs):\n",
    "                #load in data\n",
    "                signal_data = np.load(os.path.join(indir, animal, fov, signals_file))\n",
    "                lever_data = np.load(os.path.join(indir, animal, fov, aligned_levers_file))\n",
    "                #stack data\n",
    "                temp_data = np.vstack((temp_data, signal_data))\n",
    "    data = temp_data[1:,:]\n",
    "    return(data, lever_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for matching neurons to clusters based on criteria\n",
    "def find_indexes(indir, sub_animals_of_interest_array, original_full_stack, signal_file, cluster_labels_file):\n",
    "    indexes = []\n",
    "    for animal in sub_animals_of_interest_array:\n",
    "        FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(FOVs):\n",
    "            signal_data = np.load(os.path.join(indir, animal, fov, signal_file))\n",
    "            for neuron in range(len(signal_data)):\n",
    "                for row in range(len(original_full_stack)):\n",
    "                    if np.equal(signal_data[neuron], original_full_stack[row])[0]==True:\n",
    "                        indexes.append({'Animal': animal, 'Stack index': row, 'Cluster': cluster_labels_file[row]})\n",
    "    indexes = pd.DataFrame(indexes)\n",
    "    return(indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cue data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cue-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#stacking early data\n",
    "\n",
    "temp_early_cue, early_lever_cue = stack_data(acq_earlybasedir, early_animals_of_interest, window_size, 'signalsData.npy','alignedActiveLeverCueData.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_cue = temp_early_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_cue = temp_early_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_early_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "early_cue_mean = np.nanmean(early_cue, axis=0)\n",
    "\n",
    "print('Cue population shape:', early_cue.shape)\n",
    "print('Early labels shape:', acq_early_newlabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking middle data\n",
    "\n",
    "temp_middle_cue, middle_lever_cue = stack_data(acq_middlebasedir, middle_animals_of_interest, window_size, 'signalsData.npy','alignedActiveLeverCueData.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_middle_cue = temp_middle_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_cue = temp_middle_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_middle_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "middle_cue_mean = np.nanmean(middle_cue, axis=0)\n",
    "\n",
    "print('Cue population shape:', middle_cue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking late data\n",
    "\n",
    "temp_late_cue, late_lever_cues = stack_data(acq_latebasedir, late_animals_of_interest, window_size, 'signalsData.npy','alignedActiveLeverCueData.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_late_cue = temp_late_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_cue = temp_late_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_late_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "late_cue_mean = np.nanmean(late_cue, axis=0)\n",
    "\n",
    "print('Cue population shape:', late_cue.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cue within-session division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_p1 = early_cue[:int(len(early_cue)/2)]\n",
    "early_p2 = early_cue[int(len(early_cue)/2):]\n",
    "print('Part 1 shape:', early_p1.shape)\n",
    "print('Part 2 shape:', early_p2.shape)\n",
    "\n",
    "temp1 = np.nanmean(early_p1[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "temp2 = np.nanmean(early_p2[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "\n",
    "early_p1_sort = np.argsort(temp1)[::-1]\n",
    "early_p2_sort = np.argsort(temp2)[::-1]\n",
    "\n",
    "early_p1_orig_sort = np.argsort(sortresponse_early_cue[:int(len(sortresponse_early_cue)/2)])[::-1]\n",
    "early_p2_orig_sort = np.argsort(sortresponse_early_cue[int(len(sortresponse_early_cue)/2):])[::-1]\n",
    "\n",
    "early_p1_mean = np.nanmean(early_p1, axis=0)\n",
    "early_p2_mean = np.nanmean(early_p2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_p1 = middle_cue[:int(len(middle_cue)/2)]\n",
    "middle_p2 = middle_cue[int(len(middle_cue)/2):]\n",
    "print('Part 1 shape:', middle_p1.shape)\n",
    "print('Part 2 shape:', middle_p2.shape)\n",
    "\n",
    "temp1 = np.nanmean(middle_p1[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "temp2 = np.nanmean(middle_p2[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "\n",
    "middle_p1_sort = np.argsort(temp1)[::-1]\n",
    "middle_p2_sort = np.argsort(temp2)[::-1]\n",
    "\n",
    "middle_p1_orig_sort = np.argsort(sortresponse_middle_cue[:int(len(sortresponse_middle_cue)/2)])[::-1]\n",
    "middle_p2_orig_sort = np.argsort(sortresponse_middle_cue[int(len(sortresponse_middle_cue)/2):])[::-1]\n",
    "\n",
    "middle_p1_mean = np.nanmean(middle_p1, axis=0)\n",
    "middle_p2_mean = np.nanmean(middle_p2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_p1 = late_cue[:int(len(late_cue)/2)]\n",
    "late_p2 = late_cue[int(len(late_cue)/2):]\n",
    "print('Part 1 shape:', late_p1.shape)\n",
    "print('Part 2 shape:', late_p2.shape)\n",
    "\n",
    "temp1 = np.nanmean(late_p1[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "temp2 = np.nanmean(late_p2[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "\n",
    "late_p1_sort = np.argsort(temp1)[::-1]\n",
    "late_p2_sort = np.argsort(temp2)[::-1]\n",
    "\n",
    "late_p1_orig_sort = np.argsort(sortresponse_late_cue[:int(len(sortresponse_late_cue)/2)])[::-1]\n",
    "late_p2_orig_sort = np.argsort(sortresponse_late_cue[int(len(sortresponse_late_cue)/2):])[::-1]\n",
    "\n",
    "late_p1_mean = np.nanmean(late_p1, axis=0)\n",
    "late_p2_mean = np.nanmean(late_p2, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No-cue data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking early data\n",
    "\n",
    "temp_early_no_cue, early_lever_no_cue = stack_data(acq_earlybasedir, early_animals_of_interest, window_size, 'noCuePopulation.npy','alignedActiveLeverNoCue.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_no_cue = temp_early_no_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_no_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_no_cue = temp_early_no_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_no_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_early_no_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean\n",
    "early_no_cue_mean = np.nanmean(early_no_cue, axis=0)\n",
    "print(early_no_cue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking middle data\n",
    "\n",
    "temp_middle_no_cue, middle_lever_no_cue = stack_data(acq_middlebasedir, middle_animals_of_interest, window_size, 'noCuePopulation.npy','alignedActiveLeverNoCue.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_middle_no_cue = temp_middle_no_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_no_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_no_cue = temp_middle_no_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_no_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_middle_no_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean\n",
    "middle_no_cue_mean = np.nanmean(middle_no_cue, axis=0)\n",
    "\n",
    "print('No-cue population shape:', middle_no_cue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking late data\n",
    "\n",
    "temp_late_no_cue, late_lever_no_cue = stack_data(acq_latebasedir, late_animals_of_interest, window_size, 'noCuePopulation.npy','alignedActiveLeverNoCue.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_late_no_cue = temp_late_no_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_no_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_no_cue = temp_late_no_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_no_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_late_no_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean\n",
    "late_no_cue_mean = np.nanmean(late_no_cue, axis=0)\n",
    "\n",
    "print('No-cue population shape:', late_no_cue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "early_diff = (early_cue - early_no_cue)\n",
    "middle_diff = (middle_cue - middle_no_cue)\n",
    "late_diff = (late_cue - late_no_cue)\n",
    "\n",
    "early_diff_mean = np.mean(early_diff, axis=0)\n",
    "middle_diff_mean = np.mean(middle_diff, axis=0)\n",
    "late_diff_mean = np.mean(late_diff, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CueRein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_dir = os.path.join(basedir, 'CueRein')\n",
    "\n",
    "rst_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L2', 'ER-L1',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa5','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]  \n",
    "\n",
    "rst_cue, rst_cue_lever = stack_data(rst_dir, rst_animals_of_interest, window_size, 'cuePopulation.npy','alignedActiveLeverCueData.npy')\n",
    "rst_no_cue, rst_no_cue_lever = stack_data(rst_dir, rst_animals_of_interest, window_size, 'noCuePopulation.npy','alignedActiveLeverNoCue.npy')\n",
    "\n",
    "#num neurons cue\n",
    "numneurons_rst_cue = rst_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(rst_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "rst_cue = rst_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(rst_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_rst_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean\n",
    "rst_cue_mean = np.nanmean(rst_cue, axis=0)\n",
    "\n",
    "print('Cue population shape:', rst_cue.shape)\n",
    "\n",
    "\n",
    "#num neurons no-cue\n",
    "numneurons_rst_no_cue = rst_no_cue.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(rst_no_cue[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "rst_no_cue = rst_no_cue - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(rst_no_cue[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "sortresponse_rst_no_cue = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean\n",
    "rst_no_cue_mean = np.nanmean(rst_no_cue, axis=0)\n",
    "\n",
    "print('No-cue population shape:', rst_no_cue.shape)\n",
    "\n",
    "rst_diff = rst_cue - rst_no_cue\n",
    "rst_diff_mean = np.mean(rst_diff, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_p1 = rst_cue[:int(len(rst_cue)/2)]\n",
    "rst_p2 = rst_cue[int(len(rst_cue)/2):]\n",
    "print('Part 1 shape:', rst_p1.shape)\n",
    "print('Part 2 shape:', rst_p2.shape)\n",
    "\n",
    "temp1 = np.nanmean(rst_p1[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "temp2 = np.nanmean(rst_p2[:,pre_window_size-(1*int(framerate)):pre_window_size+(1*int(framerate))], axis=1)\n",
    "\n",
    "rst_p1_sort = np.argsort(temp1)[::-1]\n",
    "rst_p2_sort = np.argsort(temp2)[::-1]\n",
    "\n",
    "rst_p1_orig_sort = np.argsort(sortresponse_rst_cue[:int(len(sortresponse_rst_cue)/2)])[::-1]\n",
    "rst_p2_orig_sort = np.argsort(sortresponse_rst_cue[int(len(sortresponse_rst_cue)/2):])[::-1]\n",
    "\n",
    "rst_p1_mean = np.nanmean(rst_p1, axis=0)\n",
    "rst_p2_mean = np.nanmean(rst_p2, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the NaN values\n",
    "def filter_NAN(processed_data, windowsize, prewindowsize, framerate):\n",
    "        filtered_stack = np.nan*np.ones((1, windowsize))\n",
    "        for row in processed_data:\n",
    "                if np.isfinite(row[0]):\n",
    "                        filtered_stack = np.vstack((filtered_stack, row))\n",
    "        filtered_stack = filtered_stack[1:,:]\n",
    "        response = np.nanmean(filtered_stack[:,prewindowsize-(1*int(framerate)):prewindowsize+1*int(framerate)], axis=1)\n",
    "        sortresponse = np.argsort(response)[::-1]\n",
    "        return(filtered_stack, sortresponse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cue vs No-cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 11)) #rows x columns, width x height\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "# early cue plots\n",
    "ax = axs[0, 0] #[row, col]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_cue[sortresponse_early_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_early_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_cue], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 0]\n",
    "ax.plot(early_cue_mean)\n",
    "ax.plot(early_no_cue_mean)\n",
    "ax.plot(early_diff_mean, color='k', linestyle=':')\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "# early no-cue plots\n",
    "ax = axs[1, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_no_cue[sortresponse_early_no_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-NO CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % early_no_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_no_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# middle cue plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_cue[sortresponse_middle_cue, :], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_middle_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 1]\n",
    "ax.plot(middle_cue_mean)\n",
    "ax.plot(middle_no_cue_mean)\n",
    "ax.plot(middle_diff_mean, color='k', linestyle=':')\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "# middle no-cue plots\n",
    "ax = axs[1, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_no_cue[sortresponse_middle_no_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-NO CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % middle_no_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_no_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# late cue plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_cue[sortresponse_late_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_late_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_cue], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 2]\n",
    "ax.plot(late_cue_mean)\n",
    "ax.plot(late_no_cue_mean)\n",
    "ax.plot(late_diff_mean, color='k', linestyle=':')\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Cue', 'No cue','Difference'])\n",
    "\n",
    "# late no-cue plots\n",
    "ax = axs[1, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_no_cue[sortresponse_late_no_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-NO CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % late_no_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_no_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax = axs[0,3]\n",
    "# heatmap\n",
    "hm = sns.heatmap(rst_cue[sortresponse_rst_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(\"CUE REIN-CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_rst_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_rst_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "ax = axs[1,3]\n",
    "# heatmap\n",
    "hm = sns.heatmap(rst_no_cue[sortresponse_rst_no_cue,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(\"CUE REIN-NO CUE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_rst_no_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_rst_no_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "ax = axs[2,3]\n",
    "ax.plot(rst_cue_mean)\n",
    "ax.plot(rst_no_cue_mean)\n",
    "ax.plot(rst_diff_mean, color='k', linestyle=':')\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Cue', 'No cue','Difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(results, 'population/PFC-HeroinSA_cue-analysis_population.pdf'), format='PDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within-session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 11)) #rows x columns, width x height\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "#Early-early cue\n",
    "ax = axs[0, 0] #[row, col] \n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_p1[early_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Early: Pt. 1', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_early_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_cue], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 0]\n",
    "ax.plot(early_p1_mean)\n",
    "ax.plot(early_p2_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Pt. 1', 'Pt. 2'])\n",
    "\n",
    "#Late-early cue\n",
    "ax = axs[1, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_p2[early_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Early: Pt. 2', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % early_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# middle cue plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_p1[middle_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Middle: Pt. 1', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_middle_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 1]\n",
    "ax.plot(middle_p1_mean)\n",
    "ax.plot(middle_p2_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Pt. 1', 'Pt. 2'])\n",
    "\n",
    "# middle no-cue plots\n",
    "ax = axs[1, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_p2[middle_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Middle: Pt. 2', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % middle_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# late cue plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_p1[late_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Late: Pt. 1', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_late_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_cue], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 2]\n",
    "ax.plot(late_p1_mean)\n",
    "ax.plot(late_p2_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Pt. 1', 'Pt. 2'])\n",
    "\n",
    "# late no-cue plots\n",
    "ax = axs[1, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_p2[late_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title('ACQ Late: Pt. 2', fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % late_cue.shape[0], fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "\n",
    "ax = axs[0,3]\n",
    "# heatmap\n",
    "hm = sns.heatmap(rst_p1[rst_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(\"CueRein Pt. 1\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_rst_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_rst_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "ax = axs[1,3]\n",
    "# heatmap\n",
    "hm = sns.heatmap(rst_p2[rst_p1_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(\"CueRein Pt. 2\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_rst_cue, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_rst_cue], '--', linewidth=1.5, color='white')\n",
    "\n",
    "ax = axs[2,3]\n",
    "ax.plot(rst_p1_mean)\n",
    "ax.plot(rst_p2_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Pt. 1', 'Pt. 2'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering, KMeans\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import interpolate\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import (ModelDesc, EvalEnvironment, Term, EvalFactor, LookupFactor, dmatrices, INTERCEPT)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cue-all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps for cue\n",
    "\n",
    "sessions = [early_diff, middle_diff, late_diff, rst_diff] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "cmin = -.1\n",
    "\n",
    "fig, axs = plt.subplots(4,len(uniquelabels), figsize=(11,11))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early = early_diff[np.where(acq_early_newlabels==cluster)[0],:]\n",
    "    middle = middle_diff[np.where(acq_middle_newlabels==cluster)[0],:]\n",
    "    late = late_diff[np.where(acq_late_newlabels==cluster)[0],:]\n",
    "    rst = rst_diff[np.where(rst_newlabels==cluster)[0],:]\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early.shape[0]\n",
    "    middle_n = middle.shape[0]\n",
    "    late_n = late.shape[0]\n",
    "    rst_n = rst.shape[0]\n",
    "\n",
    "    #sort response\n",
    "    early_sort = np.argsort(np.mean(early[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    middle_sort = np.argsort(np.mean(middle[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    late_sort = np.argsort(np.mean(late[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    rst_sort = np.argsort(np.mean(rst[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    \n",
    "    #heatmaps\n",
    "    early_hm = sns.heatmap(\n",
    "                    early[early_sort],\n",
    "                    ax=axs[0, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[0, cluster].grid(False)\n",
    "    axs[0, cluster].set_xticks([])\n",
    "    axs[0, cluster].tick_params(width=0.5)    \n",
    "    axs[0, cluster].set_xticklabels([])\n",
    "    axs[0, cluster].set_yticks([])\n",
    "    axs[0, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "    middle_hm = sns.heatmap(\n",
    "                    middle[middle_sort],\n",
    "                    ax=axs[1, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[1, cluster].grid(False)\n",
    "    axs[1, cluster].set_xticks([])\n",
    "    axs[1, cluster].tick_params(width=0.5)    \n",
    "    axs[1, cluster].set_xticklabels([])\n",
    "    axs[1, cluster].set_yticks([])\n",
    "    axs[1, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    late_hm = sns.heatmap(\n",
    "                    late[late_sort],\n",
    "                    ax=axs[2, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[2, cluster].grid(False)\n",
    "    axs[2, cluster].set_xticks([])\n",
    "    axs[2, cluster].tick_params(width=0.5)    \n",
    "    axs[2, cluster].set_xticklabels([])\n",
    "    axs[2, cluster].set_yticks([])\n",
    "    axs[2, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    \n",
    "    rst_hm = sns.heatmap(\n",
    "                    rst[rst_sort],\n",
    "                    ax=axs[3,cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[3, cluster].grid(False)\n",
    "    axs[3, cluster].set_xticks([])\n",
    "    axs[3, cluster].tick_params(width=0.5)    \n",
    "    axs[3, cluster].set_xticklabels([])\n",
    "    axs[3, cluster].set_yticks([])\n",
    "    axs[3, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    axs[0, 0].set_ylabel('Early ACQ')\n",
    "    axs[1, 0].set_ylabel('Middle ACQ')\n",
    "    axs[2, 0].set_ylabel('Late ACQ')\n",
    "    axs[3, 0].set_ylabel('CueRein')\n",
    "\n",
    "    # axs[0, 0].set_ylabel('Early ACQ, N = %s'%(early_n))\n",
    "    # axs[1, 0].set_ylabel('Middle ACQ, N = %s'%(middle_n))\n",
    "    # axs[2, 0].set_ylabel('Late ACQ, N = %s'%(late_n))\n",
    "    # axs[3, 0].set_ylabel('CueRein, N = %s'%(rst_n))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12, horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(results, 'clusters/PFC-HeroinSA_cue-analysis_clusters-heatmaps.pdf'), format='PDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots for differences\n",
    "\n",
    "#vertical plot\n",
    "# fig, axs = plt.subplots(len(uniquelabels), 1, figsize=(8, 20))\n",
    "\n",
    "#horizontal plot\n",
    "fig, axs = plt.subplots(1,len(uniquelabels), figsize=(18, 5))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early = early_diff[np.where(acq_early_newlabels==cluster)[0],:]\n",
    "    middle = middle_diff[np.where(acq_middle_newlabels==cluster)[0],:]\n",
    "    late = late_diff[np.where(acq_late_newlabels==cluster)[0],:]\n",
    "    if cluster == 0:\n",
    "        rst = rst_diff[np.where(rst_newlabels==3)[0],:]\n",
    "    if cluster == 1:\n",
    "        rst = rst_diff[np.where(rst_newlabels==0)[0],:]\n",
    "    if cluster == 2:\n",
    "        rst = rst_diff[np.where(rst_newlabels==1)[0],:]\n",
    "    if cluster == 3:\n",
    "        rst = rst_diff[np.where(rst_newlabels==2)[0],:]\n",
    "\n",
    "    #means for polylines\n",
    "    early_m = np.mean(early, axis=0)\n",
    "    middle_m = np.mean(middle, axis=0)\n",
    "    late_m = np.mean(late, axis=0)\n",
    "    rst_m = np.mean(rst, axis=0)\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early.shape[0]\n",
    "    middle_n = middle.shape[0]\n",
    "    late_n = late.shape[0]\n",
    "    rst_n = rst.shape[0]\n",
    "    \n",
    "    #plot means\n",
    "    axs[cluster].plot(early_m, color='blue', linewidth=.5)\n",
    "    axs[cluster].plot(middle_m, color='grey', linewidth=.5)\n",
    "    axs[cluster].plot(late_m, color='red')\n",
    "    axs[cluster].plot(rst_m, color='black')\n",
    "\n",
    "#annotations\n",
    "    axs[cluster].legend(['Early ACQ, N: %s'%(early_n), \n",
    "                         'Middle ACQ, N: %s'%(middle_n), \n",
    "                         'Late ACQ, N: %s'%(late_n), \n",
    "                         'Cue RST, N: %s'%(rst_n)], \n",
    "                         fontsize=8)\n",
    "    axs[cluster].set_title('Cluster: %s'%(cluster+1))\n",
    "    axs[cluster].grid(False)\n",
    "    axs[cluster].set_xticks([])\n",
    "    axs[cluster].tick_params(width=0.5)    \n",
    "    axs[cluster].set_yticks([])\n",
    "    axs[cluster].set(ylim=(-.05, .05))    \n",
    "    axs[cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "    axs[cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots for cue\n",
    "\n",
    "#vertical plot\n",
    "# fig, axs = plt.subplots(len(uniquelabels), 1, figsize=(8, 20))\n",
    "\n",
    "#horizontal plot\n",
    "fig, axs = plt.subplots(1,len(uniquelabels), figsize=(18, 5))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early = early_cue[np.where(acq_early_newlabels==cluster)[0],:]\n",
    "    middle = middle_cue[np.where(acq_middle_newlabels==cluster)[0],:]\n",
    "    late = late_cue[np.where(acq_late_newlabels==cluster)[0],:]\n",
    "    if cluster == 0:\n",
    "        rst = rst_cue[np.where(rst_newlabels==3)[0],:]\n",
    "    if cluster == 1:\n",
    "        rst = rst_cue[np.where(rst_newlabels==0)[0],:]\n",
    "    if cluster == 2:\n",
    "        rst = rst_cue[np.where(rst_newlabels==1)[0],:]\n",
    "    if cluster == 3:\n",
    "        rst = rst_cue[np.where(rst_newlabels==2)[0],:]\n",
    "\n",
    "    #means for polylines\n",
    "    early_m = np.mean(early, axis=0)\n",
    "    middle_m = np.mean(middle, axis=0)\n",
    "    late_m = np.mean(late, axis=0)\n",
    "    rst_m = np.mean(rst, axis=0)\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early.shape[0]\n",
    "    middle_n = middle.shape[0]\n",
    "    late_n = late.shape[0]\n",
    "    rst_n = rst.shape[0]\n",
    "    \n",
    "    #plot means\n",
    "    axs[cluster].plot(early_m, color='blue', linewidth=.5)\n",
    "    axs[cluster].plot(middle_m, color='grey', linewidth=.5)\n",
    "    axs[cluster].plot(late_m, color='red')\n",
    "    axs[cluster].plot(rst_m, color='black')\n",
    "\n",
    "#annotations\n",
    "    axs[cluster].legend(['Early ACQ, N: %s'%(early_n), \n",
    "                         'Middle ACQ, N: %s'%(middle_n), \n",
    "                         'Late ACQ, N: %s'%(late_n), \n",
    "                         'Cue RST, N: %s'%(rst_n)], \n",
    "                         fontsize=8)\n",
    "    axs[cluster].set_title('Cluster: %s'%(cluster+1))\n",
    "    axs[cluster].grid(False)\n",
    "    axs[cluster].set_xticks([])\n",
    "    axs[cluster].tick_params(width=0.5)    \n",
    "    axs[cluster].set_yticks([])\n",
    "    axs[cluster].set(ylim=(-.2, .2))    \n",
    "    axs[cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "    axs[cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots for no-cue\n",
    "\n",
    "#vertical plot\n",
    "# fig, axs = plt.subplots(len(uniquelabels), 1, figsize=(8, 20))\n",
    "\n",
    "#horizontal plot\n",
    "fig, axs = plt.subplots(1,len(uniquelabels), figsize=(18, 5))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early = early_no_cue[np.where(acq_early_newlabels==cluster)[0],:]\n",
    "    middle = middle_no_cue[np.where(acq_middle_newlabels==cluster)[0],:]\n",
    "    late = late_no_cue[np.where(acq_late_newlabels==cluster)[0],:]\n",
    "    if cluster == 0:\n",
    "        rst = rst_no_cue[np.where(rst_newlabels==3)[0],:]\n",
    "    if cluster == 1:\n",
    "        rst = rst_no_cue[np.where(rst_newlabels==0)[0],:]\n",
    "    if cluster == 2:\n",
    "        rst = rst_no_cue[np.where(rst_newlabels==1)[0],:]\n",
    "    if cluster == 3:\n",
    "        rst = rst_no_cue[np.where(rst_newlabels==2)[0],:]\n",
    "\n",
    "    #means for polylines\n",
    "    early_m = np.mean(early, axis=0)\n",
    "    middle_m = np.mean(middle, axis=0)\n",
    "    late_m = np.mean(late, axis=0)\n",
    "    rst_m = np.mean(rst, axis=0)\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early.shape[0]\n",
    "    middle_n = middle.shape[0]\n",
    "    late_n = late.shape[0]\n",
    "    rst_n = rst.shape[0]\n",
    "    \n",
    "    #plot means\n",
    "    axs[cluster].plot(early_m, color='blue', linewidth=.5)\n",
    "    axs[cluster].plot(middle_m, color='grey', linewidth=.5)\n",
    "    axs[cluster].plot(late_m, color='red')\n",
    "    axs[cluster].plot(rst_m, color='black')\n",
    "\n",
    "#annotations\n",
    "    axs[cluster].legend(['Early ACQ, N: %s'%(early_n), \n",
    "                         'Middle ACQ, N: %s'%(middle_n), \n",
    "                         'Late ACQ, N: %s'%(late_n), \n",
    "                         'Cue RST, N: %s'%(rst_n)], \n",
    "                         fontsize=8)\n",
    "    axs[cluster].set_title('Cluster: %s'%(cluster+1))\n",
    "    axs[cluster].grid(False)\n",
    "    axs[cluster].set_xticks([])\n",
    "    axs[cluster].tick_params(width=0.5)    \n",
    "    axs[cluster].set_yticks([])\n",
    "    axs[cluster].set(ylim=(-.2, .2))    \n",
    "    axs[cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "    axs[cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,len(uniquelabels), figsize=(15, 15))\n",
    "\n",
    "for c, cluster in enumerate(uniquelabels):\n",
    "\n",
    "    early_m_cue = np.mean(early_cue[np.where(acq_early_newlabels==cluster)[0],:], axis=0)\n",
    "    middle_m_cue = np.mean(middle_cue[np.where(acq_middle_newlabels==cluster)[0],:], axis=0)\n",
    "    late_m_cue = np.mean(late_cue[np.where(acq_late_newlabels==cluster)[0],:], axis=0)\n",
    "    rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==3)[0],:], axis=0)\n",
    "\n",
    "    early_m_no_cue = np.mean(early_no_cue[np.where(acq_early_newlabels==cluster)[0],:], axis=0)\n",
    "    middle_m_no_cue = np.mean(middle_no_cue[np.where(acq_middle_newlabels==cluster)[0],:], axis=0)\n",
    "    late_m_no_cue = np.mean(late_no_cue[np.where(acq_late_newlabels==cluster)[0],:], axis=0)\n",
    "\n",
    "    early_m_diff = np.mean(early_diff[np.where(acq_early_newlabels==cluster)[0],:], axis=0)\n",
    "    middle_m_diff = np.mean(middle_diff[np.where(acq_middle_newlabels==cluster)[0],:], axis=0)\n",
    "    late_m_diff = np.mean(late_diff[np.where(acq_late_newlabels==cluster)[0],:], axis=0)\n",
    "\n",
    "    if cluster == 0:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==3)[0],:], axis=0)\n",
    "        rst_m_no_cue = np.mean(rst_no_cue[np.where(rst_newlabels==3)[0],:], axis=0)\n",
    "        rst_m_diff = np.mean(rst_diff[np.where(rst_newlabels==3)[0],:], axis=0)\n",
    "    elif cluster == 1:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==0)[0],:], axis=0)\n",
    "        rst_m_no_cue = np.mean(rst_no_cue[np.where(rst_newlabels==0)[0],:], axis=0)\n",
    "        rst_m_diff =  np.mean(rst_diff[np.where(rst_newlabels==0)[0],:], axis=0)\n",
    "    elif cluster == 2:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==1)[0],:], axis=0)\n",
    "        rst_m_no_cue = np.mean(rst_no_cue[np.where(rst_newlabels==1)[0],:], axis=0)\n",
    "        rst_m_diff =  np.mean(rst_diff[np.where(rst_newlabels==1)[0],:], axis=0)\n",
    "    elif cluster == 3:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==2)[0],:], axis=0)\n",
    "        rst_m_no_cue = np.mean(rst_no_cue[np.where(rst_newlabels==2)[0],:], axis=0)\n",
    "        rst_m_diff =  np.mean(rst_diff[np.where(rst_newlabels==2)[0],:], axis=0)\n",
    "\n",
    "    axs[0, c].plot(early_m_cue)\n",
    "    axs[0, c].plot(early_m_no_cue)\n",
    "    axs[0, c].plot(early_m_diff, color='k', alpha=.7, linewidth=.8)\n",
    "    axs[0, c].legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "    axs[1, c].plot(middle_m_cue)\n",
    "    axs[1, c].plot(middle_m_no_cue)\n",
    "    axs[1, c].plot(middle_m_diff, color='k', alpha=.7, linewidth=.8)\n",
    "    axs[1, c].legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "    axs[2, c].plot(late_m_cue)\n",
    "    axs[2, c].plot(late_m_no_cue)\n",
    "    axs[2, c].plot(late_m_diff, color='k', alpha=.7, linewidth=.8)\n",
    "    axs[2, c].legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "    axs[3, c].plot(rst_m_cue)\n",
    "    axs[3, c].plot(rst_m_no_cue)\n",
    "    axs[3, c].plot(rst_m_diff, color='k', alpha=.7, linewidth=.8)\n",
    "    axs[3, c].legend(['Cue', 'No cue', 'Difference'])\n",
    "\n",
    "    axs[0,c].set_title('Cluster: %s'%(c+1))\n",
    "\n",
    "    for i in range(4):\n",
    "        axs[i,c].grid(False)\n",
    "        axs[i,c].set_xticks([])\n",
    "        axs[i,c].tick_params(width=0.5)    \n",
    "        axs[i,c].set_yticks([])\n",
    "        axs[i,c].set(ylim=(-.15, .15))    \n",
    "        axs[i,c].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[i,c].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "\n",
    "axs[0,0].set_ylabel('Early ACQ')\n",
    "axs[1,0].set_ylabel('Middle ACQ')\n",
    "axs[2,0].set_ylabel('Late ACQ')\n",
    "axs[3,0].set_ylabel('Cue RST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(results, 'clusters/PFC-HeroinSA_cue-analysis_clusters-polylines.pdf'), format='PDF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within-session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps for cue\n",
    "\n",
    "sessions = [early_p1, middle_p1, late_p1, rst_p1] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "cmin = -.1\n",
    "\n",
    "fig, axs = plt.subplots(4,len(uniquelabels), figsize=(11,11))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early1 = early_p1[np.where(acq_early_newlabels[:int(len(acq_early_newlabels)/2)]==cluster)[0],:]\n",
    "    middle1 = middle_p1[np.where(acq_middle_newlabels[:int(len(acq_middle_newlabels)/2)]==cluster)[0],:]\n",
    "    late1 = late_p1[np.where(acq_late_newlabels[:int(len(acq_late_newlabels)/2)]==cluster)[0],:]\n",
    "    if cluster == 0:\n",
    "        rst1 = rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==3)[0],:]\n",
    "    elif cluster == 1:\n",
    "        rst1 = rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==0)[0],:]\n",
    "    elif cluster == 2:\n",
    "        rst1 = rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==1)[0],:]\n",
    "    else:\n",
    "        rst1 = rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==2)[0],:]\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early1.shape[0]\n",
    "    middle_n = middle1.shape[0]\n",
    "    late_n = late1.shape[0]\n",
    "    rst_n = rst1.shape[0]\n",
    "\n",
    "    #sort response\n",
    "    early_sort = np.argsort(np.mean(early1[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    middle_sort = np.argsort(np.mean(middle1[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    late_sort = np.argsort(np.mean(late1[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    rst_sort = np.argsort(np.mean(rst1[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    \n",
    "    #heatmaps\n",
    "    early_hm = sns.heatmap(\n",
    "                    early1[early_sort],\n",
    "                    ax=axs[0, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[0, cluster].grid(False)\n",
    "    axs[0, cluster].set_xticks([])\n",
    "    axs[0, cluster].tick_params(width=0.5)    \n",
    "    axs[0, cluster].set_xticklabels([])\n",
    "    axs[0, cluster].set_yticks([])\n",
    "    axs[0, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "    middle_hm = sns.heatmap(\n",
    "                    middle1[middle_sort],\n",
    "                    ax=axs[1, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[1, cluster].grid(False)\n",
    "    axs[1, cluster].set_xticks([])\n",
    "    axs[1, cluster].tick_params(width=0.5)    \n",
    "    axs[1, cluster].set_xticklabels([])\n",
    "    axs[1, cluster].set_yticks([])\n",
    "    axs[1, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    late_hm = sns.heatmap(\n",
    "                    late1[late_sort],\n",
    "                    ax=axs[2, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[2, cluster].grid(False)\n",
    "    axs[2, cluster].set_xticks([])\n",
    "    axs[2, cluster].tick_params(width=0.5)    \n",
    "    axs[2, cluster].set_xticklabels([])\n",
    "    axs[2, cluster].set_yticks([])\n",
    "    axs[2, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    \n",
    "    rst_hm = sns.heatmap(\n",
    "                    rst1[rst_sort],\n",
    "                    ax=axs[3,cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[3, cluster].grid(False)\n",
    "    axs[3, cluster].set_xticks([])\n",
    "    axs[3, cluster].tick_params(width=0.5)    \n",
    "    axs[3, cluster].set_xticklabels([])\n",
    "    axs[3, cluster].set_yticks([])\n",
    "    axs[3, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    axs[0, 0].set_ylabel('Early ACQ')\n",
    "    axs[1, 0].set_ylabel('Middle ACQ')\n",
    "    axs[2, 0].set_ylabel('Late ACQ')\n",
    "    axs[3, 0].set_ylabel('CueRein')\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12, horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps for cue\n",
    "\n",
    "sessions = [early_p2, middle_p2, late_p2, rst_p2] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "cmin = -.1\n",
    "\n",
    "fig, axs = plt.subplots(4,len(uniquelabels), figsize=(11,11))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    #cluster data\n",
    "    early2 = early_p2[np.where(acq_early_newlabels[int(len(acq_early_newlabels)/2):]==cluster)[0],:]\n",
    "    middle2 = middle_p2[np.where(acq_middle_newlabels[int(len(acq_middle_newlabels)/2):]==cluster)[0],:]\n",
    "    late2 = late_p2[np.where(acq_late_newlabels[int(len(acq_late_newlabels)/2):]==cluster)[0],:]\n",
    "    if cluster == 0:\n",
    "        rst2 = rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==3)[0],:]\n",
    "    elif cluster == 1:\n",
    "        rst2 = rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==0)[0],:]\n",
    "    elif cluster == 2:\n",
    "        rst2 = rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==1)[0],:]\n",
    "    else:\n",
    "        rst2 = rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==2)[0],:]\n",
    "\n",
    "    #num neurons\n",
    "    early_n = early2.shape[0]\n",
    "    middle_n = middle2.shape[0]\n",
    "    late_n = late2.shape[0]\n",
    "    rst_n = rst2.shape[0]\n",
    "\n",
    "    #sort response\n",
    "    early_sort = np.argsort(np.mean(early2[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    middle_sort = np.argsort(np.mean(middle2[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    late_sort = np.argsort(np.mean(late2[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    rst_sort = np.argsort(np.mean(rst2[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "    \n",
    "    #heatmaps\n",
    "    early_hm = sns.heatmap(\n",
    "                    early2[early_sort],\n",
    "                    ax=axs[0, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[0, cluster].grid(False)\n",
    "    axs[0, cluster].set_xticks([])\n",
    "    axs[0, cluster].tick_params(width=0.5)    \n",
    "    axs[0, cluster].set_xticklabels([])\n",
    "    axs[0, cluster].set_yticks([])\n",
    "    axs[0, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "    middle_hm = sns.heatmap(\n",
    "                    middle2[middle_sort],\n",
    "                    ax=axs[1, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[1, cluster].grid(False)\n",
    "    axs[1, cluster].set_xticks([])\n",
    "    axs[1, cluster].tick_params(width=0.5)    \n",
    "    axs[1, cluster].set_xticklabels([])\n",
    "    axs[1, cluster].set_yticks([])\n",
    "    axs[1, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    late_hm = sns.heatmap(\n",
    "                    late2[late_sort],\n",
    "                    ax=axs[2, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[2, cluster].grid(False)\n",
    "    axs[2, cluster].set_xticks([])\n",
    "    axs[2, cluster].tick_params(width=0.5)    \n",
    "    axs[2, cluster].set_xticklabels([])\n",
    "    axs[2, cluster].set_yticks([])\n",
    "    axs[2, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "    \n",
    "    rst_hm = sns.heatmap(\n",
    "                    rst2[rst_sort],\n",
    "                    ax=axs[3,cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "    axs[3, cluster].grid(False)\n",
    "    axs[3, cluster].set_xticks([])\n",
    "    axs[3, cluster].tick_params(width=0.5)    \n",
    "    axs[3, cluster].set_xticklabels([])\n",
    "    axs[3, cluster].set_yticks([])\n",
    "    axs[3, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "\n",
    "    axs[0, 0].set_ylabel('Early ACQ')\n",
    "    axs[1, 0].set_ylabel('Middle ACQ')\n",
    "    axs[2, 0].set_ylabel('Late ACQ')\n",
    "    axs[3, 0].set_ylabel('CueRein')\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12, horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,len(uniquelabels), figsize=(15, 15))\n",
    "\n",
    "for c, cluster in enumerate(uniquelabels):\n",
    "\n",
    "    #full session data\n",
    "    early_m_cue = np.mean(early_cue[np.where(acq_early_newlabels==cluster)[0],:], axis=0)\n",
    "    middle_m_cue = np.mean(middle_cue[np.where(acq_middle_newlabels==cluster)[0],:], axis=0)\n",
    "    late_m_cue = np.mean(late_cue[np.where(acq_late_newlabels==cluster)[0],:], axis=0)\n",
    "    if cluster == 0:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==3)[0],:], axis=0)\n",
    "    elif cluster == 1:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==0)[0],:], axis=0)\n",
    "    elif cluster == 2:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==1)[0],:], axis=0)\n",
    "    else:\n",
    "        rst_m_cue = np.mean(rst_cue[np.where(rst_newlabels==2)[0],:], axis=0)\n",
    "\n",
    "    #session pt 1\n",
    "    early1_m = np.mean(early_p1[np.where(acq_early_newlabels[:int(len(acq_early_newlabels)/2)]==cluster)[0],:], axis=0)\n",
    "    middle1_m = np.mean(middle_p1[np.where(acq_middle_newlabels[:int(len(acq_middle_newlabels)/2)]==cluster)[0],:], axis=0)\n",
    "    late1_m = np.mean(late_p1[np.where(acq_late_newlabels[:int(len(acq_late_newlabels)/2)]==cluster)[0],:], axis=0)\n",
    "    if cluster == 0:\n",
    "        rst1_m = np.mean(rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==3)[0],:], axis=0)\n",
    "    elif cluster == 1:\n",
    "        rst1_m = np.mean(rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==0)[0],:], axis=0)\n",
    "    elif cluster == 2:\n",
    "        rst1_m = np.mean(rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==1)[0],:], axis=0)\n",
    "    else:\n",
    "        rst1_m = np.mean(rst_p1[np.where(rst_newlabels[:int(len(rst_newlabels)/2)]==2)[0],:], axis=0)\n",
    "\n",
    "    #session pt2\n",
    "    early2_m = np.mean(early_p2[np.where(acq_early_newlabels[int(len(acq_early_newlabels)/2):]==cluster)[0],:],axis=0)\n",
    "    middle2_m = np.mean(middle_p2[np.where(acq_middle_newlabels[int(len(acq_middle_newlabels)/2):]==cluster)[0],:],axis=0)\n",
    "    late2_m = np.mean(late_p2[np.where(acq_late_newlabels[int(len(acq_late_newlabels)/2):]==cluster)[0],:],axis=0)\n",
    "    if cluster == 0:\n",
    "        rst2_m = np.mean(rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==3)[0],:],axis=0)\n",
    "    elif cluster == 1:\n",
    "        rst2_m = np.mean(rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==0)[0],:],axis=0)\n",
    "    elif cluster == 2:\n",
    "        rst2_m = np.mean(rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==1)[0],:],axis=0)\n",
    "    else:\n",
    "        rst2_m = np.mean(rst_p2[np.where(rst_newlabels[int(len(rst_newlabels)/2):]==2)[0],:],axis=0)\n",
    "\n",
    "    #differences\n",
    "    early_diff = early1_m - early2_m\n",
    "    middle_diff = middle1_m - middle2_m\n",
    "    late_diff = late1_m - late2_m\n",
    "    rst_diff = rst1_m - rst2_m\n",
    "\n",
    "    axs[0, c].plot(early_m_cue, color='k')\n",
    "    axs[0, c].plot(early1_m)\n",
    "    axs[0, c].plot(early2_m)\n",
    "    axs[0, c].plot(early_diff, color='k', linestyle=':')\n",
    "    axs[0, c].legend(['Full Session', 'Pt. 1', 'Pt. 2','Difference'])\n",
    "\n",
    "    axs[1, c].plot(middle_m_cue, color='k')\n",
    "    axs[1, c].plot(middle1_m)\n",
    "    axs[1, c].plot(middle2_m)\n",
    "    axs[1, c].plot(middle_diff, color='k', linestyle=':')\n",
    "    axs[1, c].legend(['Full Session', 'Pt. 1', 'Pt. 2','Difference'])\n",
    "\n",
    "    axs[2, c].plot(late_m_cue, color='k')\n",
    "    axs[2, c].plot(late1_m)\n",
    "    axs[2, c].plot(late2_m)\n",
    "    axs[2, c].plot(late_diff, color='k', linestyle=':')\n",
    "    axs[2, c].legend(['Full Session', 'Pt. 1', 'Pt. 2','Difference'])\n",
    "\n",
    "    axs[3, c].plot(rst_m_cue, color='k')\n",
    "    axs[3, c].plot(rst1_m)\n",
    "    axs[3, c].plot(rst2_m)\n",
    "    axs[3, c].plot(rst_diff, color='k', linestyle=':')\n",
    "    axs[3, c].legend(['Full Session', 'Pt. 1', 'Pt. 2','Difference'])\n",
    "\n",
    "    axs[0,c].set_title('Cluster: %s'%(c+1))\n",
    "\n",
    "    for i in range(4):\n",
    "        axs[i,c].grid(False)\n",
    "        axs[i,c].set_xticks([])\n",
    "        axs[i,c].tick_params(width=0.5)    \n",
    "        axs[i,c].set_yticks([])\n",
    "        axs[i,c].set(ylim=(-.15, .15))    \n",
    "        axs[i,c].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[i,c].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "\n",
    "axs[0,0].set_ylabel('Early ACQ')\n",
    "axs[1,0].set_ylabel('Middle ACQ')\n",
    "axs[2,0].set_ylabel('Late ACQ')\n",
    "axs[3,0].set_ylabel('Cue RST')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivoxel Pattern Analysis *(decoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "\n",
    "#classifiers and models\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval, rand\n",
    "from skopt import BayesSearchCV\n",
    "import lightgbm as lgb\n",
    "from hpsklearn import HyperoptEstimator, sgd, any_classifier, any_preprocessing, svc\n",
    "\n",
    "\n",
    "#preproccesing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "import traceback\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def gs_model(y, X):\n",
    "    hyperparameters = {'kernel': ['rbf'], \n",
    "                       'gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                       'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "    clf = GridSearchCV(SVC(), hyperparameters, cv=10) \n",
    "    clf.fit(X, y)\n",
    "    accuracy = clf.best_score_\n",
    "    return accuracy\n",
    "\n",
    "def rs_model(y, X):\n",
    "    hyperparameters = {'kernel': ['rbf'], \n",
    "                       'gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                       'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "                       }\n",
    "    search = RandomizedSearchCV(SVC(), hyperparameters, cv=10, n_iter=10)\n",
    "    search.fit(X, y)\n",
    "    accuracy = search.best_score_\n",
    "    return accuracy\n",
    "    \n",
    "def svmregression(y, X):\n",
    "    hyperparameters = {'kernel': ['rbf'], \n",
    "                       'cluster': np.logspace(-3, 3, 5),\n",
    "                      'epsilon': np.logspace(-3, 3, 5),\n",
    "                      'gamma': np.logspace(-5, 5, 10)}\n",
    "    clf = GridSearchCV(SVR(), hyperparameters, cv=10)\n",
    "    if np.all(np.isnan(X)):\n",
    "        R2=np.nan\n",
    "    else:\n",
    "        clf.fit(X, y)\n",
    "        R2 = clf.best_score_\n",
    "    #reference for 10-fold cross-validation http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf\n",
    "    return R2\n",
    "\n",
    "def calculate_t(x, y):\n",
    "    Sp= np.sqrt((np.nanstd(x)**2 + np.nanstd(y)**2)/2)\n",
    "    denominator = Sp*(np.sqrt(2/len(x)))\n",
    "    numerator = np.nanmean(x) - np.nanmean(y)\n",
    "    t = numerator/denominator\n",
    "    return t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "<br>GridSearchCV, Random SearchCV, and Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== STARTING ==========\n",
      "Group: CueRein \n",
      "Animal: CTL1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_47604\\3000674672.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m                                    'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]}\n\u001b[0;32m     69\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0macc_tally\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jboqu\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "groups = ['CueRein']\n",
    "indir_list = [rst_cuedir]\n",
    "animals_of_interest_list = [cue_animals_of_interest[:1]]\n",
    "session_analysis_split_by_ensemble = ['Yes'] ###SET TO ['Yes'] OR TO ['No']\n",
    "decoding = ['Neuron', 'Trial'] ###SET TO Neuron or Session and Trial or Lick\n",
    "numclusters = 4\n",
    "\n",
    "#initialize epochs\n",
    "baseline_epoch = [1, 8]\n",
    "response_epoch = [pre_window_size, pre_window_size+12]\n",
    "\n",
    "numshuffles = 1 \n",
    "classification_accuracy = {}\n",
    "uniquelabels = np.arange(numclusters)\n",
    "numneuronsincluster = np.nan*np.ones((numclusters,))\n",
    "\n",
    "print('========== STARTING ==========')\n",
    "datadir=0\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    acc_tally = []\n",
    "    animals_of_interest = animals_of_interest_list[index]\n",
    "    indir = indir_list[index]\n",
    "\n",
    "    numneuronstillnow = 0 \n",
    "    for animal in animals_of_interest:\n",
    "        print('Group:', group, '\\nAnimal:', animal)\n",
    "        fovs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(fovs):\n",
    "            trials = np.load(os.path.join(indir, animal, fov, 'alignedActiveLeverCueData.npy'))\n",
    "            flags = np.load(os.path.join(indir, animal, fov, 'classificationFlags.npy')) #flags should match num trials\n",
    "            #references to shape\n",
    "            num_trials = trials.shape[0]\n",
    "            numneuronsinfov = trials.shape[2]\n",
    "\n",
    "            baseline = np.nan*np.ones((num_trials ,numneuronsinfov))\n",
    "            response = np.nan*np.ones((num_trials, numneuronsinfov))\n",
    "            \n",
    "            positives = len(flags[flags==1])\n",
    "            negatives = len(flags[flags==0])\n",
    "            activeflag = np.hstack((np.zeros((negatives)), np.ones((positives))))\n",
    "\n",
    "\n",
    "\n",
    "            newbaseline = np.empty(shape=(trials.shape))\n",
    "            newresponse = np.empty(shape=(trials.shape))\n",
    "\n",
    "            for neuron in range(numneuronsinfov):\n",
    "                baseline[:,neuron] = np.nanmean(trials[:,baseline_epoch[0]:baseline_epoch[1],neuron], axis=1)\n",
    "                response[:,neuron] = np.nanmean(trials[:,response_epoch[0]:response_epoch[1],neuron], axis=1)\n",
    "\n",
    "                newbaseline[:,baseline_epoch[0]:baseline_epoch[1],:neuron] = trials[:,baseline_epoch[0]:baseline_epoch[1],:neuron]\n",
    "                newresponse[:,response_epoch[0]:response_epoch[1],:neuron] = trials[:,response_epoch[0]:response_epoch[1],:neuron]\n",
    "                newactivity = np.vstack((newbaseline, newresponse))\n",
    "\n",
    "                neuralactivity_trialtype = np.vstack((baseline, response))\n",
    "                y = activeflag\n",
    "                X = neuralactivity_trialtype[:,neuron] #y and X need to have matching shape values\n",
    "\n",
    "\n",
    "                X = newactivity\n",
    "                X = X.reshape(len(y), int(np.size(newactivity)/len(y)))\n",
    "\n",
    "                #RandomSearchCV model\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "                hyperparameters = {'kernel': ['rbf'], \n",
    "                                   'gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                                   'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "                clf = RandomizedSearchCV(SVC(), hyperparameters, cv=5, n_iter=20, n_jobs=-1, refit=True)\n",
    "                clf.fit(X, y)\n",
    "                accuracy = np.round(clf.best_score_,2)*100\n",
    "                acc_tally.append(accuracy)\n",
    "            numneuronstillnow += numneuronsinfov\n",
    "        print('Average accuracy:', '{0:.0f}'.format(np.mean(np.array(acc_tally)))+'%')\n",
    "        print('Highest accuracy:', '{0:.0f}'.format(max(acc_tally))+'%')\n",
    "        print('Lowest accuracy:', '{0:.0f}'.format(min(acc_tally))+'%')\n",
    "        print()\n",
    "print('========== FINISHED ==========')\n",
    "\n",
    "\"\"\"\n",
    "Notes:\n",
    "- GridSearchCV time for CTL1 on Josh's computer: 1m 1.6s, Average accuracy: 67%\n",
    "- RandomSearchCV time for CTL1 on Josh's computer: 28.6s, Average accuracy: 66%\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Methods tried:\n",
    "\n",
    "for neuron in range(numneuronsinfov):\n",
    "    new_baseline = np.nan*np.ones((trials.shape[0]))\n",
    "    new_response = np.nan*np.ones((trials.shape[0]))\n",
    "    for trial in range(num_trials):\n",
    "        new_baseline[baseline_epoch[0]:baseline_epoch[1]] = trials[baseline_epoch[0]:baseline_epoch[1], trial, neuron]\n",
    "        new_response[response_epoch[0]:response_epoch[1]] = trials[response_epoch[0]:response_epoch[1],trial, neuron]\n",
    "        X = np.vstack((np.nanmean(new_baseline), np.nanmean(new_response)))\n",
    "        # X = X.reshape(len(activeflag),2)\n",
    "        y = activeflag[:trial]\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    activity = np.vstack((trials[trial,baseline_epoch,:],trials[trial,response_epoch,:]))\n",
    "    flag = np.ones(activity.shape[1])\n",
    "    X = activity\n",
    "    X = X.reshape(len(flag),4)\n",
    "    y = flag\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding: Neuron, Cue\n",
    "Population: Reinstatement\n",
    "<br>Group(s): CueRein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize decoding directories\n",
    "decoding_dict_results_dir =r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis/cue\\results\\decoding\\dictionaries'%(user)\n",
    "decode_results_dir = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis/cue\\results\\decoding'%(user)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['CueRein']\n",
    "indir_list = [rst_cuedir]\n",
    "animals_of_interest_list = [cue_animals_of_interest]\n",
    "session_analysis_split_by_ensemble = ['Yes'] ###SET TO ['Yes'] OR TO ['No']\n",
    "decoding = ['Neuron', 'Trial'] ###SET TO Neuron or Session and Trial or Lick\n",
    "numclusters = 4\n",
    "\n",
    "#initialize epochs\n",
    "baseline_epoch = [1, 8]\n",
    "response_epoch = [pre_window_size, pre_window_size+12]\n",
    "\n",
    "numshuffles = 1 \n",
    "classification_accuracy = {}\n",
    "uniquelabels = np.arange(numclusters)\n",
    "numneuronsincluster = np.nan*np.ones((numclusters,))\n",
    "\n",
    "print('========== STARTING ==========')\n",
    "datadir=0\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    classification_accuracy[group] = {}\n",
    "    classification_accuracy[group]['individualneurons'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['shuffled'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['unshuffled'] = {}\n",
    "\n",
    "    animals_of_interest = animals_of_interest_list[index]\n",
    "    indir = indir_list[index]\n",
    "\n",
    "    numneuronstillnow = 0 \n",
    "    for animal in animals_of_interest:\n",
    "        print('Group:', group, '\\nAnimal:', animal)\n",
    "        fovs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(fovs):\n",
    "            trials = np.load(os.path.join(indir, animal, fov, 'alignedActiveLeverCueData.npy'))\n",
    "            flags = np.load(os.path.join(indir, animal, fov, 'classificationFlags.npy')) #flags should match num trials\n",
    "            #references to shape\n",
    "            num_trials = trials.shape[0]\n",
    "            numneuronsinfov = trials.shape[2]\n",
    "\n",
    "            baseline = np.nan*np.ones((num_trials ,numneuronsinfov))\n",
    "            response = np.nan*np.ones((num_trials, numneuronsinfov))\n",
    "\n",
    "            positives = len(flags[flags==1])\n",
    "            negatives = len(flags[flags==0])\n",
    "            activeflag = np.hstack((np.zeros((negatives)), np.ones((positives))))\n",
    "\n",
    "            for neuron in range(numneuronsinfov):\n",
    "                baseline[:,neuron] = np.nanmean(trials[:,baseline_epoch[0]:baseline_epoch[1],neuron], axis=1)\n",
    "                response[:,neuron] = np.nanmean(trials[:,response_epoch[0]:response_epoch[1],neuron], axis=1)\n",
    "\n",
    "                neuralactivity_trialtype = np.vstack((baseline, response))\n",
    "                y = activeflag\n",
    "                X = neuralactivity_trialtype[:,neuron] #y and X need to have matching shape values\n",
    "                X = X.reshape(len(y), 2)\n",
    "                classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron] = binaryclassifier(y, X)\n",
    "                #shuffling data\n",
    "                shuffledresults = np.nan*np.ones((numshuffles,))\n",
    "                for shuffleid in range(numshuffles):\n",
    "                    new_y = np.random.permutation(activeflag) #shuffled flag\n",
    "                    shuffledresults[shuffleid] = binaryclassifier(new_y, X)\n",
    "                classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron] = shuffledresults\n",
    "            numneuronstillnow += numneuronsinfov\n",
    "    print()\n",
    "print('========== FINISHED ==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionaries as .npy files\n",
    "variable_to_save = 'Cue'\n",
    "groups = ['CueRein']\n",
    "decoding_dict_results_dir =r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\reinstatement\\results\\decoding\\dictionaries'%(user)\n",
    "\n",
    "for g, group in enumerate (groups):\n",
    "    unshuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['unshuffled'])), dtype=object)\n",
    "    shuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['shuffled'])), dtype=object)\n",
    "    stacked = np.vstack((unshuffled[:,1], shuffled[:,1]))\n",
    "    np.save(os.path.join(decoding_dict_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group,variable_to_save,decoding[0])),stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show what's in each file\n",
    "for i in os.listdir(decoding_dict_results_dir):\n",
    "    print(i)\n",
    "    infile = np.load(os.path.join(decoding_dict_results_dir, i), allow_pickle=True)\n",
    "    print(infile.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .cdf plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DECODING CDF PLOTS FOR EARLY, MIDDLE, AND LATE DATA\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "population = 'CueRein'\n",
    "variables_to_analyze = ['Cue']\n",
    "groups = ['CueRein'] \n",
    "# color = (['k'],['tab:red'], ['tab:green'],['tab:blue'])\n",
    "ls = ['--','solid']\n",
    "\n",
    "d = {}\n",
    "###THIS SECTION IS FOR LOADING AND PLOTTING SAVED POPULATION DECODING ARRAYS (BY NEURON OR SESSION)\n",
    "for v, variable in enumerate (variables_to_analyze):\n",
    "    d[variable] = {}\n",
    "    all_shuffle_for_variable=[]\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "    for g, group in enumerate(groups):\n",
    "        d[variable][group] = {}\n",
    "        d[variable][group] = np.array(np.load(os.path.join(decoding_dict_results_dir,\n",
    "                                                           'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group,variable,analyze_by)), \n",
    "                                                           allow_pickle=True).astype(float))\n",
    "        temp_unshuffle_nonans, temp_shuffle_nonans = ([],[])\n",
    "        temp_unshuffle,temp_shuffle = (d[variable][group][0],d[variable][group][1])\n",
    "\n",
    "        for i in range(len(temp_unshuffle)):\n",
    "            if np.isfinite(temp_unshuffle[i]):\n",
    "                temp_unshuffle_nonans = np.append(temp_unshuffle_nonans, temp_unshuffle[i])\n",
    "        for i in range(len(temp_shuffle)):\n",
    "            if np.isfinite(temp_shuffle[i]):\n",
    "                temp_shuffle_nonans = np.append(temp_shuffle_nonans, temp_shuffle[i])\n",
    "                \n",
    "       ##NORMALIZING\n",
    "        mean_shuffle = np.mean(temp_shuffle_nonans)\n",
    "        temp_unshuffle_nonans = temp_unshuffle_nonans - mean_shuffle\n",
    "        temp_shuffle_nonans = temp_shuffle_nonans - mean_shuffle\n",
    "\n",
    "        plt.hist((temp_unshuffle_nonans),  density=True, cumulative=True,\\\n",
    "            label = 'Unshuffle', histtype='step',\\\n",
    "            linestyle = ('-'), bins = 'auto', color = 'k', linewidth=2)\n",
    "\n",
    "        all_shuffle_for_variable = np.append(all_shuffle_for_variable, d[variable][group][1])\n",
    "        if g == len(groups)-1:\n",
    "            plt.hist((temp_shuffle_nonans),  density=True, cumulative=True,\\\n",
    "                label = 'Shuffle', histtype='step',\\\n",
    "                linestyle = ('--'), bins ='auto', color = 'grey', linewidth=2)\n",
    "                \n",
    "        ax[0].text(.2,1-g*.5,'%s-Shuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_shuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_shuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_shuffle_nonans)))\n",
    "        ax[0].text(.2, .9-g*.5,'%s-Unhuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_unshuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_unshuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_unshuffle_nonans)))\n",
    "        t, p = stats.ttest_ind(temp_shuffle_nonans,\\\n",
    "            temp_unshuffle_nonans, equal_var=False)\n",
    "        ax[0].text(.2, .8-g*.5, '%s T-test: t = '%(group) + '{0:.3g}'.format(t) + ', p = ' + '{0:.3g}'.format(p))\n",
    "\n",
    "    ax[0].get_xaxis().set_visible(False)\n",
    "    ax[0].get_yaxis().set_visible(False)\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].spines['left'].set_visible(False)\n",
    "    ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "    plt.legend(loc=2)\n",
    "    plt.title('%s-level analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "    \n",
    "    plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding.PDF'%(population, variable, analyze_by)), format = 'PDF')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "\n",
    "### DECODING CDF PLOTS FOR EARLY, MIDDLE, AND LATE DATA\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "variables_to_analyze = ['Cue']\n",
    "groups = ['CueRein'] \n",
    "dir_list = [rst_cuedir]\n",
    "color = (['k'],['tab:red'], ['tab:green'],['tab:blue'], ['tab:yellow'])\n",
    "ls = ['--','solid']\n",
    "bins = np.arange(0.4,0.8,0.01)  \n",
    "\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    newlabels = np.load((os.path.join(dir_list[index], 'cluster_list_per_session_CueDrugTMT.npy')))\n",
    "    dict_file = np.load(os.path.join(decoding_dict_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group, variables_to_analyze[0], analyze_by)),allow_pickle = True).astype(float)\n",
    "    for variable in variables_to_analyze:\n",
    "        print('Group:', group)\n",
    "        d = {}\n",
    "        d[variable]={}\n",
    "        all_shuffle_for_variable = []\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "        for cluster in range(numclusters):\n",
    "            d[variable][cluster] = {}\n",
    "            file_max = len(dict_file[1])\n",
    "            fit = np.array(newlabels[:file_max])\n",
    "            temp_array = np.squeeze(dict_file[:,np.where(fit==cluster)[0]])\n",
    "            d[variable][cluster] = temp_array\n",
    "\n",
    "            shuffled_mean = np.nanmean(d[variable][cluster][1])\n",
    "            normalized_unshuffled = d[variable][cluster][0] - shuffled_mean\n",
    "            normalized_shuffled = d[variable][cluster][1] - shuffled_mean\n",
    "            all_shuffle_for_variable = np.append(all_shuffle_for_variable, normalized_shuffled)\n",
    "\n",
    "            plt.hist((normalized_unshuffled), density=True, cumulative=True,\\\n",
    "                                label = ['Cluster %s'%(cluster+1)], histtype='step', linestyle = '-',\\\n",
    "                                bins = 'auto', linewidth=2)\n",
    "            ax[0].text(-0.15, (1.1-cluster*.16), \n",
    "                    ('Ensemble '+str(cluster+1)+' (shuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_shuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_shuffled[np.where(np.isfinite(normalized_shuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_shuffled)))\n",
    "            ax[0].text(-0.15, 1.03-cluster*.16, \n",
    "                    ('Ensemble '+str(cluster+1)+' (unshuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_unshuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_unshuffled[np.where(np.isfinite(normalized_unshuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_unshuffled)))\n",
    "            if cluster == len(uniquelabels)-1:\n",
    "                plt.hist((all_shuffle_for_variable), density=True, cumulative=True,\\\n",
    "                    label = ['Shuffled'], histtype='step', linestyle = '--',\\\n",
    "                    bins = 'auto', linewidth=2, color = 'k', alpha = .8)\n",
    "                ax[0].text(-0.15, .8-cluster*.16, \n",
    "                    ('All shuffled stats -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean(all_shuffle_for_variable)) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(all_shuffle_for_variable[np.where(np.isfinite(all_shuffle_for_variable))]))) +\n",
    "                    ', N: ' + str(len(all_shuffle_for_variable)))\n",
    "\n",
    "            ax[0].get_xaxis().set_visible(False)\n",
    "            ax[0].get_yaxis().set_visible(False)\n",
    "            ax[0].spines['top'].set_visible(False)\n",
    "            ax[0].spines['right'].set_visible(False)\n",
    "            ax[0].spines['left'].set_visible(False)\n",
    "            ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "            plt.legend(loc=2)\n",
    "            plt.title('%s-level Cluster analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "        #change plot title as needed\n",
    "        plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_%s_Normalized-Cluster_Decoding.PDF'%(population, group, variable, analyze_by)), format = 'PDF')\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding: Neuron, Cue\n",
    "Population: Acquisition\n",
    "<br>Group(s): Early, Middle, and Late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize decoding directories\n",
    "decoding_dict_results_dir =r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\cue/results\\decoding\\dictionaries'%(user) #specify model type folder\n",
    "decode_results_dir = r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\cue/results\\decoding'%(user)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionaries\n",
    "\n",
    "groups = ['Early','Middle', 'Late']\n",
    "indir_list = [acq_earlybasedir, acq_middlebasedir, acq_latebasedir]\n",
    "animals_of_interest_list = [early_animals_of_interest, middle_animals_of_interest, late_animals_of_interest]\n",
    "# groups = ['Early']\n",
    "# indir_list = [acq_earlybasedir]\n",
    "# animals_of_interest_list = [early_animals_of_interest]\n",
    "session_analysis_split_by_ensemble = ['Yes'] ###SET TO ['Yes'] OR TO ['No']\n",
    "decoding = ['Neuron', 'Trial'] ###SET TO Neuron or Session and Trial or Lick\n",
    "numclusters = 4\n",
    "\n",
    "#initialize epochs\n",
    "baseline_epoch = [1, 8]\n",
    "response_epoch = [pre_window_size, pre_window_size+12]\n",
    "\n",
    "numshuffles = 1 \n",
    "classification_accuracy = {}\n",
    "uniquelabels = np.arange(numclusters)\n",
    "numneuronsincluster = np.nan*np.ones((numclusters,))\n",
    "\n",
    "print('========== STARTING ==========')\n",
    "datadir=0\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    classification_accuracy[group] = {}\n",
    "    classification_accuracy[group]['individualneurons'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['shuffled'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['unshuffled'] = {}\n",
    "\n",
    "    animals_of_interest = animals_of_interest_list[index]\n",
    "    indir = indir_list[index]\n",
    "\n",
    "    numneuronstillnow = 0 \n",
    "    for animal in animals_of_interest:\n",
    "        print('Group:', group, '\\nAnimal:', animal)\n",
    "        fovs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(fovs):\n",
    "            trials = np.load(os.path.join(indir, animal, fov, 'alignedActiveLeverCueData.npy'))\n",
    "            flags = np.load(os.path.join(indir, animal, fov, 'classificationFlags.npy')) #flags should match num trials\n",
    "\n",
    "            #eliminate NaN's\n",
    "            for i in reversed(range(trials.shape[0])): ###reversed to prevent deletion from messing up indexing\n",
    "                if np.isnan(np.mean(trials[i,:,:])):\n",
    "                    trials = np.delete(trials, i, axis = 0)\n",
    "                    flags = np.delete(flags, i)\n",
    "\n",
    "            #references to shape\n",
    "            num_trials = trials.shape[0]\n",
    "            numneuronsinfov = trials.shape[2]\n",
    "\n",
    "            if num_trials < 7:\n",
    "                print('*** Error: insufficient trials ***')\n",
    "            else:\n",
    "                baseline = np.nan*np.ones((num_trials ,numneuronsinfov))\n",
    "                response = np.nan*np.ones((num_trials, numneuronsinfov))\n",
    "\n",
    "                #creating array of flags to classify predictions\n",
    "                positives = len(flags[flags==1])\n",
    "                negatives = len(flags[flags==0])\n",
    "                activeflag = np.hstack((np.zeros((negatives)), np.ones((positives))))\n",
    "                \n",
    "                for neuron in range(numneuronsinfov):\n",
    "                    baseline[:,neuron] = np.nanmean(trials[:,baseline_epoch[0]:baseline_epoch[1],neuron], axis=1)\n",
    "                    response[:,neuron] = np.nanmean(trials[:,response_epoch[0]:response_epoch[1],neuron], axis=1)\n",
    "                    neuralactivity_trialtype = np.vstack((baseline, response))\n",
    "\n",
    "                    #assigning training data\n",
    "                    y = activeflag\n",
    "                    X = neuralactivity_trialtype[:,neuron] #y and X need to have matching shape values\n",
    "                    try:\n",
    "                        X = X.reshape(len(y), 2)\n",
    "                    except:\n",
    "                        X = np.expand_dims(X, axis=1)\n",
    "\n",
    "                    #unshuffled data accuracy classifications\n",
    "                    classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron] = binaryclassifier(y, X)\n",
    "                    print('     Unshuffled accuracy:', classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron])\n",
    "                    #shuffled data accuracy classifications\n",
    "                    shuffledresults = np.nan*np.ones((numshuffles,))\n",
    "                    for shuffleid in range(numshuffles):\n",
    "                        new_y = np.random.permutation(activeflag) #shuffled flag\n",
    "                        shuffledresults[shuffleid] = binaryclassifier(new_y, X)\n",
    "                        print('     Shuffled accuracy:', shuffledresults[shuffleid])\n",
    "                    classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron] = shuffledresults\n",
    "                numneuronstillnow += numneuronsinfov\n",
    "        print()\n",
    "print('========== FINISHED ==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionaries as .npy files\n",
    "variable_to_save = 'Cue'\n",
    "# groups = ['Early', 'Middle', 'Late']\n",
    "groups = ['Early']\n",
    "decoding_dict_results_dir =r'C:\\Users\\%s\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\cue-analysis\\acquisition-reinstatement\\results\\decoding\\dictionaries'%(user)\n",
    "\n",
    "for g, group in enumerate (groups):\n",
    "    try:\n",
    "        unshuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['unshuffled'])), dtype=object)\n",
    "        shuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['shuffled'])), dtype=object)\n",
    "        stacked = np.vstack((unshuffled[:,1], shuffled[:,1]))\n",
    "        np.save(os.path.join(decoding_dict_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group,variable_to_save,decoding[0])),stacked)\n",
    "    except Exception as e:\n",
    "        print('*** Error:', e, '***')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .cdf plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdf plots for neurons\n",
    "\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "population = 'Acquisition'\n",
    "variables_to_analyze = ['Cue']\n",
    "variable = 'Cue'\n",
    "groups = ['Early', 'Middle', 'Late'] \n",
    "# groups = ['Early']\n",
    "colors = (['k'],['tab:red'], ['tab:green'],['tab:blue'])\n",
    "ls = ['--','solid']\n",
    "\n",
    "d = {}\n",
    "d[variable] = {}\n",
    "all_shuffle_for_variable=[]\n",
    "fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "for g, group in enumerate(groups):\n",
    "    d[variable][group] = {}\n",
    "    d[variable][group] = np.array(np.load(os.path.join(decoding_dict_results_dir,\n",
    "                                                        'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group,variable,analyze_by)), \n",
    "                                                        allow_pickle = True).astype(float))\n",
    "    temp_unshuffle_nonans, temp_shuffle_nonans = ([],[])\n",
    "    temp_unshuffle,temp_shuffle = (d[variable][group][0],d[variable][group][1])\n",
    "\n",
    "    for i in range(len(temp_unshuffle)):\n",
    "        if np.isfinite(temp_unshuffle[i]):\n",
    "            temp_unshuffle_nonans = np.append(temp_unshuffle_nonans, temp_unshuffle[i])\n",
    "    for i in range(len(temp_shuffle)):\n",
    "        if np.isfinite(temp_shuffle[i]):\n",
    "            temp_shuffle_nonans = np.append(temp_shuffle_nonans, temp_shuffle[i])\n",
    "            \n",
    "    #normalize data\n",
    "    mean_shuffle = np.mean(temp_shuffle_nonans)\n",
    "    temp_unshuffle_nonans = temp_unshuffle_nonans - mean_shuffle\n",
    "    temp_shuffle_nonans = temp_shuffle_nonans - mean_shuffle\n",
    "    \n",
    "    plt.hist((temp_unshuffle_nonans),  density=True, cumulative=True,\\\n",
    "        label = '%s-Unshuffle'%(group), histtype='step',\\\n",
    "        linestyle = ('-'), bins = 'auto', color = colors[g], linewidth=2)\n",
    "\n",
    "    all_shuffle_for_variable = np.append(all_shuffle_for_variable, d[variable][group][1])\n",
    "    if g == len(groups)-1:\n",
    "        plt.hist((temp_shuffle_nonans),  density=True, cumulative=True,\\\n",
    "            label = 'Shuffle', histtype='step',\\\n",
    "            linestyle = ('--'), bins ='auto', color = 'k', alpha=.8,linewidth=2)\n",
    "            \n",
    "    ax[0].text(.2,1-g*.5,'%s-Shuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_shuffle_nonans)) + \\\n",
    "        ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_shuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_shuffle_nonans)))\n",
    "    ax[0].text(.2, .9-g*.5,'%s-Unhuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_unshuffle_nonans)) + \\\n",
    "        ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_unshuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_unshuffle_nonans)))\n",
    "    t, p = stats.ttest_ind(temp_shuffle_nonans,\\\n",
    "        temp_unshuffle_nonans, equal_var=False)\n",
    "    ax[0].text(.2, .8-g*.5, '%s T-test: t = '%(group) + '{0:.3g}'.format(t) + ', p = ' + '{0:.3g}'.format(p))\n",
    "\n",
    "ax[0].get_xaxis().set_visible(False)\n",
    "ax[0].get_yaxis().set_visible(False)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[0].spines['left'].set_visible(False)\n",
    "ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.title('%s-level analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "\n",
    "plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding.PDF'%(population, variable, analyze_by)), format = 'PDF')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdf plots for clusters\n",
    "\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "variables_to_analyze = ['Cue']\n",
    "groups = ['Early', 'Middle', 'Late'] \n",
    "dir_list = [acq_earlybasedir, acq_middlebasedir, acq_latebasedir]\n",
    "color = (['k'],['tab:red'], ['tab:green'],['tab:blue'], ['tab:yellow'])\n",
    "ls = ['--','solid']\n",
    "bins = np.arange(0.4,0.8,0.01)  \n",
    "\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    newlabels = np.load((os.path.join(dir_list[index], 'cluster_list_per_session_Acquisition.npy')))\n",
    "    dict_file = np.load(os.path.join(decoding_dict_results_dir, 'PFC-HeroinSA_%s_%s_%s_Decoding-dict.npy'%(group, variables_to_analyze[0], analyze_by)),allow_pickle = True).astype(float)\n",
    "    for variable in variables_to_analyze:\n",
    "        print('Group:', group)\n",
    "        d = {}\n",
    "        d[variable]={}\n",
    "        all_shuffle_for_variable = []\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "        for cluster in range(numclusters):\n",
    "            d[variable][cluster] = {}\n",
    "            file_max = len(dict_file[1])\n",
    "            fit = np.array(newlabels[:file_max])\n",
    "            temp_array = np.squeeze(dict_file[:,np.where(fit==cluster)[0]])\n",
    "            d[variable][cluster] = temp_array\n",
    "\n",
    "            shuffled_mean = np.nanmean(d[variable][cluster][1])\n",
    "            normalized_unshuffled = d[variable][cluster][0] - shuffled_mean\n",
    "            normalized_shuffled = d[variable][cluster][1] - shuffled_mean\n",
    "            all_shuffle_for_variable = np.append(all_shuffle_for_variable, normalized_shuffled)\n",
    "\n",
    "            plt.hist((normalized_unshuffled), density=True, cumulative=True,\\\n",
    "                                label = ['Cluster %s'%(cluster+1)], histtype='step', linestyle = '-',\\\n",
    "                                bins = 'auto', linewidth=2)\n",
    "            ax[0].text(-0.15, (1.1-cluster*.16), \n",
    "                    ('Ensemble '+str(cluster+1)+' (shuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_shuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_shuffled[np.where(np.isfinite(normalized_shuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_shuffled)))\n",
    "            ax[0].text(-0.15, 1.03-cluster*.16, \n",
    "                    ('Ensemble '+str(cluster+1)+' (unshuffled) -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean((normalized_unshuffled))) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(normalized_unshuffled[np.where(np.isfinite(normalized_unshuffled))]))) +\n",
    "                    ', N: ' + str(len(normalized_unshuffled)))\n",
    "            if cluster == len(uniquelabels)-1:\n",
    "                plt.hist((all_shuffle_for_variable), density=True, cumulative=True,\\\n",
    "                    label = ['Shuffled'], histtype='step', linestyle = '--',\\\n",
    "                    bins = 'auto', linewidth=2, color = 'k', alpha = .8)\n",
    "                ax[0].text(-0.15, .8-cluster*.16, \n",
    "                    ('All shuffled stats -> ' +\n",
    "                    'Mean: ' + '%.3g'%(np.nanmean(all_shuffle_for_variable)) +\n",
    "                    ', SEM: ' + '%.3g'%(stats.sem(all_shuffle_for_variable[np.where(np.isfinite(all_shuffle_for_variable))]))) +\n",
    "                    ', N: ' + str(len(all_shuffle_for_variable)))\n",
    "\n",
    "            ax[0].get_xaxis().set_visible(False)\n",
    "            ax[0].get_yaxis().set_visible(False)\n",
    "            ax[0].spines['top'].set_visible(False)\n",
    "            ax[0].spines['right'].set_visible(False)\n",
    "            ax[0].spines['left'].set_visible(False)\n",
    "            ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "            plt.legend(loc=2)\n",
    "            plt.title('%s-level Cluster analysis | Population: %s | Decoding: %s'%(analyze_by, population, variable))\n",
    "        plt.savefig(os.path.join(decode_results_dir, 'PFC-HeroinSA_%s_%s_%s_%s_Normalized-Cluster_Decoding.PDF'%(population, group, variable, analyze_by)), format = 'PDF')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "josh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
