{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@Josh Boquiren\\nVer. I\\nOTIS Lab MUSC\\n5.16.23\\n\\nNotes:\\n- preloaded for RST-CueDrugTMT\\n- I left an empty fig.save statement for convenience. Just fill in file path and file name\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@Josh Boquiren\n",
    "Ver. I\n",
    "OTIS Lab MUSC\n",
    "5.16.23\n",
    "\n",
    "Notes:\n",
    "- preloaded for RST-CueDrugTMT\n",
    "- I left an empty fig.save statement for convenience. Just fill in file path and file name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories/Animals of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#directory and file manager\n",
    "import os\n",
    "\n",
    "#statistics\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import roc_auc_score as auROC\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RST directories\n",
    "\n",
    "population = 'Cue-Drug-TMT'\n",
    "\n",
    "basedir = r'/Users/elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Project Datasets/PFC Self-Admin Analysis'\n",
    "\n",
    "earlybasedir = r'/Users/elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Project Datasets/PFC Self-Admin Analysis/CueRein'\n",
    "middlebasedir = r'/Users/elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Project Datasets/PFC Self-Admin Analysis/DrugRein'\n",
    "latebasedir = r'/Users/elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Project Datasets/PFC Self-Admin Analysis/TMTRein'\n",
    "\n",
    "models = r'/Users\\elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Repositories/PFC_Self-Admin_Analysis/PFC_Self-Admin_Analysis/active-inactive_analysis/universal_models'\n",
    "results = r'/Users\\elizabethdoncheck/Dropbox/2P Imaging Projects/Beth/Josh/Repositories/PFC_Self-Admin_Analysis/PFC_Self-Admin_Analysis/active-inactive_analysis/reinstatement/results'\n",
    "\n",
    "#cluster list files\n",
    "early_newlabels = np.load(os.path.join(earlybasedir, 'cluster_list_per_session_CueDrugTMT.npy')) #put clustering files in a folder to loop through\n",
    "middle_newlabels = np.load(os.path.join(middlebasedir, 'cluster_list_per_session_CueDrugTMT.npy'))\n",
    "late_newlabels = np.load(os.path.join(latebasedir, 'cluster_list_per_session_CueDrugTMT.npy'))\n",
    "\n",
    "#for later plot titles\n",
    "plot_titles = ['CUE', 'DRUG', 'TMT']\n",
    "population_title = \"RST\"\n",
    "\n",
    "#animals of interest\n",
    "early_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L1','ER-L2',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa5','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]  \n",
    "middle_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L1','ER-L2',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ]  \n",
    "late_animals_of_interest = [\n",
    "    'CTL1',\n",
    "    'ER-L1','ER-L2',\n",
    "    'IG-19',\n",
    "    'LCDD-PGa1','LCDD-PGa3','LCDD-PGa4','LCDD-PGa6',\n",
    "    'LCDD-PGa-T1','LCDD-PGa-T2','LCDD-PGa-T3','LCDD-PGa-T4','LCDD-PGa-T5',\n",
    "    'PGa-T1','PGa-T2','PGa-T3'\n",
    "    ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame rate variables\n",
    "frameaveraging = 4\n",
    "timebetweenframes = 33.3333\n",
    "framerate = 30\n",
    "framerate = timebetweenframes/frameaveraging #raw frame rate\n",
    "averagedframerate = timebetweenframes/frameaveraging #averaged frame rate\n",
    "print('Frame rate:', framerate)\n",
    "print('Averaged frame rate:', averagedframerate)\n",
    "\n",
    "#window size variables\n",
    "pre_window_size = int(10*framerate) #How many frames per trial before origin to be plotted?\n",
    "window_size =  int((pre_window_size*2)+(3*framerate)) #How many frames do you want to plot around the origin?\n",
    "post_window_size = window_size - pre_window_size\n",
    "baselinefirstframe = 0\n",
    "baselinelastframe = int(1*framerate)\n",
    "infusionframe = int(pre_window_size+(3*framerate))\n",
    "print('Prewindow size:', pre_window_size)\n",
    "print('Window size:', window_size)\n",
    "print('Postwindow size:', post_window_size)\n",
    "\n",
    "#set cell tracking\n",
    "tracking = 'No' ### 'Yes' or 'No'\n",
    "sorting = 'Yes' ### 'Yes' or 'No'\n",
    "sorttoearly = 'No' ###'Yes' or 'No'; This is for sorting, but align to early data. 'Sorting' must also be Yes\n",
    "csv_id_for_tracking = 'CUE-DRUG-TMT'\n",
    "\n",
    "#tracking\n",
    "if tracking == 'Yes':\n",
    "    population_active_tracked_early = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_middle = np.nan*np.ones((1,window_size))\n",
    "    population_active_tracked_late = np.nan*np.ones((1,window_size))\n",
    "    print ('Cell Tracking')\n",
    "else:\n",
    "    print ('No Cell Tracking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making single session analysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for fixing dropped frames\n",
    "def fix_any_dropped_frames(frame_timestamps):\n",
    "    first_frame = np.array([0])\n",
    "    last_frame = np.array([int(np.max(frame_timestamps)+(500*timebetweenframes))])\n",
    "    frame_index_temp = np.concatenate((first_frame,frame_timestamps, last_frame)) ###adds frame to timepoint '0' and an extra 500 frames at end\n",
    "    frames_missed = [] ###creates empty list for us to add timestamps for missed frames\n",
    "    for i in range(len(frame_index_temp)-1): ###iterates through each collected frame\n",
    "            numframes_missed = int(np.round((frame_index_temp[i+1]-frame_index_temp[i])\\\n",
    "                /timebetweenframes)-1) ### number of missed frames per frame interval\n",
    "            if numframes_missed > 0: \n",
    "                for j in range(numframes_missed):\n",
    "                    frame_missed = np.array([frame_index_temp[i] + (int(timebetweenframes * (j+1)))])\n",
    "                    frames_missed = np.concatenate((frames_missed, frame_missed))\n",
    "    corrected_frame_index = np.array(sorted(np.concatenate((frame_index_temp, frames_missed))))\n",
    "    return corrected_frame_index\n",
    "\n",
    "#method for fixing assumed frames\n",
    "def fix_assumed_frames(frames):\n",
    "    dropped_frames = []\n",
    "    diff_frames = np.diff(frames)\n",
    "    inter_frame_interval = 33\n",
    "    frame_drop_idx = np.where(diff_frames>1.5*inter_frame_interval)[0]\n",
    "    for idx in frame_drop_idx:\n",
    "        numframesdropped = int(np.round((frames[idx+1]-frames[idx])/(inter_frame_interval+0.0))-1)\n",
    "        temp = [frames[idx]+a*inter_frame_interval for a in range(1,numframesdropped+1)]\n",
    "        dropped_frames.extend(temp)\n",
    "    corrected_frames = np.sort(np.concatenate((frames, np.array(dropped_frames))))\n",
    "    return corrected_frames\n",
    "\n",
    "#generate behavior data\n",
    "try:\n",
    "    assumed_frames = np.load(os.path.join(models, 'assumed_frames.npy'))\n",
    "    assumed_frame_timestamps = np.load(os.path.join(models, 'assumed_frame_timestamps.npy'))\n",
    "    print(\"Loaded behavior data.\")\n",
    "except:\n",
    "    #load in data\n",
    "    behaviordata_noframes = sio.loadmat(r\"C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Project Datasets\\PFC Self-Admin Analysis\\PFC Self Admin Data\\Spreadsheets\\matfile_noframes_3.mat\")\n",
    "    eventlog_noframes = np.squeeze(behaviordata_noframes['eventlog'])\n",
    "\n",
    "    #parse desired data\n",
    "    max_of_eventlog_noframes = max(eventlog_noframes[:,1]) #all rows, second column\n",
    "    length_of_eventlog_noframes = len(eventlog_noframes[:,1])\n",
    "    x = np.vstack((eventlog_noframes, eventlog_noframes, eventlog_noframes))\n",
    "    x[length_of_eventlog_noframes:,1]= x[length_of_eventlog_noframes:,1]+max_of_eventlog_noframes\n",
    "    x[length_of_eventlog_noframes*2:,1]= x[length_of_eventlog_noframes*2:,1]+(2*max_of_eventlog_noframes)\n",
    "    eventlog_noframes = x\n",
    "\n",
    "    assumed_frames = fix_any_dropped_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    assumed_frame_timestamps = fix_assumed_frames(eventlog_noframes[eventlog_noframes[:,0]==9,1]) ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "\n",
    "    np.save(os.path.join(models, 'assumed_frames'), assumed_frames)\n",
    "    np.save(os.path.join(models, 'assumed_frame_timestamps'), assumed_frame_timestamps)\n",
    "    print(\"Behavior data processed and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def fit_regression(x, y):\n",
    "    lm = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    x_range = sm.add_constant(np.array([x.min(), x.max()]))\n",
    "    x_range_pred = lm.predict(x_range)\n",
    "    return lm.pvalues[1], lm.params[1], x_range[:,1], x_range_pred, lm.rsquared\n",
    "\n",
    "def CDFplot(x, ax, color=None, label='', linetype='-'):\n",
    "    x = np.array(x)\n",
    "    ix=np.argsort(x)\n",
    "    ax.plot(x[ix], ECDF(x)(x)[ix], linetype, color=color, label=label)\n",
    "    return ax\n",
    "\n",
    "def fit_regression_and_plot(x, y, ax, plot_label='', color='k', markersize=3):\n",
    "    #linetype is a string like 'bo'\n",
    "    pvalue, slope, temp, temppred, R2 = fit_regression(x, y)    \n",
    "    ax.scatter(x, y, color=color, label='%s p=%.3f\\nR$^2$=%.3f'% (plot_label, pvalue, R2), s=markersize)\n",
    "    ax.plot(temp, temppred, color=color)\n",
    "    return ax, slope, pvalue, R2\n",
    "\n",
    "\n",
    "def ismembertol(x, y, tol=1E-6):\n",
    "    # Are elements of x in y within tolerance of tol?\n",
    "    # x and y must be 1d numpy arrays\n",
    "    sortx = np.sort(x)\n",
    "    orderofx = np.argsort(x)\n",
    "    sorty = np.sort(y)\n",
    "    current_y_idx = 0\n",
    "    result = np.nan*np.zeros(x.shape)\n",
    "    for i, elt in enumerate(sortx):\n",
    "        temp = sorty[current_y_idx:]\n",
    "        if np.any(np.abs(temp-elt)<=tol):\n",
    "            result[orderofx[i]]=1\n",
    "        else:\n",
    "            result[orderofx[i]]=0\n",
    "        temp = np.argwhere(sorty>elt)\n",
    "        if temp.size>0:\n",
    "            current_y_idx = temp[0][0]\n",
    "    return result\n",
    "\n",
    "def mkdir_p(path):\n",
    "    #makes a new directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise \n",
    "            \n",
    "def framenumberforevent(event, frame_timestamps):\n",
    "    framenumber = np.nan*np.zeros(event.shape)\n",
    "    for ie, e in enumerate(event):\n",
    "        #print('     e:', e)\n",
    "        if np.isnan(e):\n",
    "            framenumber[ie] = np.nan\n",
    "        else:\n",
    "            temp = np.nonzero(frame_timestamps<=e)[0]\n",
    "            if temp.shape[0]>0:\n",
    "                framenumber[ie] = np.nonzero(frame_timestamps<=e)[0][-1]\n",
    "            else:\n",
    "                framenumber[ie] = 0\n",
    "    return framenumber\n",
    "\n",
    "def calculate_num_licks_for_each_frame(framenumberforlicks, numframes):\n",
    "    numlicksperframe = np.nan*np.ones((numframes,))\n",
    "    for i in range(numframes):\n",
    "        numlicksperframe[i] = np.sum(framenumberforlicks==i)\n",
    "    return numlicksperframe\n",
    "\n",
    "def calculate_auROC(x,y,offset_to_zero=True):\n",
    "    U, p = stats.mannwhitneyu(x,y)\n",
    "    labels = np.concatenate((np.ones(x.shape), np.zeros(y.shape)))\n",
    "    data = np.concatenate((x,y))\n",
    "    A = auROC(labels, data)\n",
    "    if offset_to_zero:\n",
    "        return (2*(A-0.5), p)\n",
    "    else:\n",
    "        return (A, p)\n",
    "    \n",
    "def Benjamini_Hochberg_correction(vector_of_pvals,\n",
    "                                  alpha = 0.05):\n",
    "    # This function ipltements the BH FDR correction\n",
    "    \n",
    "    # Parameters:\n",
    "    # Vector of p values from the different tests\n",
    "    # alpha:significance level\n",
    "    \n",
    "    # Returns: Corrected p values. All the p values that are above the FDR threshold are set to 1. \n",
    "    #          Remaining p values are unchanged.\n",
    "    \n",
    "    sortedpvals = np.sort(vector_of_pvals)\n",
    "    orderofpvals = np.argsort(vector_of_pvals)\n",
    "    m = sortedpvals[np.isfinite(sortedpvals)].shape[0] #Total number of hypotheses\n",
    "    for i in range(m):\n",
    "        if sortedpvals[i] > (i+1)*alpha/m:\n",
    "            k = i\n",
    "            break\n",
    "        elif i == m-1:\n",
    "            k = m-1\n",
    "        \n",
    "    correctedpvals = np.copy(vector_of_pvals)\n",
    "    correctedpvals[orderofpvals[k:]] = 1\n",
    "    correctedpvals[np.isnan(vector_of_pvals)] = np.nan\n",
    "    return correctedpvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for animal analysis\n",
    "def analyze_single_session(indir, window_size, pre_window_size):    \n",
    "    tempfiles = next(os.walk(indir))[2]\n",
    "    npyfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "        and 'extractedsignals_raw' in f]\n",
    "    matfiles = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat']\n",
    "\n",
    "    if len(npyfiles) > 1:\n",
    "        npyfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' \n",
    "            and 'extractedsignals_raw' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        if npyfile[0][0]!='nan':\n",
    "            npyfile = npyfile [0]\n",
    "        matfile = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' \n",
    "            and not 'results' in f \n",
    "            and not 'part2' in f \n",
    "            and not 'part3' in f \n",
    "            and not 'part4' in f]\n",
    "        matfile = matfile [0]\n",
    "    else:\n",
    "        npyfile = npyfiles[0]\n",
    "        matfile = matfiles[0]\n",
    "    \n",
    "    signals = np.squeeze(np.load(os.path.join(indir, npyfile)))\n",
    "    numneurons = signals.shape[0] \n",
    "   \n",
    "    behaviordata = sio.loadmat(os.path.join(indir, matfile))\n",
    "    eventlog = np.squeeze(behaviordata['eventlog'])\n",
    "    licks = np.squeeze(behaviordata['licks'])\n",
    "    lastframe_timestamp_part1 = np.max(eventlog)\n",
    "    \n",
    "    if len(npyfiles) > 1:\n",
    "        npyfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part2' in f]\n",
    "        matfiles2 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part2' in f and not 'results' in f]\n",
    "        npyfile2 = npyfiles2[0]\n",
    "        matfile2 = matfiles2[0]\n",
    "        signals2 = np.squeeze(np.load(os.path.join(indir, npyfile2))) \n",
    "        if signals2[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals2))\n",
    "        behaviordata2 = sio.loadmat(os.path.join(indir, matfile2))\n",
    "        eventlog2 = np.squeeze(behaviordata2['eventlog'])\n",
    "        eventlog2[:,1] = eventlog2[:,1]+lastframe_timestamp_part1  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog2))\n",
    "        lastframe_timestamp_part2 = np.max(eventlog)        \n",
    "        licks2 = np.squeeze(behaviordata2['licks'])\n",
    "        licks2 = licks2+lastframe_timestamp_part1\n",
    "        licks = np.concatenate ([licks, licks2])\n",
    "    if len(npyfiles) > 2:\n",
    "        npyfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw'and 'part3' in f]\n",
    "        matfiles3 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part3' in f and not 'results' in f]\n",
    "        npyfile3 = npyfiles3[0]\n",
    "        matfile3 = matfiles3[0]\n",
    "        signals3 = np.squeeze(np.load(os.path.join(indir, npyfile3))) \n",
    "        if signals3[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals3))\n",
    "        behaviordata3 = sio.loadmat(os.path.join(indir, matfile3))\n",
    "        eventlog3 = np.squeeze(behaviordata3['eventlog'])\n",
    "        eventlog3[:,1] = eventlog3[:,1]+lastframe_timestamp_part2  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog3))\n",
    "        lastframe_timestamp_part3 = np.max(eventlog)\n",
    "        licks3 = np.squeeze(behaviordata3['licks'])\n",
    "        licks3 = licks3+lastframe_timestamp_part2\n",
    "        licks = np.concatenate ([licks, licks3])\n",
    "    if len(npyfiles) > 3:\n",
    "        npyfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.npy' and 'extractedsignals_raw' and 'part4' in f]\n",
    "        matfiles4 = [f for f in tempfiles if os.path.splitext(f)[1]=='.mat' and 'part4' in f and not 'results' in f]\n",
    "        npyfile4 = npyfiles4[0]\n",
    "        matfile4 = matfiles4[0]\n",
    "        signals4 = np.squeeze(np.load(os.path.join(indir, npyfile4))) \n",
    "        if signals4[0][0]!='nan':\n",
    "            signals = np.hstack((signals, signals4))\n",
    "        behaviordata4 = sio.loadmat(os.path.join(indir, matfile4))\n",
    "        eventlog4 = np.squeeze(behaviordata4['eventlog'])\n",
    "        eventlog4[:,1] = eventlog4[:,1]+lastframe_timestamp_part3  #adding the last frame to the second column of data in eventlog\n",
    "        eventlog = np.concatenate((eventlog,eventlog4))\n",
    "        lastframe_timestamp_part4 = np.max(eventlog)\n",
    "        licks4 = np.squeeze(behaviordata4['licks'])\n",
    "        licks4 = licks4+lastframe_timestamp_part3\n",
    "        licks = np.concatenate ([licks, licks4])\n",
    "    #pulling data from eventlog\n",
    "    activelever = eventlog[eventlog[:,0]==22,1]\n",
    "    activelevertimeout = eventlog[eventlog[:,0]==222,1]\n",
    "    inactivelever = eventlog[eventlog[:,0]==21,1]\n",
    "    inactivelevertimeout = eventlog[eventlog[:,0]==212,1]\n",
    "    cues = eventlog[eventlog[:,0]==7,1]\n",
    "    infusions = eventlog[eventlog[:,0]==4,1]    \n",
    "\n",
    "    signals /= np.mean(signals, axis=1)[:, None]\n",
    "    signalsT = signals.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ###IF YOUR CODE LACKS FRAME INPUTS, WE CAN ATTEMPT TO PREDICT FRAME TIMING BY USING PREVIOUS FRAME TIMESTAMPS\n",
    "    if animal == 'CTL1' or animal == 'ER-L1' or animal == 'ER-L2' or animal == 'IG-19' or animal == 'IG-28' or animal == 'PGa-T1' or animal == 'XYZ':\n",
    "        frame_timestamps = assumed_frame_timestamps ###Fixes issue for finding behavior IF YOU DON\"T HAVE FRAME INFO\n",
    "    else:\n",
    "        frame_timestamps = fix_any_dropped_frames(eventlog[eventlog[:,0]==9,1]) \n",
    "    frame_timestamps = frame_timestamps[::frameaveraging] ###incorporates averaging into timestamp array\n",
    "    \n",
    "    ###DISCARDS BEHAVIORAL EVENTS THAT WERE NOT FULLY MONITORED WITH IMAGING\n",
    "    if signals.shape[1] > frame_timestamps.shape[0]:\n",
    "        signals = signals[:,:frame_timestamps.shape[0]-1] ###cuts signals so it's not longer than the frame timestamps\n",
    "        \n",
    "    final_frame_timestamp = frame_timestamps[signals.shape[1]] #This is the timestamp of the final frame in milliseconds\n",
    "    activelever = activelever[activelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    activelevertimeout = activelevertimeout[activelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelever = inactivelever[inactivelever<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    inactivelevertimeout = inactivelevertimeout[inactivelevertimeout<(final_frame_timestamp-(window_size/framerate*1000))]\n",
    "    \n",
    "    seconds_monitored = int(signals.shape[1]/averagedframerate) ###seconds monitored by 2p imaging\n",
    "    seconds_behavior = int(max(activelever/1000)) ###final seconds to be monitored for behavior\n",
    "\n",
    "    if seconds_monitored < seconds_behavior: #calculates last fully-monitored active lever press with 2p recording\n",
    "        included_trials = []\n",
    "        discarded_trials=[]\n",
    "        for i in range(len(activelever)):\n",
    "            if activelever[i]/1000<seconds_monitored:\n",
    "                included_trials=np.append(included_trials, activelever[i])\n",
    "            else:\n",
    "                discarded_trials=np.append(discarded_trials,activelever[i]) #FIXME why is this even here?\n",
    "        activelever=included_trials \n",
    "    #combines all presses\n",
    "    activeleverall = np.hstack((activelever, activelevertimeout))\n",
    "    inactiveleverall = np.hstack((inactivelever, inactivelevertimeout))\n",
    "\n",
    "    #FIXME\n",
    "    if activeleverall.shape[0] < 6:\n",
    "        activeleverall =np.array([])\n",
    "    if inactiveleverall.shape[0] < 6:\n",
    "        inactiveleverall = np.array([])\n",
    "    print('Signals.T:', signalsT.shape, 'Active:', activeleverall.shape, 'Inactive:',inactiveleverall.shape )\n",
    " \n",
    "    #method for calculating aligned data\n",
    "    def calculate_aligneddata_forevent(data, frame_after_event): #FIXME\n",
    "        framenumberfor_eventofinterest = np.squeeze(framenumberforevent(frame_after_event, frame_timestamps))\n",
    "        numtrials = framenumberfor_eventofinterest.shape[0]\n",
    "        if data.size==signals.size:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size,numneurons])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size,numneurons])###CHANGED ON AUGUST 20 2021\n",
    "        else:\n",
    "            align = np.NAN*np.zeros([numtrials,window_size])\n",
    "            align_to_plot = np.NAN*np.zeros([numtrials,window_size])\n",
    "        temp = data\n",
    "        prevendindex = 0\n",
    "        for i in range(numtrials):  ###CHANGED THIS SECTION ON AUGUST 20 2021\n",
    "            print(i)\n",
    "            tempindex = framenumberfor_eventofinterest[i]\n",
    "            if np.isfinite(tempindex):\n",
    "                tempindex = int(tempindex)\n",
    "                tempstartindex = np.amin([pre_window_size, tempindex]).astype(int)\n",
    "                startindex = np.amin([tempstartindex, tempindex-prevendindex]).astype(int)\n",
    "                tempendindex = np.amin([len(frame_timestamps)-tempindex, post_window_size])\n",
    "                print('  tempindex',tempindex)\n",
    "                print('  tempstartindex',tempstartindex)\n",
    "                print('  startindex',startindex)\n",
    "                print('  tempendindex',tempendindex)\n",
    "                if i<(numtrials-1) and np.isfinite(framenumberfor_eventofinterest[i+1]):\n",
    "                    #endindex = np.amin([framenumberfor_eventofinterest[i+1]-tempindex, tempendindex]).astype(int)\n",
    "                    #print('  endindex', endindex)\n",
    "                    endindex = tempendindex\n",
    "                    print('  endindex', endindex)\n",
    "                else:\n",
    "                    #endindex = tempendindex.astype(int) \n",
    "                    endindex = tempendindex\n",
    "                    print('  endindex', endindex) \n",
    "                    prevendindex = tempindex+endindex\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    print('     T1 align to plot:', (align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex,:]).shape)\n",
    "                    print('     T2 temp:', (temp[tempindex-startindex:tempindex+endindex,:]).shape) #FIXME -> throwing index error\n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex,:] = temp[tempindex-startindex:tempindex+endindex,:]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex,:] = temp[tempindex-tempstartindex:tempindex+endindex,:]\n",
    "                else: \n",
    "                    print((align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex,:]).shape)\n",
    "                    print((temp[tempindex-startindex:tempindex+endindex,:]).shape)\n",
    "                    align_to_plot[i,pre_window_size-startindex:pre_window_size+endindex] = temp[tempindex-startindex:tempindex+endindex]\n",
    "                    align[i,pre_window_size-tempstartindex:pre_window_size+endindex] = temp[tempindex-tempstartindex:tempindex+endindex]\n",
    "            else:\n",
    "                if temp.shape[0]!=temp.size:\n",
    "                    align_to_plot[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                    align[i,:,:] = np.nan*np.ones((window_size, numneurons))\n",
    "                else:\n",
    "                    align_to_plot[i,:] = np.nan*np.ones((window_size))\n",
    "                    align[i,:] = np.nan*np.ones((window_size))\n",
    "        if temp.shape[0]!=temp.size:         \n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]     \n",
    "        else:\n",
    "            align_to_plot = align_to_plot[np.where(np.isfinite(align_to_plot[:,0]))[0],:]\n",
    "        return align, align_to_plot, framenumberfor_eventofinterest\n",
    "    \n",
    "    print('start active calculation')\n",
    "    align_activelever, align_to_plot_activelever, framenumberfor_frameafter_activelever = \\\n",
    "        calculate_aligneddata_forevent(signalsT, activeleverall)  \n",
    "    populationdata_activelever = np.nanmean(align_activelever, axis=0).T-1\n",
    "    print('end active calculation')\n",
    "\n",
    "    print('start inactive calculation')\n",
    "    align_inactivelever, align_to_plot_inactivelever, framenumberfor_frameafter_inactivelever = \\\n",
    "        calculate_aligneddata_forevent(signalsT, inactiveleverall) #FIXME\n",
    "    populationdata_inactivelever = np.nanmean(align_inactivelever, axis=0).T-1\n",
    "    print('end inactive calculation')\n",
    "    \n",
    "    for i in range(signals.shape[0]):\n",
    "        if np.isnan(np.mean(signals[i,:])):\n",
    "            print(animal, fov, 'IMAGE J ROI.ZIP CELL NUMBER %s HAS NaNs AND SHOULD BE CHANGED'%(i+1))\n",
    "        \n",
    "    return populationdata_activelever, populationdata_inactivelever, align_activelever, align_inactivelever, framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early population\n",
    "excluded = []\n",
    "for animal in early_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        temp_active = np.nan*np.ones((1, window_size))\n",
    "        temp_inactive = np.nan*np.ones((1, window_size))\n",
    "        for fov in sorted(FOVs):\n",
    "            try:\n",
    "                temp1, temp2, temp3, temp4, framerate = analyze_single_session(\n",
    "                    #analysis parameters\n",
    "                    os.path.join(earlybasedir, animal, fov), \n",
    "                    window_size, \n",
    "                    pre_window_size\n",
    "                    )\n",
    "                #saving active and inactive signal data (includig NaN rows)\n",
    "                temp_active = np.vstack((temp_active, temp1))\n",
    "                temp_inactive = np.vstack((temp_inactive, temp2))\n",
    "                #saving aligned active and inactive lever data\n",
    "                temp_align_active_lever = temp3\n",
    "                temp_align_inactive_lever = temp4\n",
    "            except Exception as e:\n",
    "                print('***ERROR:', e, '***')\n",
    "                excluded.append(animal)\n",
    "            #files for signal data with NaN's\n",
    "            np.save(os.path.join(earlybasedir, animal, fov, \"active\"), temp_active[1:,:])\n",
    "            np.save(os.path.join(earlybasedir, animal, fov, \"inactive\"), temp_inactive[1:,:])\n",
    "            #files for aligned lever data\n",
    "            np.save(os.path.join(earlybasedir, animal, fov, \"aligned_active_lever_data\"), temp_align_active_lever)\n",
    "            np.save(os.path.join(earlybasedir, animal, fov, \"aligned_inactive_lever_data\"), temp_align_inactive_lever)\n",
    "print('Early excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Middle population\n",
    "excluded = []\n",
    "for animal in middle_animals_of_interest:\n",
    "    print('\\n>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(middlebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "            temp_active = np.nan*np.ones((1, window_size))\n",
    "            temp_inactive = np.nan*np.ones((1, window_size))\n",
    "            try:\n",
    "                for fov in sorted(FOVs):\n",
    "                    temp1, temp2, temp3, temp4, framerate = analyze_single_session(\n",
    "                        #analysis parameters\n",
    "                        os.path.join(middlebasedir, animal, fov), \n",
    "                        window_size, \n",
    "                        pre_window_size\n",
    "                        )\n",
    "                    #saving active and inactive signal data (includig NaN rows)\n",
    "                    temp_active = np.vstack((temp_active, temp1))\n",
    "                    temp_inactive = np.vstack((temp_inactive, temp2))\n",
    "                    #saving aligned active and inactive lever data\n",
    "                    temp_align_active_lever = temp3\n",
    "                    temp_align_inactive_lever = temp4\n",
    "            except Exception as e:\n",
    "                    print('***ERROR:', e, '***')\n",
    "                    excluded.append(animal)\n",
    "            #files for signal data without NaN's\n",
    "            np.save(os.path.join(middlebasedir, animal, fov, \"active\"), temp_active[1:,:])\n",
    "            np.save(os.path.join(middlebasedir, animal, fov, \"inactive\"), temp_inactive[1:,:])\n",
    "            #files for aligned lever data\n",
    "            np.save(os.path.join(middlebasedir, animal, fov, \"aligned_active_lever_data\"), temp_align_active_lever)\n",
    "            np.save(os.path.join(middlebasedir, animal, fov, \"aligned_inactive_lever_data\"), temp_align_inactive_lever)\n",
    "print('Middle excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Late population\n",
    "excluded = []\n",
    "for animal in late_animals_of_interest:\n",
    "    print('>>>', animal)\n",
    "    FOVs = next(os.walk(os.path.join(latebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "            temp_active = np.nan*np.ones((1, window_size))\n",
    "            temp_inactive = np.nan*np.ones((1, window_size))\n",
    "            for fov in sorted(FOVs):\n",
    "                try:\n",
    "                    temp1, temp2, temp3, temp4, framerate = analyze_single_session(\n",
    "                        #analysis parameters\n",
    "                        os.path.join(latebasedir, animal, fov), \n",
    "                        window_size, \n",
    "                        pre_window_size\n",
    "                        )\n",
    "                    #saving active and inactive signal data (includig NaN rows)\n",
    "                    print('Temp active shape:', temp_active.shape, 'Temp1 shape:', temp1.shape)\n",
    "                    temp_active = np.vstack((temp_active, temp1))\n",
    "                    temp_inactive = np.vstack((temp_inactive, temp2))\n",
    "                    #saving aligned active and inactive lever data\n",
    "                    temp_align_active_lever = temp3\n",
    "                    temp_align_inactive_lever = temp4\n",
    "                except Exception as e:\n",
    "                    print('***ERROR:', e, '***')\n",
    "                    excluded.append(animal)\n",
    "                #files for signal data without NaN's\n",
    "                np.save(os.path.join(latebasedir, animal, fov, \"active\"), temp_active[1:,:])\n",
    "                np.save(os.path.join(latebasedir, animal, fov, \"inactive\"), temp_inactive[1:,:])\n",
    "                #files for aligned lever data\n",
    "                np.save(os.path.join(latebasedir, animal, fov, \"aligned_active_lever_data\"), temp_align_active_lever)\n",
    "                np.save(os.path.join(latebasedir, animal, fov, \"aligned_inactive_lever_data\"), temp_align_inactive_lever)\n",
    "print('Late excluded animals:', excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for stacking data\n",
    "def stack_data(indir, animals_of_interest, window, signals_file, aligned_levers_file):\n",
    "    temp_data = np.nan*np.ones((1, window))\n",
    "    for animal in animals_of_interest:\n",
    "            FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "            for fov in sorted(FOVs):\n",
    "                    try:\n",
    "                        #load in data\n",
    "                        signal_data = np.load(os.path.join(indir, animal, fov, signals_file))\n",
    "                        lever_data = np.load(os.path.join(indir, animal, fov, aligned_levers_file))\n",
    "                        #stack data\n",
    "                        temp_data = np.vstack((temp_data, signal_data))\n",
    "                    except Exception as e:\n",
    "                        print('***ERROR:', e, ' ***')\n",
    "    data = temp_data[1:,:]\n",
    "    return(data, lever_data)\n",
    "\n",
    "#method for matching neurons to clusters based on criteria\n",
    "def find_indexes(indir, sub_animals_of_interest_array, original_full_stack, signal_file, cluster_labels_file):\n",
    "    indexes = []\n",
    "    for animal in sub_animals_of_interest_array:\n",
    "        FOVs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(FOVs):\n",
    "            signal_data = np.load(os.path.join(indir, animal, fov, signal_file))\n",
    "            for neuron in range(len(signal_data)):\n",
    "                for row in range(len(original_full_stack)):\n",
    "                    if np.equal(signal_data[neuron], original_full_stack[row])[0]==True:\n",
    "                        indexes.append({'Animal': animal, 'Stack index': row, 'Cluster': cluster_labels_file[row]})\n",
    "    indexes = pd.DataFrame(indexes)\n",
    "    return(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking early data\n",
    "\n",
    "#early active data\n",
    "temp_early_active, early_active_levers = stack_data(earlybasedir, early_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_active = temp_early_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_active = temp_early_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_early_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "early_active_mean = np.nanmean(early_active, axis=0)\n",
    "\n",
    "\n",
    "#early inactive data\n",
    "temp_early_inactive, early_inactive_levers = stack_data(earlybasedir, early_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons\n",
    "numneurons_early_inactive = temp_early_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_early_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "early_inactive = temp_early_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(early_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_early_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "early_inactive_mean = np.nanmean(early_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', early_active.shape)\n",
    "print('Active lever shape:', early_active_levers.shape)\n",
    "print('Inative shape:', early_inactive.shape)\n",
    "print('Inctive lever shape:', early_inactive_levers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking middle data\n",
    "\n",
    "#middle active data\n",
    "temp_middle_active, middle_active_levers = stack_data(middlebasedir, middle_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_middle_active = temp_middle_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_active = temp_middle_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_middle_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "middle_active_mean = np.nanmean(middle_active, axis=0)\n",
    "\n",
    "\n",
    "#middle inactive data\n",
    "temp_middle_inactive, middle_inactive_levers = stack_data(middlebasedir, middle_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_middle_inactive = temp_middle_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_middle_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "middle_inactive = temp_middle_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(middle_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_middle_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "middle_inactive_mean = np.nanmean(middle_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', middle_active.shape)\n",
    "print('Active lever shape:', middle_active_levers.shape)\n",
    "print('Inative shape:', middle_inactive.shape)\n",
    "print('Inctive lever shape:', middle_inactive_levers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking late data\n",
    "\n",
    "#late active data\n",
    "temp_late_active, late_active_levers = stack_data(latebasedir, late_animals_of_interest, window_size, \"active.npy\", 'aligned_active_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_late_active = temp_late_active.shape[0]-1 \n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_active = temp_late_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_active[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_late_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "late_active_mean = np.nanmean(late_active, axis=0)\n",
    "\n",
    "\n",
    "#late inactive data\n",
    "temp_late_inactive, late_inactive_levers = stack_data(latebasedir, late_animals_of_interest, window_size, \"inactive.npy\", 'aligned_inactive_lever_data.npy')\n",
    "\n",
    "#num neurons is length of data\n",
    "numneurons_late_inactive = temp_late_inactive.shape[0]-1 \n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(temp_late_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "late_inactive = temp_late_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(late_inactive[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_late_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "late_inactive_mean = np.nanmean(late_inactive, axis=0)\n",
    "\n",
    "print('Active shape:', late_active.shape)\n",
    "print('Active lever shape:', late_active_levers.shape)\n",
    "print('Inative shape:', late_inactive.shape)\n",
    "print('Inctive lever shape:', late_inactive_levers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating array of animals that meet lever press requirement\n",
    "\n",
    "req_presses = 6\n",
    "\n",
    "#early animals\n",
    "sub_early = []\n",
    "for animal in early_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(earlybasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(earlybasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_early.append(animal)\n",
    "\n",
    "#middle animals\n",
    "sub_middle = []\n",
    "for animal in middle_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(middlebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(middlebasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_middle.append(animal)\n",
    "\n",
    "#late animals\n",
    "sub_late = []\n",
    "for animal in late_animals_of_interest:\n",
    "    FOVs = next(os.walk(os.path.join(latebasedir, animal)))[1]\n",
    "    for fov in sorted(FOVs):\n",
    "        lever_data = np.load(os.path.join(latebasedir, animal, fov, 'aligned_inactive_lever_data.npy'))\n",
    "        num_presses = lever_data.shape[0]\n",
    "        if num_presses > req_presses:\n",
    "            sub_late.append(animal)\n",
    "\n",
    "print('Early animals with sufficient presses:', sub_early)\n",
    "print('Middle animals with sufficient presses:', sub_middle)\n",
    "print('Late animals with sufficient presses:', sub_late)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_early_active_df = find_indexes(earlybasedir, sub_early, temp_early_active, 'active.npy', early_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_early_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, early_active[index]))\n",
    "sub_early_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_early_active = sub_early_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_early_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_early_active_minus_baseline = sub_early_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_early_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_early_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_early_active_mean = np.nanmean(sub_early_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_early_inactive_df = find_indexes(earlybasedir, sub_early, temp_early_inactive, 'inactive.npy', early_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_early_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, early_inactive[index]))\n",
    "sub_early_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_early_inactive = sub_early_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_early_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_early_inactive_minus_baseline = sub_early_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_early_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_early_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_early_inactive_mean = np.nanmean(sub_early_inactive, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#middle data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_middle_active_df = find_indexes(middlebasedir, sub_middle, temp_middle_active, 'active.npy', middle_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_middle_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, middle_active[index]))\n",
    "sub_middle_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_middle_active = sub_middle_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_middle_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_middle_active_minus_baseline = sub_middle_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_middle_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_middle_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_middle_active_mean = np.nanmean(sub_middle_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_middle_inactive_df = find_indexes(middlebasedir, sub_middle, temp_middle_inactive, 'inactive.npy', middle_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_middle_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, middle_inactive[index]))\n",
    "sub_middle_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_middle_inactive = sub_middle_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_middle_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_middle_inactive_minus_baseline = sub_middle_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_middle_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_middle_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_middle_inactive_mean = np.nanmean(sub_middle_inactive, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#late data\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_late_active_df = find_indexes(latebasedir, sub_late, temp_late_active, 'active.npy', late_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_late_active_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, late_active[index]))\n",
    "sub_late_active = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_late_active = sub_late_active.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_late_active[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_late_active_minus_baseline = sub_late_active - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_late_active_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_late_active = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_late_active_mean = np.nanmean(sub_late_active, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#dataframe of female animal active data indexes\n",
    "sub_late_inactive_df = find_indexes(latebasedir, sub_late, temp_late_inactive, 'inactive.npy', late_newlabels)\n",
    "\n",
    "temp_stack = np.nan*np.ones((1, window_size))\n",
    "for index in sub_late_inactive_df['Stack index']:\n",
    "    temp_stack = np.vstack((temp_stack, late_inactive[index]))\n",
    "sub_late_inactive = temp_stack[1:,:]\n",
    "\n",
    "#num neurons\n",
    "numneurons_sub_late_inactive = sub_late_inactive.shape[0]\n",
    "\n",
    "#calculating population data - baseline\n",
    "baseline = np.mean(sub_late_inactive[:,baselinefirstframe:baselinelastframe], axis=1)\n",
    "sub_late_inactive_minus_baseline = sub_late_inactive - baseline[:,None]\n",
    "\n",
    "#sorting data\n",
    "tempresponse = np.nanmean(sub_late_inactive_minus_baseline[:,pre_window_size-(1*int(framerate)):pre_window_size+1*int(framerate)], axis=1)\n",
    "sortresponse_sub_late_inactive = np.argsort(tempresponse)[::-1]\n",
    "\n",
    "#calculating the mean using pandas\n",
    "sub_late_inactive_mean = np.nanmean(sub_late_inactive, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the NaN values\n",
    "def filter_NAN(processed_data, windowsize, prewindowsize, framerate):\n",
    "        filtered_stack = np.nan*np.ones((1, windowsize))\n",
    "        for row in processed_data:\n",
    "                if np.isfinite(row[0]):\n",
    "                        filtered_stack = np.vstack((filtered_stack, row))\n",
    "        filtered_stack = filtered_stack[1:,:]\n",
    "        response = np.nanmean(filtered_stack[:,prewindowsize-(1*int(framerate)):prewindowsize+1*int(framerate)], axis=1)\n",
    "        sortresponse = np.argsort(response)[::-1]\n",
    "        return(filtered_stack, sortresponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "# 2 rows and 3 columns of graphs; may end up with blank column\n",
    "fig, axs = plt.subplots(3, 3, figsize=(11, 11))\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "# early active plots\n",
    "ax = axs[0, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(early_active[sortresponse_early_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_early_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_active], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 0]\n",
    "ax.plot(early_active_mean)\n",
    "ax.plot(early_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# early inactive plots (sorted to active plot)\n",
    "ax = axs[1, 0]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_early_inactive, inactive_sort = filter_NAN(early_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_early_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_early_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_early_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# middle active plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(middle_active[sortresponse_middle_active, :], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_middle_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 1]\n",
    "ax.plot(middle_active_mean)\n",
    "ax.plot(middle_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# middle inactive plots\n",
    "ax = axs[1, 1]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_middle_inactive, inactive_sort = filter_NAN(middle_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_middle_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_middle_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_middle_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# late active plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(late_active[sortresponse_late_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_late_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 2]\n",
    "ax.plot(late_active_mean)\n",
    "ax.plot(late_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# late inactive plots\n",
    "ax = axs[1, 2]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_late_inactive, inactive_sort = filter_NAN(late_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_late_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_late_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_late_inactive], '--', linewidth=1.5, color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save fig\n",
    "#fig.savefig(os.path.join(, format='PDF')\n",
    "#fig.savefig(os.path.join(, format='PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "# initialize the plot\n",
    "# 2 rows and 3 columns of graphs; may end up with blank column\n",
    "fig, axs = plt.subplots(3, 3, figsize=(11, 11))\n",
    "sns.set_style('white')\n",
    "\n",
    "# setting max/min variables\n",
    "cmax = .1\n",
    "cmin = -cmax\n",
    "ymax = .1\n",
    "ymin = -ymax\n",
    "\n",
    "# early active plots\n",
    "ax = axs[0, 0]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_early_active[sortresponse_sub_early_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1]) #<-- set tick index\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"]) #<-- set tick labels\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_early_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_early_active], '--k', linewidth=1.5, color='white') #leverpress line <-- change line color\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 0]\n",
    "ax.plot(sub_early_active_mean)\n",
    "ax.plot(sub_early_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# early inactive plots (sorted to active plot)\n",
    "ax = axs[1, 0]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_early_inactive, inactive_sort = filter_NAN(sub_early_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_early_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[0]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_early_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_early_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# middle active plots\n",
    "ax = axs[0, 1]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_middle_active[sortresponse_sub_middle_active, :], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_middle_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_middle_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 1]\n",
    "ax.plot(sub_middle_active_mean)\n",
    "ax.plot(sub_middle_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# middle inactive plots\n",
    "ax = axs[1, 1]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_middle_inactive, inactive_sort = filter_NAN(sub_middle_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_middle_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[1]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_middle_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_middle_inactive], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# late active plots\n",
    "ax = axs[0, 2]\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sub_late_active[sortresponse_sub_late_active,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# color bar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\",\"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-ACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % numneurons_sub_late_active, fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_late_active], '--', linewidth=1.5, color='white')\n",
    "\n",
    "# line plot\n",
    "ax = axs[2, 2]\n",
    "ax.plot(sub_late_active_mean)\n",
    "ax.plot(sub_late_inactive_mean)\n",
    "ax.set_ylim([-.07, .07])\n",
    "ax.plot([0, window_size], [0, 0], '--k', linewidth=0.5)\n",
    "ax.axvline(pre_window_size, color='black', linestyle='--')\n",
    "ax.legend(['Active', 'Inactive'])\n",
    "\n",
    "# late inactive plots\n",
    "ax = axs[1, 2]\n",
    "\n",
    "#filtering NaN's\n",
    "sorted_sub_late_inactive, inactive_sort = filter_NAN(sub_late_inactive, window_size, pre_window_size, framerate)\n",
    "\n",
    "# heatmap\n",
    "hm = sns.heatmap(sorted_sub_late_inactive[inactive_sort,:], ax=ax, vmax=cmax, vmin=cmin, linewidth=0,\n",
    "                 cmap=sns.diverging_palette(\n",
    "                     154, 308, n=230, s=100, sep=50, center='dark'),\n",
    "                 cbar_kws={'label': '$\\Delta$F/F'}, xticklabels=False,  yticklabels=False)  # sets tick label increments\n",
    "\n",
    "# colorbar\n",
    "cbar = hm.collections[0].colorbar\n",
    "cbar.set_ticks([-.1, .1])\n",
    "cbar.set_ticklabels([cmin, cmax])\n",
    "ax.set(xticks=[0, pre_window_size, window_size-1])\n",
    "ax.set(xticklabels=[\"-10\", \"0\", \"13\"])\n",
    "\n",
    "#lines and labels\n",
    "ax.grid(False)\n",
    "ax.set_title(plot_titles[2]+\"-INACTIVE\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel('%s Neurons' % sorted_sub_late_inactive.shape[0], fontsize=12)\n",
    "ax.set_xlabel('Time (sec)', fontsize=12)\n",
    "ax.plot([pre_window_size, pre_window_size],\n",
    "        [0, numneurons_sub_late_inactive], '--', linewidth=1.5, color='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##inactive data\n",
    "#early_populationdata = early_inactive\n",
    "#middle_populationdata = middle_inactive\n",
    "#late_populationdata = late_inactive\n",
    "#all_populationdata = np.vstack((early_inactive, middle_inactive, late_inactive))\n",
    "\n",
    "#active data\n",
    "early_populationdata = early_active\n",
    "middle_populationdata = middle_active\n",
    "late_populationdata = late_active\n",
    "all_populationdata = np.vstack((early_active, middle_active, late_active))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late', 'all'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            temp = early_populationdata[np.where(early_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            temp = middle_populationdata[np.where(middle_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            temp = late_populationdata[np.where(late_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            temp = early_populationdata[np.where(early_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'middle':\n",
    "            temp = middle_populationdata[np.where(middle_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'late':\n",
    "            temp = late_populationdata[np.where(late_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:] #FIXME\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population data based on lever presses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Active clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active data\n",
    "early_populationdata = early_active\n",
    "middle_populationdata = middle_active\n",
    "late_populationdata = late_active\n",
    "all_populationdata = np.vstack((early_active, middle_active, late_active))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_active_df['Stack index'][np.where(sub_early_active_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_active_df['Stack index'][np.where(sub_middle_active_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_active_df['Stack index'][np.where(sub_late_active_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_active_df['Stack index'][np.where(sub_early_active_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_active_df['Stack index'][np.where(sub_middle_active_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_active_df['Stack index'][np.where(sub_late_active_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inactive clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inactive data\n",
    "early_populationdata = early_inactive\n",
    "middle_populationdata = middle_inactive\n",
    "late_populationdata = late_inactive\n",
    "all_populationdata = np.vstack((early_inactive, middle_inactive, late_inactive))\n",
    "\n",
    "#num neurons\n",
    "early_numneurons = early_populationdata.shape[0]\n",
    "middle_numneurons = middle_populationdata.shape[0]\n",
    "late_numneurons = late_populationdata.shape[0]\n",
    "all_numneurons = all_populationdata.shape[0]\n",
    "\n",
    "print('Early population num neurons:', early_numneurons)\n",
    "print('Middle population num neurons:', middle_numneurons)\n",
    "print('Late population num neurons:', late_numneurons)\n",
    "print('All population num neurons:', all_numneurons)\n",
    "print()\n",
    "\n",
    "#cluster list files\n",
    "all_newlabels = np.hstack((early_newlabels, middle_newlabels, late_newlabels))\n",
    "\n",
    "#the label values should match the num of neurons\n",
    "print('Early labels shape:', early_newlabels.shape)\n",
    "print('Middle labels shape:', middle_newlabels.shape)\n",
    "print('Late labels shape:', late_newlabels.shape)\n",
    "print('All labels shape:', all_newlabels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster heatmaps\n",
    "\n",
    "sessions = ['early', 'middle', 'late'] ###SET TO THE DIFFERENT TIME POINTS THAT WERE USED FOR TRACKING\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS FOR DATASET\n",
    "uniquelabels = np.arange(numclusters)\n",
    "\n",
    "sortwindow = {}\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    sortwindow[cluster] = {}\n",
    "    if cluster == 0:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 1:\n",
    "        sortwindow[cluster] = [infusionframe+int(1*framerate), -1]\n",
    "    if cluster == 2:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    if cluster == 3:\n",
    "        sortwindow[cluster] = [pre_window_size, infusionframe+int(3*framerate)]\n",
    "    \n",
    "cmax = 0.1\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(sessions)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_inactive_df['Stack index'][np.where(sub_early_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_inactive_df['Stack index'][np.where(sub_middle_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_inactive_df['Stack index'][np.where(sub_late_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[cluster][0]:sortwindow[cluster][1]], axis=1))[::-1]\n",
    "        hm = sns.heatmap(\n",
    "                    temp[sortresponse],\n",
    "                    ax=axs[s, cluster],\n",
    "                    cmap=sns.diverging_palette(154, 308,n=230,s=100,sep=50,center='dark'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence', 'ticks': [cmax, cmin]}\n",
    "                    )\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_xticklabels([])\n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='white', linewidth=1.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel('%s\\nNeurons'%(session))\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time (sec)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster line plots\n",
    "\n",
    "fig, axs = plt.subplots(len(sessions), len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),3*len(sessions)))\n",
    "\n",
    "numneuronsincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "colors_for_key = ['red','blue','purple','green']\n",
    "\n",
    "for cluster, cluster in enumerate(uniquelabels):\n",
    "    for s, session in enumerate(sessions):\n",
    "        if session == 'early':\n",
    "            df_reference = sub_early_inactive_df['Stack index'][np.where(sub_early_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = early_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'middle':\n",
    "            df_reference = sub_middle_inactive_df['Stack index'][np.where(sub_middle_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = middle_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'late':\n",
    "            df_reference = sub_late_inactive_df['Stack index'][np.where(sub_late_inactive_df['Cluster']==cluster)[0]]\n",
    "            temp = late_populationdata[df_reference]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        elif session == 'all':\n",
    "            temp = all_populationdata[np.where(all_newlabels==cluster)[0],:]\n",
    "            temp = temp[np.where(np.isfinite(temp[:,0]))[0],:]\n",
    "        numneuronsincluster[cluster] = temp.shape[0]\n",
    "        temp = np.mean(temp, axis = 0)        \n",
    "        sns.lineplot(data = temp, dashes = False, color = colors_for_key[s],\n",
    "                    ax=axs[s, cluster])\n",
    "\n",
    "        axs[s, cluster].grid(False)\n",
    "        if s==len(sessions)-1:\n",
    "            axs[s, cluster].set_xticks([0, pre_window_size, infusionframe, window_size])\n",
    "        else:\n",
    "            axs[s, cluster].set_xticks([])\n",
    "        axs[s, cluster].tick_params(width=0.5)    \n",
    "        axs[s, cluster].set_yticks([])\n",
    "        axs[s, cluster].set(ylim=(-.2, .2))\n",
    "        axs[s, cluster].text(x = s, y = .1, s = 'n = %d'%(numneuronsincluster[cluster]))\n",
    "        \n",
    "        axs[s, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=1.5)\n",
    "        axs[s, cluster].axhline(0, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[s, 0].set_ylabel(session)\n",
    "    axs[0, cluster].set_title('Cluster %d'%(cluster+1))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivoxel Pattern Analysis *(decoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import subprocess\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering, KMeans\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import interpolate\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import (ModelDesc, EvalEnvironment, Term, EvalFactor, LookupFactor, dmatrices, INTERCEPT)\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various methods\n",
    "\n",
    "def binaryclassifier(y, X, cv_val):\n",
    "    hyperparameters = {'kernel': ['rbf'], 'gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                     'C': [1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "    try:\n",
    "        clf = GridSearchCV(SVC(), hyperparameters, cv=cv_val)\n",
    "        clf.fit(X, y)\n",
    "        accuracy = clf.best_score_\n",
    "        return accuracy\n",
    "    except Exception as e:\n",
    "        print('*** ERROR:', e, '***')\n",
    "\n",
    "def svmregression(y, X):\n",
    "    hyperparameters = {'kernel': ['rbf'], 'cluster': np.logspace(-3, 3, 5),\n",
    "                      'epsilon': np.logspace(-3, 3, 5),\n",
    "                      'gamma': np.logspace(-5, 5, 10)}\n",
    "    clf = GridSearchCV(SVR(), hyperparameters, cv=10)\n",
    "    if np.all(np.isnan(X)):\n",
    "        R2=np.nan\n",
    "    else:\n",
    "        clf.fit(X, y)\n",
    "        R2 = clf.best_score_\n",
    "    #reference for 10-fold cross-validation http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf\n",
    "    return R2\n",
    "\n",
    "def calculate_t(x, y):\n",
    "    Sp= np.sqrt((np.nanstd(x)**2 + np.nanstd(y)**2)/2)\n",
    "    denominator = Sp*(np.sqrt(2/len(x)))\n",
    "    numerator = np.nanmean(x) - np.nanmean(y)\n",
    "    t = numerator/denominator\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['Early','Middle', 'Late'] ###INSERT YOUR GROUPS (E.G., EARLY AND LATE LEARNING)\n",
    "#animals_of_interest_list = [sub_early, sub_middle, sub_late]\n",
    "animals_of_interest_list = [early_animals_of_interest, middle_animals_of_interest, late_animals_of_interest]\n",
    "indir_list = [earlybasedir, middlebasedir, latebasedir]\n",
    "session_analysis_split_by_ensemble = ['Yes'] ###SET TO ['Yes'] OR TO ['No']\n",
    "decoding = ['Neuron', 'Trial'] ###SET TO Neuron or Session and Trial or Lick\n",
    "numclusters = 4 ###SET TO NUMBER OF CLUSTERS #FIXME -> 4 clusters?\n",
    "\n",
    "baseline = [1, 8]  ###These variables are for assigning neuronal data epochs\n",
    "leverresponse = [pre_window_size-9, pre_window_size-1]\n",
    "\n",
    "numshuffles = 1 \n",
    "classification_accuracy = {}\n",
    "uniquelabels = np.arange(numclusters)\n",
    "numneuronsincluster = np.nan*np.ones((numclusters,))\n",
    "\n",
    "print('========== STARTING ==========')\n",
    "datadir=0\n",
    "for index in range(len(groups)):\n",
    "    group = groups[index]\n",
    "    classification_accuracy[group] = {}\n",
    "    classification_accuracy[group]['individualneurons'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['shuffled'] = {}\n",
    "    classification_accuracy[group]['individualneurons']['unshuffled'] = {}\n",
    "\n",
    "    animals_of_interest = animals_of_interest_list[index]\n",
    "    indir = indir_list[index]\n",
    "\n",
    "    numneuronstillnow = 0 \n",
    "    for animal in animals_of_interest:\n",
    "        fovs = next(os.walk(os.path.join(indir, animal)))[1]\n",
    "        for fov in sorted(fovs):\n",
    "            trials = np.load(os.path.join(indir, animal, fov, 'aligned_active_lever_data.npy'))\n",
    "\n",
    "            ###THIS SECTION DELETES ANY TRIALS WITH NANs\n",
    "            for i in reversed(range(trials.shape[0])): ###reversed to prevent deletion from messing up indexing\n",
    "                if np.isnan(np.mean(trials[i,:,:])):\n",
    "                    trials = np.delete(trials, i, axis = 0)\n",
    "            \n",
    "            ###THIS SECTION ALIGNS DATA FOR DECODING        \n",
    "            numtrials = trials.shape[0]\n",
    "            numsapltes = trials.shape[1]\n",
    "            numneuronsinfov = trials.shape[2]\n",
    "\n",
    "            baseline_inactive = np.nan*np.ones((numtrials,numneuronsinfov))\n",
    "            response_inactive = np.nan*np.ones((numtrials,numneuronsinfov))\n",
    "\n",
    "            activeflag = np.hstack((np.zeros((numtrials)), np.ones((numtrials))))\n",
    "\n",
    "            if numtrials > 9:\n",
    "                for neuron in range(numneuronsinfov):\n",
    "                    print('Group:', group, '\\nAnimal:', animal, '\\nNeuron:', neuron, 'of', numneuronsinfov)\n",
    "                    baseline_inactive[:,neuron] = np.nanmean(trials[:,baseline[0]:baseline[1],neuron], axis=1)\n",
    "                    response_inactive[:,neuron] = np.nanmean(trials[:,leverresponse[0]:leverresponse[1],neuron], axis=1)\n",
    "                    \n",
    "                    cv = 10\n",
    "                    ###CHANGE THESE VARIABLES TO ADJUST WHAT YOU ARE DECODING AND ENSURE IT ALIGNS WITH YOUR FLAGS\n",
    "                    neuralactivity_trialtype = np.vstack((baseline_inactive, response_inactive)) ###FOR COMPARING TRIAL TYPES\n",
    "                    ###TRIAL DECODING IN SINGLE NEURONS\n",
    "                    #print('-----\\nbinaryclassifier unshuffled')\n",
    "                    #print('y:', activeflag.shape)\n",
    "                    #print('X:', np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1).shape)\n",
    "                    classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron] = binaryclassifier(activeflag, np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1), cv)\n",
    "                    #print('Unshuffled accuracy:', classification_accuracy[group]['individualneurons']['unshuffled'][numneuronstillnow+neuron])\n",
    "\n",
    "                    shuffledresults = np.nan*np.ones((numshuffles,))\n",
    "                    for shuffleid in range(numshuffles):\n",
    "                        shuffled_flag = np.random.permutation(activeflag)\n",
    "                        #print('-----\\nbinaryclassifier shuffled')\n",
    "                        #print('y:', shuffled_flag.shape)\n",
    "                        #print('X:', np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1).shape)\n",
    "                        shuffledresults[shuffleid] = binaryclassifier(shuffled_flag, np.expand_dims(neuralactivity_trialtype[:,neuron], axis=1), cv)\n",
    "                    classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron] = shuffledresults\n",
    "                    #print('Shuffled accuracy:', classification_accuracy[group]['individualneurons']['shuffled'][numneuronstillnow+neuron][0],'\\n-----')\n",
    "                    print()\n",
    "                numneuronstillnow += numneuronsinfov\n",
    "    print('END:', group,'\\n')\n",
    "print('========== FINISHED ==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS SECTION IS TO SAVE DECODING DATA AS NUMPY ARRAYS\n",
    "variable_to_save = 'ActivePress-All'\n",
    "decoding_dir = r'\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\universal_models\\decoding'\n",
    "\n",
    "for g, group in enumerate (groups):\n",
    "    unshuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['unshuffled'])))\n",
    "    shuffled = np.array(list(dict.items(classification_accuracy[group]['individualneurons']['shuffled'])))\n",
    "    shuffled_mean = np.mean(shuffled)\n",
    "    normalized_unshuffled = unshuffled - shuffled_mean\n",
    "    normalized_shuffled = shuffled - shuffled_mean\n",
    "    stacked = np.vstack((unshuffled[:,1], shuffled[:,1]))\n",
    "    np.save(os.path.join(decoding_dir,'PNAC_SucroseSA_%s_%s_Decoding_Population_%s.npy'%(group,variable_to_save,decoding[0])),stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show what's in each file\n",
    "for i in os.listdir(decoding_dir):\n",
    "    print(i)\n",
    "    infile = np.load(os.path.join(decoding_dir, i), allow_pickle=True)\n",
    "    print(infile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DECODING CDF PLOTS FOR EARLY, MIDDLE, AND LATE DATA\n",
    "analyze_by = 'Neuron' ###Session or Neuron\n",
    "variables_to_analyze = ['ActivePress-All']\n",
    "groups = ['Early', 'Middle', 'Late'] \n",
    "color = (['k'],['tab:red'], ['tab:green'],['tab:blue'])\n",
    "bins = np.arange(0.4,0.8,0.01)\n",
    "ls = ['--','solid']\n",
    "decode_results_dir = r'C:\\Users\\jboqu\\Dropbox\\2P Imaging Projects\\Beth\\Josh\\Repositories\\PFC_Self-Admin_Analysis\\PFC_Self-Admin_Analysis\\active-inactive_analysis\\acquisition\\results\\decoding'\n",
    "\n",
    "d = {}\n",
    "###THIS SECTION IS FOR LOADING AND PLOTTING SAVED POPULATION DECODING ARRAYS (BY NEURON OR SESSION)\n",
    "for v, variable in enumerate (variables_to_analyze):\n",
    "    d[variable] = {}\n",
    "    all_shuffle_for_variable=[]\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (16,4))\n",
    "    for g, group in enumerate(groups):\n",
    "        d[variable][group] = {}\n",
    "        d[variable][group] = np.array(np.load(os.path.join(decoding_dir,\n",
    "                                                           'PNAC_SucroseSA_%s_%s_Decoding_Population_%s.npy'%(group,variable,analyze_by)), \n",
    "                                                           allow_pickle = True).astype(float))\n",
    "        temp_unshuffle_nonans, temp_shuffle_nonans = ([],[])\n",
    "        temp_unshuffle,temp_shuffle = (d[variable][group][0],d[variable][group][1])\n",
    "\n",
    "        for i in range(len(temp_unshuffle)):\n",
    "            if np.isfinite(temp_unshuffle[i]):\n",
    "                temp_unshuffle_nonans = np.append(temp_unshuffle_nonans, temp_unshuffle[i])\n",
    "        for i in range(len(temp_shuffle)):\n",
    "            if np.isfinite(temp_shuffle[i]):\n",
    "                temp_shuffle_nonans = np.append(temp_shuffle_nonans, temp_shuffle[i])\n",
    "                \n",
    "        #NORMALIZING\n",
    "        #temp_unshuffle_nonans = temp_unshuffle_nonans - shuffled_mean\n",
    "        #temp_shuffle_nonans = temp_shuffle_nonans - shuffled_mean\n",
    "\n",
    "        plt.hist((temp_unshuffle_nonans),  density=True, cumulative=True,\\\n",
    "            label = ['%sUnShuffle'%(group)], histtype='step',\\\n",
    "            linestyle = ('-'), bins = bins, color = color[g], linewidth=2)\n",
    "        \n",
    "        if analyze_by == 'Session':\n",
    "            plt.hist((temp_shuffle_nonans),  density=True, cumulative=True,\\\n",
    "            label = ['%sShuffle'%(group)], histtype='step',\\\n",
    "            linestyle = ('--'), bins = bins, color = color[g], linewidth=2)\n",
    "        elif analyze_by == 'Neuron':\n",
    "            all_shuffle_for_variable = np.append(all_shuffle_for_variable, d[variable][group][1])\n",
    "            if g == len(groups)-1:\n",
    "                plt.hist((temp_shuffle_nonans),  density=True, cumulative=True,\\\n",
    "                    label = ['Shuffle','%sUnhuffle'%(group)], histtype='step',\\\n",
    "                    linestyle = ('--'), bins = bins, color = 'k', linewidth=2)\n",
    "        \n",
    "        plt.text(-0.15, 1-g*.05, '%s Shuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_shuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_shuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_shuffle_nonans)))\n",
    "        plt.text(-0.15, .75-g*.05, '%s Unhuffle: Mean = '%(group) + '{0:.3g}'.format(np.mean(temp_unshuffle_nonans)) + \\\n",
    "            ', SEM = ' + '{0:.3g}'.format(stats.sem(temp_unshuffle_nonans)) + ', N = ' + '{0:.3g}'.format(len(temp_unshuffle_nonans)))\n",
    "        t, p = stats.ttest_ind(temp_shuffle_nonans,\\\n",
    "            temp_unshuffle_nonans, equal_var=False)\n",
    "        plt.text(-0.15, .5-g*.05, '%s T-test: t = '%(group) + '{0:.3g}'.format(t) + ', p = ' + '{0:.3g}'.format(p))\n",
    "\n",
    "    ax[0].set_xticklabels([])\n",
    "    ax[0].set_yticklabels([])\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].spines['left'].set_visible(False)\n",
    "    ax[0].spines['bottom'].set_visible(False)\n",
    "\n",
    "    plt.legend(loc=2)\n",
    "    plt.title('%s_Analysis, Population_%s_Decoding'%(analyze_by, variable))\n",
    "    \n",
    "    #plt.savefig(os.path.join(decode_results_dir, 'PNAC_SucroseSA_Population_Decoding_%s_%s.PDF'%(variable, analyze_by)), format = 'PDF')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "776da2145dd803a979453fbc1814d1b7d7d946f11dae218ea400f99c86c281bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
